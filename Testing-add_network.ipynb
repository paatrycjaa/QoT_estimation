{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('polska')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gdansk': [18.6, 54.2],\n",
       " 'Bydgoszcz': [17.9, 53.1],\n",
       " 'Kolobrzeg': [16.1, 54.2],\n",
       " 'Katowice': [18.8, 50.3],\n",
       " 'Krakow': [19.8, 50.0],\n",
       " 'Bialystok': [23.1, 53.1],\n",
       " 'Lodz': [19.4, 51.7],\n",
       " 'Poznan': [16.8, 52.4],\n",
       " 'Rzeszow': [21.9, 50.0],\n",
       " 'Szczecin': [14.5, 53.4],\n",
       " 'Warsaw': [21.0, 52.2],\n",
       " 'Wroclaw': [16.9, 51.1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nodes = {}\n",
    "for node in root.findall(\".//{http://sndlib.zib.de/network}node\"):\n",
    "    x = node.find(\".//{http://sndlib.zib.de/network}x\")\n",
    "    y = node.find(\".//{http://sndlib.zib.de/network}y\")\n",
    "    Nodes[node.get('id')] = [float(x.text), float(y.text)]\n",
    "Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Links = {}\n",
    "for link in root.findall(\".//{http://sndlib.zib.de/network}link\"):\n",
    "    source = link.find(\".//{http://sndlib.zib.de/network}source\")\n",
    "    target = link.find(\".//{http://sndlib.zib.de/network}target\")\n",
    "    setupCost = link.find(\".//{http://sndlib.zib.de/network}setupCost\")\n",
    "    \n",
    "    longitudeS = Nodes[source.text][0]\n",
    "    longitudeT = Nodes[target.text][0]\n",
    "    latitudeS = Nodes[source.text][1]\n",
    "    latitudeT = Nodes[target.text][1]\n",
    "    \n",
    "    #distance1 = math.sqrt((longitudeS - longitudeT)**2 + (latitudeS - latitudeT)**2) * 73\n",
    "    distance2 = math.acos(math.sin(math.radians(latitudeS))*math.sin(math.radians(latitudeT)) + math.cos(math.radians(latitudeS))*\n",
    "                          math.cos(math.radians(latitudeT))*math.cos(math.radians(longitudeT - longitudeS)) )* 6371\n",
    "    Links[link.get('id')] = distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.6728876043855"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Links.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNodetoPath(node1, node2, input_list):\n",
    "    if len(input_list) == 2 :\n",
    "        if node1 in input_list and node1 == input_list[0] :\n",
    "            #print('pierwszy przypadek')\n",
    "            second_node = input_list[1]\n",
    "            input_list[1] = input_list[0]\n",
    "            input_list[0] = second_node\n",
    "            input_list.append(node2)\n",
    "            return input_list\n",
    "        if node2 in input_list and node2 == input_list[0] :\n",
    "            #print('drugi przypadek')\n",
    "            second_node = input_list[1]\n",
    "            input_list[1] = input_list[0]\n",
    "            input_list[0] = second_node\n",
    "            input_list.append(node1)\n",
    "            return input_list  \n",
    "    if node1 not in input_list : \n",
    "        input_list.append(node1)\n",
    "    if node2 not in input_list : \n",
    "        input_list.append(node2)\n",
    "        \n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Gdansk\n",
      "Target: Bydgoszcz\n",
      "DemandValue: 195.0\n",
      "['0', '2', '1']\n",
      "39.111775527610455\n",
      "['0', '10', '1']\n",
      "37.89570976324386\n",
      "['0', '2', '9', '7', '1']\n",
      "33.77412898818498\n",
      "['0', '5', '10', '1']\n",
      "33.98536367924393\n",
      "['0', '10', '4', '3', '11', '7', '1']\n",
      "29.721523571155718\n",
      "['0', '2', '9', '7', '11', '3', '4', '10', '1']\n",
      "24.68610440131703\n",
      "['0', '5', '8', '4', '10', '1']\n",
      "27.300950612745368\n",
      "Source: Gdansk\n",
      "Target: Kolobrzeg\n",
      "DemandValue: 158.0\n",
      "['0', '2']\n",
      "46.16431196677906\n",
      "['0', '10', '1', '2']\n",
      "34.17650665740858\n",
      "['0', '5', '10', '1', '2']\n",
      "31.09949390674199\n",
      "['0', '10', '4', '3', '11', '7', '1', '2']\n",
      "27.430891893891868\n",
      "['0', '10', '1', '7', '9', '2']\n",
      "30.005526784649767\n",
      "['0', '5', '8', '4', '10', '1', '2']\n",
      "24.91508084024343\n",
      "['0', '5', '10', '4', '3', '11', '7', '1', '2']\n",
      "25.008641047987183\n",
      "Source: Gdansk\n",
      "Target: Katowice\n",
      "DemandValue: 174.0\n",
      "['0', '5', '8', '4', '3']\n",
      "32.97309041124482\n",
      "['0', '10', '4', '3']\n",
      "36.09510728532111\n",
      "['0', '5', '10', '4', '3']\n",
      "33.018094534654516\n",
      "['0', '5', '8', '4', '10', '6', '3']\n",
      "26.1610444651115\n",
      "['0', '2', '1', '10', '4', '3']\n",
      "30.939635729111004\n",
      "['0', '10', '6', '3']\n",
      "35.422470282276656\n",
      "['0', '5', '10', '6', '3']\n",
      "32.345457531610066\n",
      "Source: Gdansk\n",
      "Target: Krakow\n",
      "DemandValue: 101.0\n",
      "['0', '5', '8', '4']\n",
      "33.806423744578154\n",
      "['0', '10', '4']\n",
      "37.76177395198777\n",
      "['0', '5', '10', '4']\n",
      "33.85142786798785\n",
      "['0', '2', '1', '10', '4']\n",
      "31.439635729111004\n",
      "['0', '10', '6', '3', '4']\n",
      "34.58913694894332\n",
      "['0', '5', '10', '6', '3', '4']\n",
      "31.84545753161006\n",
      "['0', '2', '9', '7', '1', '10', '4']\n",
      "27.768655856352193\n",
      "Source: Gdansk\n",
      "Target: Bialystok\n",
      "DemandValue: 198.0\n",
      "['0', '5']\n",
      "45.25465530393023\n",
      "['0', '10', '5']\n",
      "38.33128879246759\n",
      "['0', '2', '1', '10', '5']\n",
      "32.00915056959082\n",
      "['0', '10', '4', '8', '5']\n",
      "30.48020905930236\n",
      "['0', '2', '9', '7', '1', '10', '5']\n",
      "28.338170696832012\n",
      "['0', '2', '1', '7', '11', '3', '4', '8', '5']\n",
      "25.873293587426318\n",
      "['0', '2', '1', '10', '4', '8', '5']\n",
      "25.824737503092262\n",
      "Source: Gdansk\n",
      "Target: Lodz\n",
      "DemandValue: 158.0\n",
      "['0', '5', '8', '4', '3', '6']\n",
      "30.520482297353006\n",
      "['0', '10', '6']\n",
      "39.041745062835126\n",
      "['0', '5', '10', '6']\n",
      "35.13139897883521\n",
      "['0', '5', '8', '4', '10', '6']\n",
      "28.44698591233664\n",
      "['0', '5', '8', '4', '3', '11', '6']\n",
      "27.99491179763257\n",
      "['0', '2', '1', '10', '6']\n",
      "32.71960683995836\n",
      "['0', '10', '4', '3', '6']\n",
      "33.309165838095964\n",
      "Source: Gdansk\n",
      "Target: Poznan\n",
      "DemandValue: 182.0\n",
      "['0', '2', '1', '7']\n",
      "36.424592731378674\n",
      "['0', '10', '1', '7']\n",
      "35.20852696701208\n",
      "['0', '2', '9', '7']\n",
      "35.62797845108343\n",
      "['0', '2', '1', '10', '4', '3', '11', '7']\n",
      "26.68180623974882\n",
      "['0', '5', '10', '1', '7']\n",
      "32.13151421634548\n",
      "['0', '10', '4', '3', '11', '7']\n",
      "31.075373034054163\n",
      "['0', '10', '1', '2', '9', '7']\n",
      "28.97350647504627\n",
      "Source: Gdansk\n",
      "Target: Rzeszow\n",
      "DemandValue: 154.0\n",
      "['0', '5', '8']\n",
      "37.28757388271841\n",
      "['0', '10', '4', '8']\n",
      "34.28062381384751\n",
      "['0', '5', '10', '4', '8']\n",
      "31.20361106318092\n",
      "['0', '2', '1', '10', '4', '8']\n",
      "29.125152257637403\n",
      "['0', '10', '5', '8']\n",
      "33.69754070458911\n",
      "['0', '5', '10', '6', '3', '4', '8']\n",
      "29.697640726803133\n",
      "['0', '2', '9', '7', '1', '10', '4', '8']\n",
      "25.716077146783356\n",
      "Source: Gdansk\n",
      "Target: Szczecin\n",
      "DemandValue: 175.0\n",
      "['0', '2', '9']\n",
      "39.5302129080026\n",
      "['0', '10', '1', '2', '9']\n",
      "31.70907426529879\n",
      "['0', '2', '1', '7', '9']\n",
      "33.35569160779282\n",
      "['0', '5', '10', '1', '2', '9']\n",
      "28.965394847965527\n",
      "['0', '10', '4', '3', '11', '7', '9']\n",
      "28.50647191046832\n",
      "['0', '10', '1', '7', '9']\n",
      "32.13962584342623\n",
      "['0', '2', '1', '10', '4', '3', '11', '7', '9']\n",
      "24.267667020924883\n",
      "Source: Gdansk\n",
      "Target: Warsaw\n",
      "DemandValue: 122.0\n",
      "['0', '10']\n",
      "45.41481175686553\n",
      "['0', '2', '1', '10']\n",
      "34.92600686732211\n",
      "['0', '5', '10']\n",
      "38.17113233953228\n",
      "['0', '2', '9', '7', '1', '10']\n",
      "30.755026994563288\n",
      "['0', '2', '1', '7', '11', '3', '4', '10']\n",
      "28.180392103805392\n",
      "['0', '5', '8', '4', '10']\n",
      "30.320052606367053\n",
      "['0', '2', '9', '7', '11', '3', '4', '10']\n",
      "27.383777823510144\n",
      "Source: Gdansk\n",
      "Target: Wroclaw\n",
      "DemandValue: 114.0\n",
      "['0', '2', '1', '7', '11']\n",
      "33.851010396242785\n",
      "['0', '5', '8', '4', '3', '11']\n",
      "30.52693849511376\n",
      "['0', '2', '9', '7', '11']\n",
      "33.05439611594754\n",
      "['0', '2', '1', '10', '4', '3', '11']\n",
      "28.660150479646614\n",
      "['0', '10', '4', '3', '11']\n",
      "33.31562203585672\n",
      "['0', '5', '10', '4', '3', '11']\n",
      "30.571942618523458\n",
      "['0', '5', '8', '4', '10', '6', '11']\n",
      "25.914959214855454\n",
      "Source: Bydgoszcz\n",
      "Target: Kolobrzeg\n",
      "DemandValue: 179.0\n",
      "['1', '2']\n",
      "46.080041267725804\n",
      "['1', '7', '9', '2']\n",
      "36.57572806163366\n",
      "['1', '10', '0', '2']\n",
      "34.26077735646184\n",
      "['1', '7', '11', '3', '4', '8', '5', '0', '2']\n",
      "25.047907623630746\n",
      "['1', '10', '5', '0', '2']\n",
      "31.183764605795247\n",
      "['1', '10', '0', '5', '8', '4', '3', '11', '7', '9', '2']\n",
      "18.680154700631682\n",
      "['1', '7', '11', '6', '3', '4', '8', '5', '0', '2']\n",
      "22.703869172833247\n",
      "Source: Bydgoszcz\n",
      "Target: Katowice\n",
      "DemandValue: 117.0\n",
      "['1', '2', '0', '5', '8', '4', '3']\n",
      "28.118954898627525\n",
      "['1', '7', '9', '2', '0', '5', '8', '4', '3']\n",
      "24.864641692535383\n",
      "['1', '2', '9', '7', '11', '3']\n",
      "30.523973500763223\n",
      "['1', '2', '0', '10', '4', '3']\n",
      "30.74097177270381\n",
      "['1', '2', '0', '5', '10', '4', '3']\n",
      "28.163959022037222\n",
      "['1', '2', '0', '5', '8', '4', '10', '6', '3']\n",
      "21.723575619160876\n",
      "['1', '10', '4', '3']\n",
      "36.2937712417283\n",
      "Source: Bydgoszcz\n",
      "Target: Krakow\n",
      "DemandValue: 105.0\n",
      "['1', '2', '0', '5', '8', '4']\n",
      "28.452288231960857\n",
      "['1', '7', '9', '2', '0', '5', '8', '4']\n",
      "25.04321312110681\n",
      "['1', '2', '9', '7', '11', '3', '4']\n",
      "30.190640167429894\n",
      "['1', '2', '0', '10', '4']\n",
      "31.240971772703812\n",
      "['1', '2', '0', '5', '10', '4']\n",
      "28.497292355370554\n",
      "['1', '10', '4']\n",
      "37.960437908394965\n",
      "['1', '7', '11', '3', '4']\n",
      "35.92566065939569\n",
      "Source: Bydgoszcz\n",
      "Target: Bialystok\n",
      "DemandValue: 159.0\n",
      "['1', '2', '0', '5']\n",
      "34.5671864579796\n",
      "['1', '7', '9', '2', '0', '5']\n",
      "30.396206585220792\n",
      "['1', '2', '9', '7', '11', '3', '4', '8', '5']\n",
      "24.992408608077813\n",
      "['1', '2', '0', '10', '5']\n",
      "31.810486613183627\n",
      "['1', '10', '5']\n",
      "38.52995274887478\n",
      "['1', '7', '11', '3', '4', '8', '5']\n",
      "30.310762433376947\n",
      "['1', '7', '9', '2', '0', '10', '5']\n",
      "28.13950674042482\n",
      "Source: Bydgoszcz\n",
      "Target: Lodz\n",
      "DemandValue: 198.0\n",
      "['1', '2', '0', '5', '8', '4', '3', '6']\n",
      "25.928251546640478\n",
      "['1', '7', '9', '2', '0', '5', '8', '4', '3', '6']\n",
      "22.773144689754684\n",
      "['1', '2', '9', '7', '11', '6']\n",
      "30.271432052746423\n",
      "['1', '2', '0', '10', '6']\n",
      "32.52094288355117\n",
      "['1', '2', '0', '5', '10', '6']\n",
      "29.77726346621791\n",
      "['1', '2', '0', '5', '8', '4', '10', '6']\n",
      "23.85475516162411\n",
      "['1', '2', '0', '5', '8', '4', '3', '11', '6']\n",
      "23.557442951681942\n",
      "Source: Bydgoszcz\n",
      "Target: Poznan\n",
      "DemandValue: 189.0\n",
      "['1', '7']\n",
      "47.11206157732929\n",
      "['1', '2', '9', '7']\n",
      "35.54370775203017\n",
      "['1', '10', '0', '2', '9', '7']\n",
      "29.05777717409953\n",
      "['1', '2', '0', '5', '8', '4', '3', '11', '7']\n",
      "24.015887314027246\n",
      "['1', '10', '5', '0', '2', '9', '7']\n",
      "26.48076442343294\n",
      "['1', '10', '0', '5', '8', '4', '3', '11', '7']\n",
      "22.79982154966065\n",
      "['1', '2', '0', '10', '4', '3', '11', '7']\n",
      "26.483142283341632\n",
      "Source: Bydgoszcz\n",
      "Target: Rzeszow\n",
      "DemandValue: 166.0\n",
      "['1', '2', '0', '5', '8']\n",
      "30.766771703434454\n",
      "['1', '7', '9', '2', '0', '5', '8']\n",
      "27.095791830675648\n",
      "['1', '2', '9', '7', '11', '3', '4', '8']\n",
      "28.138061457861053\n",
      "['1', '2', '0', '10', '4', '8']\n",
      "28.926488301230215\n",
      "['1', '2', '0', '5', '10', '4', '8']\n",
      "26.34947555056363\n",
      "['1', '10', '4', '8']\n",
      "34.4792877702547\n",
      "['1', '7', '11', '3', '4', '8']\n",
      "33.61117718792209\n",
      "Source: Bydgoszcz\n",
      "Target: Szczecin\n",
      "DemandValue: 142.0\n",
      "['1', '2', '9']\n",
      "39.44594220894935\n",
      "['1', '7', '9']\n",
      "39.87649378707678\n",
      "['1', '2', '0', '5', '8', '4', '3', '11', '7', '9']\n",
      "21.641430634885847\n",
      "['1', '10', '0', '2', '9']\n",
      "31.793344964352045\n",
      "['1', '7', '11', '3', '4', '8', '5', '0', '2', '9']\n",
      "23.274919675965396\n",
      "['1', '2', '0', '10', '4', '3', '11', '7', '9']\n",
      "24.06900306451769\n",
      "['1', '2', '0', '5', '10', '4', '3', '11', '7', '9']\n",
      "21.686434758295544\n",
      "Source: Bydgoszcz\n",
      "Target: Warsaw\n",
      "DemandValue: 137.0\n",
      "['1', '10']\n",
      "45.61347571327273\n",
      "['1', '2', '0', '10']\n",
      "34.72734291091491\n",
      "['1', '7', '9', '2', '0', '10']\n",
      "30.5563630381561\n",
      "['1', '2', '9', '7', '11', '3', '4', '10']\n",
      "27.299507124456884\n",
      "['1', '2', '0', '5', '10']\n",
      "31.65033016024832\n",
      "['1', '7', '11', '3', '4', '10']\n",
      "32.77262285451792\n",
      "['1', '7', '9', '2', '0', '5', '10']\n",
      "27.979350287489513\n",
      "Source: Bydgoszcz\n",
      "Target: Wroclaw\n",
      "DemandValue: 163.0\n",
      "['1', '7', '11']\n",
      "40.37181257552675\n",
      "['1', '2', '0', '5', '8', '4', '3', '11']\n",
      "25.934707744401226\n",
      "['1', '7', '9', '2', '0', '5', '8', '4', '3', '11']\n",
      "22.77960088751544\n",
      "['1', '10', '4', '3', '11']\n",
      "33.51428599226391\n",
      "['1', '2', '9', '7', '11']\n",
      "32.970125416894284\n",
      "['1', '2', '0', '10', '4', '3', '11']\n",
      "28.461486523239422\n",
      "['1', '2', '0', '5', '10', '4', '3', '11']\n",
      "25.979711867810924\n",
      "Source: Kolobrzeg\n",
      "Target: Katowice\n",
      "DemandValue: 131.0\n",
      "['2', '0', '5', '8', '4', '3']\n",
      "30.504824671129466\n",
      "['2', '1', '10', '4', '3']\n",
      "33.40790146922635\n",
      "['2', '0', '10', '4', '3']\n",
      "33.29350821187242\n",
      "['2', '0', '5', '10', '4', '3']\n",
      "30.549828794539163\n",
      "['2', '0', '5', '8', '4', '10', '6', '3']\n",
      "23.954683486900908\n",
      "['2', '9', '7', '1', '10', '4', '3']\n",
      "29.736921596467543\n",
      "['2', '1', '7', '11', '3']\n",
      "33.87312422022708\n",
      "Source: Kolobrzeg\n",
      "Target: Krakow\n",
      "DemandValue: 159.0\n",
      "['2', '0', '5', '8', '4']\n",
      "31.004824671129466\n",
      "['2', '1', '10', '4']\n",
      "34.24123480255969\n",
      "['2', '0', '10', '4']\n",
      "34.12684154520576\n",
      "['2', '0', '5', '10', '4']\n",
      "31.049828794539163\n",
      "['2', '9', '7', '1', '10', '4']\n",
      "30.070254929800875\n",
      "['2', '1', '7', '11', '3', '4']\n",
      "33.373124220227076\n",
      "['2', '1', '10', '6', '3', '4']\n",
      "32.2352644661819\n",
      "Source: Kolobrzeg\n",
      "Target: Bialystok\n",
      "DemandValue: 164.0\n",
      "['2', '0', '5']\n",
      "38.28638956381488\n",
      "['2', '1', '10', '5']\n",
      "34.81074964303951\n",
      "['2', '0', '10', '5']\n",
      "34.696356385685576\n",
      "['2', '9', '7', '1', '10', '5']\n",
      "30.639769770280694\n",
      "['2', '1', '7', '11', '3', '4', '8', '5']\n",
      "28.020130756113094\n",
      "['2', '1', '10', '0', '5']\n",
      "30.46525092111106\n",
      "['2', '0', '10', '4', '8', '5']\n",
      "28.011943319187008\n",
      "Source: Kolobrzeg\n",
      "Target: Lodz\n",
      "DemandValue: 128.0\n",
      "['2', '0', '5', '8', '4', '3', '6']\n",
      "28.218883223904328\n",
      "['2', '1', '10', '6']\n",
      "35.52120591340705\n",
      "['2', '0', '10', '6']\n",
      "35.40681265605311\n",
      "['2', '0', '5', '10', '6']\n",
      "32.32979990538652\n",
      "['2', '0', '5', '8', '4', '10', '6']\n",
      "26.14538683888796\n",
      "['2', '0', '5', '8', '4', '3', '11', '6']\n",
      "25.78855081942198\n",
      "['2', '9', '7', '1', '10', '6']\n",
      "31.35022604064823\n",
      "Source: Kolobrzeg\n",
      "Target: Poznan\n",
      "DemandValue: 195.0\n",
      "['2', '1', '7']\n",
      "40.05952513816069\n",
      "['2', '9', '7']\n",
      "39.26291085786544\n",
      "['2', '1', '10', '4', '3', '11', '7']\n",
      "28.888167217959413\n",
      "['2', '0', '10', '1', '7']\n",
      "32.40692789356339\n",
      "['2', '1', '10', '6', '11', '7']\n",
      "30.2489302141233\n",
      "['2', '1', '10', '4', '3', '6', '11', '7']\n",
      "26.444922417955564\n",
      "['2', '0', '5', '10', '1', '7']\n",
      "29.66324847623013\n",
      "Source: Kolobrzeg\n",
      "Target: Rzeszow\n",
      "DemandValue: 130.0\n",
      "['2', '0', '5', '8']\n",
      "33.6526414759364\n",
      "['2', '1', '10', '4', '8']\n",
      "31.59341799775276\n",
      "['2', '0', '10', '4', '8']\n",
      "31.479024740398824\n",
      "['2', '0', '5', '10', '4', '8']\n",
      "28.735345323065566\n",
      "['2', '9', '7', '1', '10', '4', '8']\n",
      "27.92243812499395\n",
      "['2', '1', '7', '11', '3', '4', '8']\n",
      "31.22530741542015\n",
      "['2', '1', '10', '5', '8']\n",
      "31.010334888494356\n",
      "Source: Kolobrzeg\n",
      "Target: Szczecin\n",
      "DemandValue: 105.0\n",
      "['2', '9']\n",
      "46.49847864811795\n",
      "['2', '1', '7', '9']\n",
      "36.15729068124151\n",
      "['2', '0', '10', '1', '7', '9']\n",
      "29.671360103310874\n",
      "['2', '1', '10', '4', '3', '11', '7', '9']\n",
      "26.41450418961166\n",
      "['2', '0', '5', '10', '1', '7', '9']\n",
      "27.094347352644288\n",
      "['2', '0', '10', '4', '3', '11', '7', '9']\n",
      "26.300110932257727\n",
      "['2', '1', '10', '6', '11', '7', '9']\n",
      "27.680029090537456\n",
      "Source: Kolobrzeg\n",
      "Target: Warsaw\n",
      "DemandValue: 173.0\n",
      "['2', '0', '10']\n",
      "38.44654601675019\n",
      "['2', '1', '10']\n",
      "38.56093927410412\n",
      "['2', '0', '5', '10']\n",
      "34.536199932750264\n",
      "['2', '9', '7', '1', '10']\n",
      "33.223292734678644\n",
      "['2', '1', '7', '11', '3', '4', '10']\n",
      "30.386753082015982\n",
      "['2', '0', '5', '8', '4', '10']\n",
      "27.8517868662517\n",
      "['2', '9', '7', '11', '3', '4', '10']\n",
      "29.590138801720737\n",
      "Source: Kolobrzeg\n",
      "Target: Wroclaw\n",
      "DemandValue: 157.0\n",
      "['2', '1', '7', '11']\n",
      "36.65260946969148\n",
      "['2', '0', '5', '8', '4', '3', '11']\n",
      "28.22533942166508\n",
      "['2', '1', '10', '4', '3', '11']\n",
      "30.961749553095295\n",
      "['2', '9', '7', '11']\n",
      "35.85599518939623\n",
      "['2', '0', '10', '4', '3', '11']\n",
      "30.847356295741363\n",
      "['2', '0', '5', '10', '4', '3', '11']\n",
      "28.270343545074777\n",
      "['2', '0', '5', '8', '4', '10', '6', '11']\n",
      "23.708598236644857\n",
      "Source: Katowice\n",
      "Target: Krakow\n",
      "DemandValue: 194.0\n",
      "['3', '4']\n",
      "48.13257770689441\n",
      "['3', '6', '10', '4']\n",
      "35.487198427427764\n",
      "['3', '11', '7', '1', '2', '0', '5', '8', '4']\n",
      "22.995371184462137\n",
      "['3', '6', '11', '7', '1', '2', '0', '5', '8', '4']\n",
      "20.651332733664635\n",
      "['3', '6', '10', '5', '8', '4']\n",
      "29.941815041888834\n",
      "['3', '11', '6', '10', '4']\n",
      "32.461627927707326\n",
      "['3', '11', '7', '9', '2', '0', '5', '8', '4']\n",
      "22.19875690416689\n",
      "Source: Katowice\n",
      "Target: Bialystok\n",
      "DemandValue: 125.0\n",
      "['3', '4', '8', '5']\n",
      "36.684346147542335\n",
      "['3', '6', '10', '5']\n",
      "36.05671326790758\n",
      "['3', '4', '10', '5']\n",
      "36.72935027095203\n",
      "['3', '11', '7', '1', '2', '0', '5']\n",
      "28.193602743814214\n",
      "['3', '6', '11', '7', '1', '2', '0', '5']\n",
      "25.750357943810364\n",
      "['3', '6', '10', '0', '5']\n",
      "31.711214545979136\n",
      "['3', '4', '10', '0', '5']\n",
      "32.38385154902359\n",
      "Source: Katowice\n",
      "Target: Lodz\n",
      "DemandValue: 110.0\n",
      "['3', '6']\n",
      "46.1799695930026\n",
      "['3', '4', '10', '6']\n",
      "37.43980654131958\n",
      "['3', '11', '6']\n",
      "38.987732426615494\n",
      "['3', '4', '8', '5', '10', '6']\n",
      "31.894423155780643\n",
      "['3', '4', '10', '1', '7', '11', '6']\n",
      "29.667646079546106\n",
      "['3', '11', '7', '1', '10', '6']\n",
      "31.533491971743594\n",
      "['3', '4', '8', '5', '0', '10', '6']\n",
      "28.048924433852203\n",
      "Source: Katowice\n",
      "Target: Poznan\n",
      "DemandValue: 132.0\n",
      "['3', '4', '8', '5', '0', '2', '1', '7']\n",
      "26.86034353096717\n",
      "['3', '6', '10', '1', '7']\n",
      "33.7672847757854\n",
      "['3', '4', '10', '1', '7']\n",
      "34.43992177882985\n",
      "['3', '4', '8', '5', '10', '1', '7']\n",
      "29.394538393290922\n",
      "['3', '4', '8', '5', '0', '10', '1', '7']\n",
      "25.64427776660057\n",
      "['3', '4', '8', '5', '0', '2', '9', '7']\n",
      "26.063729250671923\n",
      "['3', '4', '8', '5', '0', '2', '1', '10', '6', '11', '7']\n",
      "19.621177178358355\n",
      "Source: Katowice\n",
      "Target: Rzeszow\n",
      "DemandValue: 159.0\n",
      "['3', '4', '8']\n",
      "41.318094235420816\n",
      "['3', '6', '10', '4', '8']\n",
      "32.839381622620834\n",
      "['3', '4', '10', '5', '8']\n",
      "32.92893551640688\n",
      "['3', '11', '7', '1', '2', '0', '5', '8']\n",
      "24.988426084507157\n",
      "['3', '6', '11', '7', '1', '2', '0', '5', '8']\n",
      "22.604705094027125\n",
      "['3', '6', '10', '5', '8']\n",
      "32.25629851336243\n",
      "['3', '4', '10', '0', '5', '8']\n",
      "28.916770127811773\n",
      "Source: Katowice\n",
      "Target: Szczecin\n",
      "DemandValue: 109.0\n",
      "['3', '4', '8', '5', '0', '2', '9']\n",
      "28.537392279019677\n",
      "['3', '6', '10', '0', '2', '9']\n",
      "30.486772150051507\n",
      "['3', '4', '10', '0', '2', '9']\n",
      "31.15940915309596\n",
      "['3', '4', '8', '5', '10', '0', '2', '9']\n",
      "26.375930529461794\n",
      "['3', '4', '8', '5', '0', '10', '1', '2', '9']\n",
      "22.79958696964919\n",
      "['3', '4', '8', '5', '0', '2', '1', '7', '9']\n",
      "24.44620431214323\n",
      "['3', '11', '7', '9']\n",
      "35.54394233204163\n",
      "Source: Katowice\n",
      "Target: Warsaw\n",
      "DemandValue: 126.0\n",
      "['3', '4', '10']\n",
      "40.47953990201665\n",
      "['3', '6', '10']\n",
      "39.8069028989722\n",
      "['3', '4', '8', '5', '10']\n",
      "33.76748984981106\n",
      "['3', '11', '6', '10']\n",
      "35.947999065918424\n",
      "['3', '6', '11', '7', '1', '10']\n",
      "30.701409103865394\n",
      "['3', '4', '8', '5', '0', '10']\n",
      "29.75532446121594\n",
      "['3', '11', '7', '1', '10']\n",
      "33.40655866577401\n",
      "Source: Katowice\n",
      "Target: Wroclaw\n",
      "DemandValue: 100.0\n",
      "['3', '11']\n",
      "46.18642579076335\n",
      "['3', '6', '11']\n",
      "38.981276228854746\n",
      "['3', '4', '8', '5', '0', '2', '1', '7', '11']\n",
      "24.941523100593194\n",
      "['3', '6', '10', '1', '7', '11']\n",
      "31.527035773982846\n",
      "['3', '4', '10', '6', '11']\n",
      "34.407779843838384\n",
      "['3', '4', '8', '5', '10', '6', '11']\n",
      "29.362396458299454\n",
      "['3', '4', '8', '5', '0', '10', '6', '11']\n",
      "25.612135831609105\n",
      "Source: Krakow\n",
      "Target: Bialystok\n",
      "DemandValue: 124.0\n",
      "['4', '8', '5']\n",
      "38.351012814209\n",
      "['4', '10', '5']\n",
      "38.3960169376187\n",
      "['4', '3', '6', '10', '5']\n",
      "35.22337993457425\n",
      "['4', '10', '0', '5']\n",
      "33.217184882356925\n",
      "['4', '3', '11', '7', '1', '2', '0', '5']\n",
      "27.955507505718973\n",
      "['4', '3', '6', '11', '7', '1', '2', '0', '5']\n",
      "25.571786515238937\n",
      "['4', '3', '6', '10', '0', '5']\n",
      "31.211214545979136\n",
      "Source: Krakow\n",
      "Target: Lodz\n",
      "DemandValue: 106.0\n",
      "['4', '3', '6']\n",
      "41.1799695930026\n",
      "['4', '10', '6']\n",
      "39.10647320798624\n",
      "['4', '3', '11', '6']\n",
      "37.32106575994884\n",
      "['4', '8', '5', '10', '6']\n",
      "32.39442315578064\n",
      "['4', '10', '1', '7', '11', '6']\n",
      "30.00097941287944\n",
      "['4', '3', '11', '7', '1', '10', '6']\n",
      "31.200158638410265\n",
      "['4', '8', '5', '0', '10', '6']\n",
      "28.382257767185532\n",
      "Source: Krakow\n",
      "Target: Poznan\n",
      "DemandValue: 136.0\n",
      "['4', '8', '5', '0', '2', '1', '7']\n",
      "27.09843876906241\n",
      "['4', '10', '1', '7']\n",
      "35.273255112163184\n",
      "['4', '8', '5', '10', '1', '7']\n",
      "29.72787172662425\n",
      "['4', '8', '5', '0', '10', '1', '7']\n",
      "25.88237300469581\n",
      "['4', '8', '5', '0', '2', '9', '7']\n",
      "26.301824488767164\n",
      "['4', '8', '5', '0', '2', '1', '10', '6', '11', '7']\n",
      "19.73228828946947\n",
      "['4', '3', '6', '10', '1', '7']\n",
      "33.2672847757854\n",
      "Source: Krakow\n",
      "Target: Rzeszow\n",
      "DemandValue: 144.0\n",
      "['4', '8']\n",
      "46.318094235420816\n",
      "['4', '10', '5', '8']\n",
      "33.76226884974022\n",
      "['4', '3', '6', '10', '5', '8']\n",
      "31.75629851336243\n",
      "['4', '10', '0', '5', '8']\n",
      "29.416770127811773\n",
      "['4', '3', '11', '7', '1', '2', '0', '5', '8']\n",
      "24.809854655935734\n",
      "['4', '3', '6', '11', '7', '1', '2', '0', '5', '8']\n",
      "22.465816205138236\n",
      "['4', '3', '6', '10', '0', '5', '8']\n",
      "27.91079979143399\n",
      "Source: Krakow\n",
      "Target: Szczecin\n",
      "DemandValue: 168.0\n",
      "['4', '8', '5', '0', '2', '9']\n",
      "28.870725612353006\n",
      "['4', '10', '0', '2', '9']\n",
      "31.659409153095964\n",
      "['4', '8', '5', '10', '0', '2', '9']\n",
      "26.614025767557035\n",
      "['4', '8', '5', '0', '10', '1', '2', '9']\n",
      "22.978158398220618\n",
      "['4', '8', '5', '0', '2', '1', '7', '9']\n",
      "24.624775740714657\n",
      "['4', '3', '6', '10', '0', '2', '9']\n",
      "30.15343881671818\n",
      "['4', '10', '1', '2', '9']\n",
      "31.773802410449896\n",
      "Source: Krakow\n",
      "Target: Warsaw\n",
      "DemandValue: 119.0\n",
      "['4', '10']\n",
      "45.47953990201665\n",
      "['4', '3', '6', '10']\n",
      "38.14023623230553\n",
      "['4', '8', '5', '10']\n",
      "34.60082318314439\n",
      "['4', '3', '11', '6', '10']\n",
      "35.11466573258509\n",
      "['4', '3', '6', '11', '7', '1', '10']\n",
      "30.368075770532066\n",
      "['4', '8', '5', '0', '10']\n",
      "30.25532446121594\n",
      "['4', '3', '11', '7', '1', '10']\n",
      "32.90655866577401\n",
      "Source: Krakow\n",
      "Target: Wroclaw\n",
      "DemandValue: 127.0\n",
      "['4', '3', '11']\n",
      "41.18642579076336\n",
      "['4', '8', '5', '0', '2', '1', '7', '11']\n",
      "25.120094529164618\n",
      "['4', '3', '6', '11']\n",
      "37.31460956218808\n",
      "['4', '10', '6', '11']\n",
      "35.24111317717171\n",
      "['4', '8', '5', '10', '6', '11']\n",
      "29.695729791632782\n",
      "['4', '8', '5', '0', '10', '6', '11']\n",
      "25.850231069704343\n",
      "['4', '8', '5', '0', '2', '9', '7', '11']\n",
      "24.32348024886937\n",
      "Source: Bialystok\n",
      "Target: Lodz\n",
      "DemandValue: 105.0\n",
      "['5', '8', '4', '3', '6']\n",
      "33.898404700317194\n",
      "['5', '10', '6']\n",
      "39.67598804846605\n",
      "['5', '8', '4', '10', '6']\n",
      "31.824908315300824\n",
      "['5', '8', '4', '3', '11', '6']\n",
      "31.206167533930085\n",
      "['5', '0', '10', '6']\n",
      "34.49715599320428\n",
      "['5', '10', '4', '3', '6']\n",
      "33.94340882372689\n",
      "['5', '8', '4', '10', '1', '7', '11', '6']\n",
      "24.647985948765456\n",
      "Source: Bialystok\n",
      "Target: Poznan\n",
      "DemandValue: 147.0\n",
      "['5', '0', '2', '1', '7']\n",
      "32.71333699508115\n",
      "['5', '10', '1', '7']\n",
      "35.842769952643\n",
      "['5', '0', '10', '1', '7']\n",
      "31.497271230714556\n",
      "['5', '0', '2', '9', '7']\n",
      "31.916722714785905\n",
      "['5', '0', '2', '1', '10', '4', '3', '11', '7']\n",
      "23.62531240821321\n",
      "['5', '8', '4', '10', '1', '7']\n",
      "29.158356886144436\n",
      "['5', '10', '0', '2', '1', '7']\n",
      "30.28997048361851\n",
      "Source: Bialystok\n",
      "Target: Rzeszow\n",
      "DemandValue: 140.0\n",
      "['5', '8']\n",
      "45.16549628568259\n",
      "['5', '10', '4', '8']\n",
      "34.91486679947844\n",
      "['5', '0', '10', '4', '8']\n",
      "30.569368077549992\n",
      "['5', '10', '6', '3', '4', '8']\n",
      "32.908896463100646\n",
      "['5', '0', '2', '1', '10', '4', '8']\n",
      "25.91389652133989\n",
      "['5', '0', '10', '6', '3', '4', '8']\n",
      "29.063397741172206\n",
      "['5', '10', '1', '7', '11', '3', '4', '8']\n",
      "28.437123658473887\n",
      "Source: Bialystok\n",
      "Target: Szczecin\n",
      "DemandValue: 198.0\n",
      "['5', '0', '2', '9']\n",
      "34.98562383837176\n",
      "['5', '10', '0', '2', '9']\n",
      "32.228923993575776\n",
      "['5', '0', '10', '1', '2', '9']\n",
      "28.3311518623346\n",
      "['5', '0', '2', '1', '7', '9']\n",
      "29.97776920482864\n",
      "['5', '8', '4', '10', '0', '2', '9']\n",
      "26.04451092707722\n",
      "['5', '10', '1', '2', '9']\n",
      "32.343317250929715\n",
      "['5', '10', '0', '2', '1', '7', '9']\n",
      "27.72106936003267\n",
      "Source: Bialystok\n",
      "Target: Warsaw\n",
      "DemandValue: 104.0\n",
      "['5', '10']\n",
      "46.04905474249646\n",
      "['5', '0', '10']\n",
      "37.53688935390135\n",
      "['5', '8', '4', '10']\n",
      "34.03130834266457\n",
      "['5', '0', '2', '1', '10']\n",
      "31.214751131024585\n",
      "['5', '8', '4', '3', '6', '10']\n",
      "32.02533800628678\n",
      "['5', '0', '2', '9', '7', '1', '10']\n",
      "27.543771258265775\n",
      "['5', '0', '2', '1', '7', '11', '3', '4', '10']\n",
      "25.123898272269777\n",
      "Source: Bialystok\n",
      "Target: Wroclaw\n",
      "DemandValue: 113.0\n",
      "['5', '0', '2', '1', '7', '11']\n",
      "30.4730879932786\n",
      "['5', '8', '4', '3', '11']\n",
      "33.90486089807794\n",
      "['5', '0', '10', '4', '3', '11']\n",
      "29.93769963289253\n",
      "['5', '0', '2', '9', '7', '11']\n",
      "29.676473712983352\n",
      "['5', '0', '2', '1', '10', '4', '3', '11']\n",
      "25.544132838587192\n",
      "['5', '10', '4', '3', '11']\n",
      "33.94986502148764\n",
      "['5', '8', '4', '10', '6', '11']\n",
      "29.126214951152967\n",
      "Source: Lodz\n",
      "Target: Poznan\n",
      "DemandValue: 169.0\n",
      "['6', '3', '4', '8', '5', '0', '2', '1', '7']\n",
      "24.729163988503934\n",
      "['6', '10', '1', '7']\n",
      "36.55322622301054\n",
      "['6', '3', '11', '7']\n",
      "35.826902008402335\n",
      "['6', '3', '4', '10', '1', '7']\n",
      "31.98731366493804\n",
      "['6', '3', '4', '8', '5', '10', '1', '7']\n",
      "27.203835041303872\n",
      "['6', '3', '4', '8', '5', '0', '10', '1', '7']\n",
      "23.513098224137337\n",
      "['6', '3', '4', '8', '5', '0', '2', '9', '7']\n",
      "23.93254970820869\n",
      "Source: Lodz\n",
      "Target: Rzeszow\n",
      "DemandValue: 187.0\n",
      "['6', '3', '4', '8']\n",
      "37.698819454862345\n",
      "['6', '10', '4', '8']\n",
      "35.625323069845976\n",
      "['6', '3', '11', '7', '1', '2', '0', '5', '8']\n",
      "22.857246542043924\n",
      "['6', '3', '4', '10', '5', '8']\n",
      "30.476327402515075\n",
      "['6', '11', '3', '4', '8']\n",
      "34.6732489551419\n",
      "['6', '10', '5', '8']\n",
      "35.04223996058758\n",
      "['6', '10', '4', '3', '11', '7', '1', '2', '0', '5', '8']\n",
      "20.53375015702756\n",
      "Source: Lodz\n",
      "Target: Szczecin\n",
      "DemandValue: 196.0\n",
      "['6', '3', '4', '8', '5', '0', '2', '9']\n",
      "26.346688927032627\n",
      "['6', '10', '0', '2', '9']\n",
      "32.93938026394332\n",
      "['6', '3', '11', '7', '9']\n",
      "32.75800088481648\n",
      "['6', '3', '4', '10', '0', '2', '9']\n",
      "28.873467705870823\n",
      "['6', '3', '4', '8', '5', '10', '0', '2', '9']\n",
      "24.24475098699856\n",
      "['6', '3', '4', '8', '5', '0', '10', '1', '2', '9']\n",
      "20.708089966868496\n",
      "['6', '3', '4', '8', '5', '0', '2', '1', '7', '9']\n",
      "22.354707309362535\n",
      "Source: Lodz\n",
      "Target: Warsaw\n",
      "DemandValue: 193.0\n",
      "['6', '10']\n",
      "46.759511012864\n",
      "['6', '3', '4', '10']\n",
      "36.86026512145818\n",
      "['6', '11', '3', '4', '10']\n",
      "33.83469462173773\n",
      "['6', '3', '11', '7', '1', '10']\n",
      "30.953950551882194\n",
      "['6', '3', '4', '8', '5', '10']\n",
      "31.314881735919244\n",
      "['6', '11', '7', '1', '10']\n",
      "33.15401721775721\n",
      "['6', '11', '3', '4', '8', '5', '10']\n",
      "28.789311236198806\n",
      "Source: Lodz\n",
      "Target: Wroclaw\n",
      "DemandValue: 151.0\n",
      "['6', '11']\n",
      "45.93388434274655\n",
      "['6', '3', '11']\n",
      "39.233817676871546\n",
      "['6', '10', '4', '3', '11']\n",
      "34.66032129185518\n",
      "['6', '3', '4', '8', '5', '0', '2', '1', '7', '11']\n",
      "22.8500260978125\n",
      "['6', '10', '1', '7', '11']\n",
      "33.97964388787465\n",
      "['6', '10', '4', '8', '5', '0', '2', '1', '7', '11']\n",
      "20.776529712796126\n",
      "['6', '3', '4', '10', '1', '7', '11']\n",
      "29.913731329802157\n",
      "Source: Poznan\n",
      "Target: Rzeszow\n",
      "DemandValue: 106.0\n",
      "['7', '1', '2', '0', '5', '8']\n",
      "29.246255573869337\n",
      "['7', '9', '2', '0', '5', '8']\n",
      "28.44964129357409\n",
      "['7', '1', '10', '4', '8']\n",
      "32.62543830735625\n",
      "['7', '1', '2', '0', '10', '4', '8']\n",
      "27.572638838331766\n",
      "['7', '1', '2', '0', '5', '10', '4', '8']\n",
      "25.09086418290327\n",
      "['7', '11', '3', '4', '8']\n",
      "35.131693317487205\n",
      "['7', '9', '2', '1', '10', '4', '8']\n",
      "26.890417815390453\n",
      "Source: Poznan\n",
      "Target: Szczecin\n",
      "DemandValue: 125.0\n",
      "['7', '9']\n",
      "45.8970099166419\n",
      "['7', '1', '2', '9']\n",
      "36.758759412717566\n",
      "['7', '11', '3', '4', '8', '5', '0', '2', '9']\n",
      "24.434324694419402\n",
      "['7', '1', '10', '0', '2', '9']\n",
      "30.272828834786928\n",
      "['7', '11', '6', '3', '4', '8', '5', '0', '2', '9']\n",
      "22.0902862436219\n",
      "['7', '11', '3', '6', '10', '0', '2', '9']\n",
      "26.22894266068933\n",
      "['7', '11', '3', '4', '10', '0', '2', '9']\n",
      "26.90157966373378\n",
      "Source: Poznan\n",
      "Target: Warsaw\n",
      "DemandValue: 194.0\n",
      "['7', '1', '10']\n",
      "39.59295958370761\n",
      "['7', '9', '2', '0', '10']\n",
      "32.076879167721216\n",
      "['7', '1', '2', '0', '10']\n",
      "32.87349344801646\n",
      "['7', '11', '3', '4', '10']\n",
      "34.293138984083036\n",
      "['7', '9', '2', '1', '10']\n",
      "32.19127242507515\n",
      "['7', '9', '2', '0', '5', '10']\n",
      "29.333199750387955\n",
      "['7', '1', '2', '0', '5', '10']\n",
      "30.129814030683203\n",
      "Source: Poznan\n",
      "Target: Wroclaw\n",
      "DemandValue: 194.0\n",
      "['7', '11']\n",
      "46.39232870509186\n",
      "['7', '1', '2', '0', '5', '8', '4', '3', '11']\n",
      "24.735620186264683\n",
      "['7', '9', '2', '0', '5', '8', '4', '3', '11']\n",
      "23.939005905969438\n",
      "['7', '1', '10', '4', '3', '11']\n",
      "31.99376986269879\n",
      "['7', '1', '2', '0', '10', '4', '3', '11']\n",
      "27.20287515557907\n",
      "['7', '1', '2', '0', '5', '10', '4', '3', '11']\n",
      "24.78062430967438\n",
      "['7', '1', '2', '0', '5', '8', '4', '10', '6', '11']\n",
      "20.31808535045082\n",
      "Source: Rzeszow\n",
      "Target: Szczecin\n",
      "DemandValue: 123.0\n",
      "['8', '5', '0', '2', '9']\n",
      "31.185209083826607\n",
      "['8', '4', '10', '0', '2', '9']\n",
      "29.344925681622364\n",
      "['8', '5', '10', '0', '2', '9']\n",
      "28.761842572363964\n",
      "['8', '5', '0', '10', '1', '2', '9']\n",
      "25.030737107789456\n",
      "['8', '5', '0', '2', '1', '7', '9']\n",
      "26.677354450283495\n",
      "['8', '4', '3', '6', '10', '0', '2', '9']\n",
      "28.10086010714934\n",
      "['8', '4', '10', '1', '2', '9']\n",
      "29.459318938976295\n",
      "Source: Rzeszow\n",
      "Target: Warsaw\n",
      "DemandValue: 181.0\n",
      "['8', '4', '10']\n",
      "38.665056430543046\n",
      "['8', '5', '10']\n",
      "38.08197332128465\n",
      "['8', '4', '3', '6', '10']\n",
      "35.4924194274986\n",
      "['8', '5', '0', '10']\n",
      "32.90314126602288\n",
      "['8', '4', '3', '11', '6', '10']\n",
      "32.80018226111149\n",
      "['8', '4', '3', '6', '11', '7', '1', '10']\n",
      "28.315497060963228\n",
      "['8', '5', '0', '2', '1', '10']\n",
      "27.74766970981277\n",
      "Source: Rzeszow\n",
      "Target: Wroclaw\n",
      "DemandValue: 193.0\n",
      "['8', '4', '3', '11']\n",
      "37.705275652623094\n",
      "['8', '5', '0', '2', '1', '7', '11']\n",
      "27.172673238733456\n",
      "['8', '4', '10', '6', '11']\n",
      "32.59329637236478\n",
      "['8', '4', '3', '6', '11']\n",
      "34.666792757381145\n",
      "['8', '5', '10', '4', '3', '11']\n",
      "30.482783600275823\n",
      "['8', '5', '0', '10', '4', '3', '11']\n",
      "26.637284878347383\n",
      "['8', '5', '0', '2', '9', '7', '11']\n",
      "26.37605895843821\n",
      "Source: Szczecin\n",
      "Target: Warsaw\n",
      "DemandValue: 181.0\n",
      "['9', '2', '0', '10']\n",
      "35.14578029130706\n",
      "['9', '7', '1', '10']\n",
      "35.69072512678844\n",
      "['9', '2', '1', '10']\n",
      "35.260173548661\n",
      "['9', '2', '0', '5', '10']\n",
      "32.06876754064047\n",
      "['9', '7', '11', '3', '4', '10']\n",
      "31.557571193830526\n",
      "['9', '7', '1', '2', '0', '10']\n",
      "30.137925657763947\n",
      "['9', '2', '1', '7', '11', '3', '4', '10']\n",
      "28.514558785144285\n",
      "Source: Szczecin\n",
      "Target: Wroclaw\n",
      "DemandValue: 195.0\n",
      "['9', '7', '11']\n",
      "39.15676091483935\n",
      "['9', '2', '1', '7', '11']\n",
      "34.18517707758168\n",
      "['9', '7', '1', '2', '0', '5', '8', '4', '3', '11']\n",
      "22.361163507123283\n",
      "['9', '2', '0', '5', '8', '4', '3', '11']\n",
      "26.353145124793375\n",
      "['9', '2', '1', '10', '4', '3', '11']\n",
      "28.994317160985506\n",
      "['9', '7', '1', '10', '4', '3', '11']\n",
      "29.42486873911295\n",
      "['9', '7', '1', '2', '0', '10', '4', '3', '11']\n",
      "24.788735936755124\n",
      "Source: Warsaw\n",
      "Target: Wroclaw\n",
      "DemandValue: 141.0\n",
      "['10', '4', '3', '11']\n",
      "36.866721319218925\n",
      "['10', '6', '11']\n",
      "39.560817648716146\n",
      "['10', '4', '8', '5', '0', '2', '1', '7', '11']\n",
      "22.288485295715425\n",
      "['10', '4', '3', '6', '11']\n",
      "33.828238423976984\n",
      "['10', '1', '7', '11']\n",
      "36.1860439152384\n",
      "['10', '6', '3', '11']\n",
      "36.194084316174475\n",
      "['10', '4', '8', '5', '0', '2', '9', '7', '11']\n",
      "21.49187101542018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All paths: 462'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "Y_values = []\n",
    "input_list = []\n",
    "for demand in root.findall(\".//{http://sndlib.zib.de/network}demand\"):\n",
    "    source = demand.find(\".//{http://sndlib.zib.de/network}source\")\n",
    "    target = demand.find(\".//{http://sndlib.zib.de/network}target\")\n",
    "    demandValue = demand.find(\".//{http://sndlib.zib.de/network}demandValue\")\n",
    "    #print(demand.attrib)\n",
    "    print(\"Source: \" + source.text)\n",
    "    print(\"Target: \" + target.text)\n",
    "    print(\"DemandValue: \" + demandValue.text)\n",
    "    \n",
    "    admissiblePaths = demand.findall(\".//{http://sndlib.zib.de/network}admissiblePath\")\n",
    "    for path in admissiblePaths:\n",
    "        path_links = path.findall(\".//{http://sndlib.zib.de/network}linkId\")\n",
    "        values = 0;\n",
    "        node_list=[]\n",
    "        for link_id in path_links:\n",
    "            values = values + 300./float(Links[link_id.text])\n",
    "            words = link_id.text.split('_')\n",
    "            node_list = addNodetoPath(words[1], words[2], node_list)\n",
    "        input_list.append(node_list.copy()) \n",
    "        size = float(len(node_list))\n",
    "        values= values + 300./min(Links.values())*(11-size)\n",
    "        values = values + 10./(size-1)\n",
    "        Y_values.append(values)\n",
    "        n = n+1\n",
    "        print(node_list)\n",
    "        print(values)  \n",
    "        node_list.clear()\n",
    "\"All paths: {}\".format(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Y_values,bins=20, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All paths: 462'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"All paths: {}\".format(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '2', '1'],\n",
       " ['0', '10', '1'],\n",
       " ['0', '2', '9', '7', '1'],\n",
       " ['0', '5', '10', '1'],\n",
       " ['0', '2'],\n",
       " ['0', '10', '1', '2'],\n",
       " ['0', '5', '8', '4', '3'],\n",
       " ['0', '10', '4', '3'],\n",
       " ['0', '5', '10', '4', '3'],\n",
       " ['0', '10', '6', '3'],\n",
       " ['0', '5', '10', '6', '3'],\n",
       " ['0', '5', '8', '4'],\n",
       " ['0', '10', '4'],\n",
       " ['0', '5', '10', '4'],\n",
       " ['0', '10', '6', '3', '4'],\n",
       " ['0', '5'],\n",
       " ['0', '10', '5'],\n",
       " ['0', '2', '1', '10', '5'],\n",
       " ['0', '10', '6'],\n",
       " ['0', '5', '10', '6'],\n",
       " ['0', '2', '1', '10', '6'],\n",
       " ['0', '10', '4', '3', '6'],\n",
       " ['0', '2', '1', '7'],\n",
       " ['0', '10', '1', '7'],\n",
       " ['0', '2', '9', '7'],\n",
       " ['0', '5', '10', '1', '7'],\n",
       " ['0', '5', '8'],\n",
       " ['0', '10', '4', '8'],\n",
       " ['0', '10', '5', '8'],\n",
       " ['0', '2', '9'],\n",
       " ['0', '2', '1', '7', '9'],\n",
       " ['0', '10', '1', '7', '9'],\n",
       " ['0', '10'],\n",
       " ['0', '2', '1', '10'],\n",
       " ['0', '5', '10'],\n",
       " ['0', '2', '1', '7', '11'],\n",
       " ['0', '2', '9', '7', '11'],\n",
       " ['0', '10', '4', '3', '11'],\n",
       " ['1', '2'],\n",
       " ['1', '7', '9', '2'],\n",
       " ['1', '10', '0', '2'],\n",
       " ['1', '10', '4', '3'],\n",
       " ['1', '10', '4'],\n",
       " ['1', '7', '11', '3', '4'],\n",
       " ['1', '2', '0', '5'],\n",
       " ['1', '10', '5'],\n",
       " ['1', '2', '0', '10', '6'],\n",
       " ['1', '7'],\n",
       " ['1', '2', '9', '7'],\n",
       " ['1', '10', '4', '8'],\n",
       " ['1', '7', '11', '3', '4', '8'],\n",
       " ['1', '2', '9'],\n",
       " ['1', '7', '9'],\n",
       " ['1', '10'],\n",
       " ['1', '2', '0', '10'],\n",
       " ['1', '7', '11', '3', '4', '10'],\n",
       " ['1', '7', '11'],\n",
       " ['1', '10', '4', '3', '11'],\n",
       " ['1', '2', '9', '7', '11'],\n",
       " ['2', '1', '10', '4', '3'],\n",
       " ['2', '0', '10', '4', '3'],\n",
       " ['2', '1', '7', '11', '3'],\n",
       " ['2', '1', '10', '4'],\n",
       " ['2', '0', '10', '4'],\n",
       " ['2', '1', '7', '11', '3', '4'],\n",
       " ['2', '1', '10', '6', '3', '4'],\n",
       " ['2', '0', '5'],\n",
       " ['2', '1', '10', '5'],\n",
       " ['2', '0', '10', '5'],\n",
       " ['2', '1', '10', '6'],\n",
       " ['2', '0', '10', '6'],\n",
       " ['2', '0', '5', '10', '6'],\n",
       " ['2', '1', '7'],\n",
       " ['2', '9', '7'],\n",
       " ['2', '0', '10', '1', '7'],\n",
       " ['2', '0', '5', '8'],\n",
       " ['2', '9'],\n",
       " ['2', '1', '7', '9'],\n",
       " ['2', '0', '10'],\n",
       " ['2', '1', '10'],\n",
       " ['2', '0', '5', '10'],\n",
       " ['2', '9', '7', '1', '10'],\n",
       " ['2', '1', '7', '11'],\n",
       " ['2', '9', '7', '11'],\n",
       " ['3', '4'],\n",
       " ['3', '6', '10', '4'],\n",
       " ['3', '11', '6', '10', '4'],\n",
       " ['3', '4', '8', '5'],\n",
       " ['3', '6', '10', '5'],\n",
       " ['3', '4', '10', '5'],\n",
       " ['3', '4', '10', '0', '5'],\n",
       " ['3', '6'],\n",
       " ['3', '4', '10', '6'],\n",
       " ['3', '11', '6'],\n",
       " ['3', '6', '10', '1', '7'],\n",
       " ['3', '4', '10', '1', '7'],\n",
       " ['3', '4', '8'],\n",
       " ['3', '6', '10', '4', '8'],\n",
       " ['3', '4', '10', '5', '8'],\n",
       " ['3', '6', '10', '5', '8'],\n",
       " ['3', '11', '7', '9'],\n",
       " ['3', '4', '10'],\n",
       " ['3', '6', '10'],\n",
       " ['3', '4', '8', '5', '10'],\n",
       " ['3', '11', '6', '10'],\n",
       " ['3', '11', '7', '1', '10'],\n",
       " ['3', '11'],\n",
       " ['3', '6', '11'],\n",
       " ['3', '4', '10', '6', '11'],\n",
       " ['4', '8', '5'],\n",
       " ['4', '10', '5'],\n",
       " ['4', '3', '6', '10', '5'],\n",
       " ['4', '10', '0', '5'],\n",
       " ['4', '3', '6'],\n",
       " ['4', '10', '6'],\n",
       " ['4', '3', '11', '6'],\n",
       " ['4', '8', '5', '10', '6'],\n",
       " ['4', '10', '1', '7'],\n",
       " ['4', '3', '6', '10', '1', '7'],\n",
       " ['4', '8'],\n",
       " ['4', '10', '5', '8'],\n",
       " ['4', '10'],\n",
       " ['4', '3', '6', '10'],\n",
       " ['4', '8', '5', '10'],\n",
       " ['4', '3', '11', '6', '10'],\n",
       " ['4', '3', '11', '7', '1', '10'],\n",
       " ['4', '3', '11'],\n",
       " ['4', '3', '6', '11'],\n",
       " ['4', '10', '6', '11'],\n",
       " ['5', '8', '4', '3', '6'],\n",
       " ['5', '10', '6'],\n",
       " ['5', '0', '10', '6'],\n",
       " ['5', '10', '4', '3', '6'],\n",
       " ['5', '0', '2', '1', '7'],\n",
       " ['5', '10', '1', '7'],\n",
       " ['5', '8'],\n",
       " ['5', '10', '4', '8'],\n",
       " ['5', '10', '6', '3', '4', '8'],\n",
       " ['5', '0', '2', '9'],\n",
       " ['5', '10', '0', '2', '9'],\n",
       " ['5', '10', '1', '2', '9'],\n",
       " ['5', '10'],\n",
       " ['5', '0', '10'],\n",
       " ['5', '8', '4', '10'],\n",
       " ['5', '8', '4', '3', '6', '10'],\n",
       " ['5', '8', '4', '3', '11'],\n",
       " ['5', '10', '4', '3', '11'],\n",
       " ['6', '10', '1', '7'],\n",
       " ['6', '3', '11', '7'],\n",
       " ['6', '3', '4', '8'],\n",
       " ['6', '10', '4', '8'],\n",
       " ['6', '11', '3', '4', '8'],\n",
       " ['6', '10', '5', '8'],\n",
       " ['6', '10', '0', '2', '9'],\n",
       " ['6', '3', '11', '7', '9'],\n",
       " ['6', '10'],\n",
       " ['6', '3', '4', '10'],\n",
       " ['6', '11', '3', '4', '10'],\n",
       " ['6', '11', '7', '1', '10'],\n",
       " ['6', '11'],\n",
       " ['6', '3', '11'],\n",
       " ['6', '10', '4', '3', '11'],\n",
       " ['6', '10', '1', '7', '11'],\n",
       " ['7', '1', '10', '4', '8'],\n",
       " ['7', '11', '3', '4', '8'],\n",
       " ['7', '9'],\n",
       " ['7', '1', '2', '9'],\n",
       " ['7', '1', '10'],\n",
       " ['7', '9', '2', '0', '10'],\n",
       " ['7', '1', '2', '0', '10'],\n",
       " ['7', '11', '3', '4', '10'],\n",
       " ['7', '9', '2', '1', '10'],\n",
       " ['7', '11'],\n",
       " ['8', '4', '10'],\n",
       " ['8', '5', '10'],\n",
       " ['8', '4', '3', '6', '10'],\n",
       " ['8', '5', '0', '10'],\n",
       " ['8', '4', '3', '11', '6', '10'],\n",
       " ['8', '4', '3', '11'],\n",
       " ['8', '4', '10', '6', '11'],\n",
       " ['8', '4', '3', '6', '11'],\n",
       " ['9', '2', '0', '10'],\n",
       " ['9', '7', '1', '10'],\n",
       " ['9', '2', '1', '10'],\n",
       " ['9', '2', '0', '5', '10'],\n",
       " ['9', '7', '11'],\n",
       " ['9', '2', '1', '7', '11'],\n",
       " ['10', '4', '3', '11'],\n",
       " ['10', '6', '11'],\n",
       " ['10', '4', '3', '6', '11'],\n",
       " ['10', '1', '7', '11'],\n",
       " ['10', '6', '3', '11']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for (i,v) in zip(input_list, Y_values) if v>32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Min: 18.680154700631682'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Min: {}\".format(min(Y_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max: 48.13257770689441'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Max: {}\".format(max(Y_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean: 31.264953871433754'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Mean: {}\".format(statistics.mean(Y_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate OSNR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_output = np.array(Y_values)\n",
    "Y_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_val=max(Y_output)\n",
    "#min_val=min(Y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_output_s = 10 + 35*(Y_output/max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min(Y_output_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(Y_output_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(Y_output_s,bins=30, kde=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.69028916, 30.95785005, 34.4318863 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimit_values=np.quantile(Y_output, [0.25,0.5,0.75])\n",
    "delimit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output[Y_output<=delimit_values[0]]=0\n",
    "Y_output[(Y_output>delimit_values[0]) & (Y_output<=delimit_values[1])]=1\n",
    "Y_output[(Y_output>delimit_values[1]) & (Y_output<=delimit_values[2])]=2\n",
    "Y_output[Y_output>delimit_values[2]]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.111775527610455,\n",
       " 37.89570976324386,\n",
       " 33.77412898818498,\n",
       " 33.98536367924393,\n",
       " 29.721523571155718,\n",
       " 24.68610440131703,\n",
       " 27.300950612745368,\n",
       " 46.16431196677906,\n",
       " 34.17650665740858,\n",
       " 31.09949390674199,\n",
       " 27.430891893891868,\n",
       " 30.005526784649767,\n",
       " 24.91508084024343,\n",
       " 25.008641047987183,\n",
       " 32.97309041124482,\n",
       " 36.09510728532111,\n",
       " 33.018094534654516,\n",
       " 26.1610444651115,\n",
       " 30.939635729111004,\n",
       " 35.422470282276656,\n",
       " 32.345457531610066,\n",
       " 33.806423744578154,\n",
       " 37.76177395198777,\n",
       " 33.85142786798785,\n",
       " 31.439635729111004,\n",
       " 34.58913694894332,\n",
       " 31.84545753161006,\n",
       " 27.768655856352193,\n",
       " 45.25465530393023,\n",
       " 38.33128879246759,\n",
       " 32.00915056959082,\n",
       " 30.48020905930236,\n",
       " 28.338170696832012,\n",
       " 25.873293587426318,\n",
       " 25.824737503092262,\n",
       " 30.520482297353006,\n",
       " 39.041745062835126,\n",
       " 35.13139897883521,\n",
       " 28.44698591233664,\n",
       " 27.99491179763257,\n",
       " 32.71960683995836,\n",
       " 33.309165838095964,\n",
       " 36.424592731378674,\n",
       " 35.20852696701208,\n",
       " 35.62797845108343,\n",
       " 26.68180623974882,\n",
       " 32.13151421634548,\n",
       " 31.075373034054163,\n",
       " 28.97350647504627,\n",
       " 37.28757388271841,\n",
       " 34.28062381384751,\n",
       " 31.20361106318092,\n",
       " 29.125152257637403,\n",
       " 33.69754070458911,\n",
       " 29.697640726803133,\n",
       " 25.716077146783356,\n",
       " 39.5302129080026,\n",
       " 31.70907426529879,\n",
       " 33.35569160779282,\n",
       " 28.965394847965527,\n",
       " 28.50647191046832,\n",
       " 32.13962584342623,\n",
       " 24.267667020924883,\n",
       " 45.41481175686553,\n",
       " 34.92600686732211,\n",
       " 38.17113233953228,\n",
       " 30.755026994563288,\n",
       " 28.180392103805392,\n",
       " 30.320052606367053,\n",
       " 27.383777823510144,\n",
       " 33.851010396242785,\n",
       " 30.52693849511376,\n",
       " 33.05439611594754,\n",
       " 28.660150479646614,\n",
       " 33.31562203585672,\n",
       " 30.571942618523458,\n",
       " 25.914959214855454,\n",
       " 46.080041267725804,\n",
       " 36.57572806163366,\n",
       " 34.26077735646184,\n",
       " 25.047907623630746,\n",
       " 31.183764605795247,\n",
       " 18.680154700631682,\n",
       " 22.703869172833247,\n",
       " 28.118954898627525,\n",
       " 24.864641692535383,\n",
       " 30.523973500763223,\n",
       " 30.74097177270381,\n",
       " 28.163959022037222,\n",
       " 21.723575619160876,\n",
       " 36.2937712417283,\n",
       " 28.452288231960857,\n",
       " 25.04321312110681,\n",
       " 30.190640167429894,\n",
       " 31.240971772703812,\n",
       " 28.497292355370554,\n",
       " 37.960437908394965,\n",
       " 35.92566065939569,\n",
       " 34.5671864579796,\n",
       " 30.396206585220792,\n",
       " 24.992408608077813,\n",
       " 31.810486613183627,\n",
       " 38.52995274887478,\n",
       " 30.310762433376947,\n",
       " 28.13950674042482,\n",
       " 25.928251546640478,\n",
       " 22.773144689754684,\n",
       " 30.271432052746423,\n",
       " 32.52094288355117,\n",
       " 29.77726346621791,\n",
       " 23.85475516162411,\n",
       " 23.557442951681942,\n",
       " 47.11206157732929,\n",
       " 35.54370775203017,\n",
       " 29.05777717409953,\n",
       " 24.015887314027246,\n",
       " 26.48076442343294,\n",
       " 22.79982154966065,\n",
       " 26.483142283341632,\n",
       " 30.766771703434454,\n",
       " 27.095791830675648,\n",
       " 28.138061457861053,\n",
       " 28.926488301230215,\n",
       " 26.34947555056363,\n",
       " 34.4792877702547,\n",
       " 33.61117718792209,\n",
       " 39.44594220894935,\n",
       " 39.87649378707678,\n",
       " 21.641430634885847,\n",
       " 31.793344964352045,\n",
       " 23.274919675965396,\n",
       " 24.06900306451769,\n",
       " 21.686434758295544,\n",
       " 45.61347571327273,\n",
       " 34.72734291091491,\n",
       " 30.5563630381561,\n",
       " 27.299507124456884,\n",
       " 31.65033016024832,\n",
       " 32.77262285451792,\n",
       " 27.979350287489513,\n",
       " 40.37181257552675,\n",
       " 25.934707744401226,\n",
       " 22.77960088751544,\n",
       " 33.51428599226391,\n",
       " 32.970125416894284,\n",
       " 28.461486523239422,\n",
       " 25.979711867810924,\n",
       " 30.504824671129466,\n",
       " 33.40790146922635,\n",
       " 33.29350821187242,\n",
       " 30.549828794539163,\n",
       " 23.954683486900908,\n",
       " 29.736921596467543,\n",
       " 33.87312422022708,\n",
       " 31.004824671129466,\n",
       " 34.24123480255969,\n",
       " 34.12684154520576,\n",
       " 31.049828794539163,\n",
       " 30.070254929800875,\n",
       " 33.373124220227076,\n",
       " 32.2352644661819,\n",
       " 38.28638956381488,\n",
       " 34.81074964303951,\n",
       " 34.696356385685576,\n",
       " 30.639769770280694,\n",
       " 28.020130756113094,\n",
       " 30.46525092111106,\n",
       " 28.011943319187008,\n",
       " 28.218883223904328,\n",
       " 35.52120591340705,\n",
       " 35.40681265605311,\n",
       " 32.32979990538652,\n",
       " 26.14538683888796,\n",
       " 25.78855081942198,\n",
       " 31.35022604064823,\n",
       " 40.05952513816069,\n",
       " 39.26291085786544,\n",
       " 28.888167217959413,\n",
       " 32.40692789356339,\n",
       " 30.2489302141233,\n",
       " 26.444922417955564,\n",
       " 29.66324847623013,\n",
       " 33.6526414759364,\n",
       " 31.59341799775276,\n",
       " 31.479024740398824,\n",
       " 28.735345323065566,\n",
       " 27.92243812499395,\n",
       " 31.22530741542015,\n",
       " 31.010334888494356,\n",
       " 46.49847864811795,\n",
       " 36.15729068124151,\n",
       " 29.671360103310874,\n",
       " 26.41450418961166,\n",
       " 27.094347352644288,\n",
       " 26.300110932257727,\n",
       " 27.680029090537456,\n",
       " 38.44654601675019,\n",
       " 38.56093927410412,\n",
       " 34.536199932750264,\n",
       " 33.223292734678644,\n",
       " 30.386753082015982,\n",
       " 27.8517868662517,\n",
       " 29.590138801720737,\n",
       " 36.65260946969148,\n",
       " 28.22533942166508,\n",
       " 30.961749553095295,\n",
       " 35.85599518939623,\n",
       " 30.847356295741363,\n",
       " 28.270343545074777,\n",
       " 23.708598236644857,\n",
       " 48.13257770689441,\n",
       " 35.487198427427764,\n",
       " 22.995371184462137,\n",
       " 20.651332733664635,\n",
       " 29.941815041888834,\n",
       " 32.461627927707326,\n",
       " 22.19875690416689,\n",
       " 36.684346147542335,\n",
       " 36.05671326790758,\n",
       " 36.72935027095203,\n",
       " 28.193602743814214,\n",
       " 25.750357943810364,\n",
       " 31.711214545979136,\n",
       " 32.38385154902359,\n",
       " 46.1799695930026,\n",
       " 37.43980654131958,\n",
       " 38.987732426615494,\n",
       " 31.894423155780643,\n",
       " 29.667646079546106,\n",
       " 31.533491971743594,\n",
       " 28.048924433852203,\n",
       " 26.86034353096717,\n",
       " 33.7672847757854,\n",
       " 34.43992177882985,\n",
       " 29.394538393290922,\n",
       " 25.64427776660057,\n",
       " 26.063729250671923,\n",
       " 19.621177178358355,\n",
       " 41.318094235420816,\n",
       " 32.839381622620834,\n",
       " 32.92893551640688,\n",
       " 24.988426084507157,\n",
       " 22.604705094027125,\n",
       " 32.25629851336243,\n",
       " 28.916770127811773,\n",
       " 28.537392279019677,\n",
       " 30.486772150051507,\n",
       " 31.15940915309596,\n",
       " 26.375930529461794,\n",
       " 22.79958696964919,\n",
       " 24.44620431214323,\n",
       " 35.54394233204163,\n",
       " 40.47953990201665,\n",
       " 39.8069028989722,\n",
       " 33.76748984981106,\n",
       " 35.947999065918424,\n",
       " 30.701409103865394,\n",
       " 29.75532446121594,\n",
       " 33.40655866577401,\n",
       " 46.18642579076335,\n",
       " 38.981276228854746,\n",
       " 24.941523100593194,\n",
       " 31.527035773982846,\n",
       " 34.407779843838384,\n",
       " 29.362396458299454,\n",
       " 25.612135831609105,\n",
       " 38.351012814209,\n",
       " 38.3960169376187,\n",
       " 35.22337993457425,\n",
       " 33.217184882356925,\n",
       " 27.955507505718973,\n",
       " 25.571786515238937,\n",
       " 31.211214545979136,\n",
       " 41.1799695930026,\n",
       " 39.10647320798624,\n",
       " 37.32106575994884,\n",
       " 32.39442315578064,\n",
       " 30.00097941287944,\n",
       " 31.200158638410265,\n",
       " 28.382257767185532,\n",
       " 27.09843876906241,\n",
       " 35.273255112163184,\n",
       " 29.72787172662425,\n",
       " 25.88237300469581,\n",
       " 26.301824488767164,\n",
       " 19.73228828946947,\n",
       " 33.2672847757854,\n",
       " 46.318094235420816,\n",
       " 33.76226884974022,\n",
       " 31.75629851336243,\n",
       " 29.416770127811773,\n",
       " 24.809854655935734,\n",
       " 22.465816205138236,\n",
       " 27.91079979143399,\n",
       " 28.870725612353006,\n",
       " 31.659409153095964,\n",
       " 26.614025767557035,\n",
       " 22.978158398220618,\n",
       " 24.624775740714657,\n",
       " 30.15343881671818,\n",
       " 31.773802410449896,\n",
       " 45.47953990201665,\n",
       " 38.14023623230553,\n",
       " 34.60082318314439,\n",
       " 35.11466573258509,\n",
       " 30.368075770532066,\n",
       " 30.25532446121594,\n",
       " 32.90655866577401,\n",
       " 41.18642579076336,\n",
       " 25.120094529164618,\n",
       " 37.31460956218808,\n",
       " 35.24111317717171,\n",
       " 29.695729791632782,\n",
       " 25.850231069704343,\n",
       " 24.32348024886937,\n",
       " 33.898404700317194,\n",
       " 39.67598804846605,\n",
       " 31.824908315300824,\n",
       " 31.206167533930085,\n",
       " 34.49715599320428,\n",
       " 33.94340882372689,\n",
       " 24.647985948765456,\n",
       " 32.71333699508115,\n",
       " 35.842769952643,\n",
       " 31.497271230714556,\n",
       " 31.916722714785905,\n",
       " 23.62531240821321,\n",
       " 29.158356886144436,\n",
       " 30.28997048361851,\n",
       " 45.16549628568259,\n",
       " 34.91486679947844,\n",
       " 30.569368077549992,\n",
       " 32.908896463100646,\n",
       " 25.91389652133989,\n",
       " 29.063397741172206,\n",
       " 28.437123658473887,\n",
       " 34.98562383837176,\n",
       " 32.228923993575776,\n",
       " 28.3311518623346,\n",
       " 29.97776920482864,\n",
       " 26.04451092707722,\n",
       " 32.343317250929715,\n",
       " 27.72106936003267,\n",
       " 46.04905474249646,\n",
       " 37.53688935390135,\n",
       " 34.03130834266457,\n",
       " 31.214751131024585,\n",
       " 32.02533800628678,\n",
       " 27.543771258265775,\n",
       " 25.123898272269777,\n",
       " 30.4730879932786,\n",
       " 33.90486089807794,\n",
       " 29.93769963289253,\n",
       " 29.676473712983352,\n",
       " 25.544132838587192,\n",
       " 33.94986502148764,\n",
       " 29.126214951152967,\n",
       " 24.729163988503934,\n",
       " 36.55322622301054,\n",
       " 35.826902008402335,\n",
       " 31.98731366493804,\n",
       " 27.203835041303872,\n",
       " 23.513098224137337,\n",
       " 23.93254970820869,\n",
       " 37.698819454862345,\n",
       " 35.625323069845976,\n",
       " 22.857246542043924,\n",
       " 30.476327402515075,\n",
       " 34.6732489551419,\n",
       " 35.04223996058758,\n",
       " 20.53375015702756,\n",
       " 26.346688927032627,\n",
       " 32.93938026394332,\n",
       " 32.75800088481648,\n",
       " 28.873467705870823,\n",
       " 24.24475098699856,\n",
       " 20.708089966868496,\n",
       " 22.354707309362535,\n",
       " 46.759511012864,\n",
       " 36.86026512145818,\n",
       " 33.83469462173773,\n",
       " 30.953950551882194,\n",
       " 31.314881735919244,\n",
       " 33.15401721775721,\n",
       " 28.789311236198806,\n",
       " 45.93388434274655,\n",
       " 39.233817676871546,\n",
       " 34.66032129185518,\n",
       " 22.8500260978125,\n",
       " 33.97964388787465,\n",
       " 20.776529712796126,\n",
       " 29.913731329802157,\n",
       " 29.246255573869337,\n",
       " 28.44964129357409,\n",
       " 32.62543830735625,\n",
       " 27.572638838331766,\n",
       " 25.09086418290327,\n",
       " 35.131693317487205,\n",
       " 26.890417815390453,\n",
       " 45.8970099166419,\n",
       " 36.758759412717566,\n",
       " 24.434324694419402,\n",
       " 30.272828834786928,\n",
       " 22.0902862436219,\n",
       " 26.22894266068933,\n",
       " 26.90157966373378,\n",
       " 39.59295958370761,\n",
       " 32.076879167721216,\n",
       " 32.87349344801646,\n",
       " 34.293138984083036,\n",
       " 32.19127242507515,\n",
       " 29.333199750387955,\n",
       " 30.129814030683203,\n",
       " 46.39232870509186,\n",
       " 24.735620186264683,\n",
       " 23.939005905969438,\n",
       " 31.99376986269879,\n",
       " 27.20287515557907,\n",
       " 24.78062430967438,\n",
       " 20.31808535045082,\n",
       " 31.185209083826607,\n",
       " 29.344925681622364,\n",
       " 28.761842572363964,\n",
       " 25.030737107789456,\n",
       " 26.677354450283495,\n",
       " 28.10086010714934,\n",
       " 29.459318938976295,\n",
       " 38.665056430543046,\n",
       " 38.08197332128465,\n",
       " 35.4924194274986,\n",
       " 32.90314126602288,\n",
       " 32.80018226111149,\n",
       " 28.315497060963228,\n",
       " 27.74766970981277,\n",
       " 37.705275652623094,\n",
       " 27.172673238733456,\n",
       " 32.59329637236478,\n",
       " 34.666792757381145,\n",
       " 30.482783600275823,\n",
       " 26.637284878347383,\n",
       " 26.37605895843821,\n",
       " 35.14578029130706,\n",
       " 35.69072512678844,\n",
       " 35.260173548661,\n",
       " 32.06876754064047,\n",
       " 31.557571193830526,\n",
       " 30.137925657763947,\n",
       " 28.514558785144285,\n",
       " 39.15676091483935,\n",
       " 34.18517707758168,\n",
       " 22.361163507123283,\n",
       " 26.353145124793375,\n",
       " 28.994317160985506,\n",
       " 29.42486873911295,\n",
       " 24.788735936755124,\n",
       " 36.866721319218925,\n",
       " 39.560817648716146,\n",
       " 22.288485295715425,\n",
       " 33.828238423976984,\n",
       " 36.1860439152384,\n",
       " 36.194084316174475,\n",
       " 21.49187101542018]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = np.full((462,11), -1)\n",
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for path in input_list:\n",
    "    for i in range(len(path)):\n",
    "        X_input[n][i] = path[i]\n",
    "    n =n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  1, ..., -1, -1, -1],\n",
       "       [ 0, 10,  1, ..., -1, -1, -1],\n",
       "       [ 0,  2,  9, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [10,  1,  7, ..., -1, -1, -1],\n",
       "       [10,  6,  3, ..., -1, -1, -1],\n",
       "       [10,  4,  8, ..., 11, -1, -1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_input,Y_output, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_B=int(math.sqrt(len(X_train)))\n",
    "n_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = n_B, max_samples=n_B, max_features=\"auto\", random_state = 42)\n",
    "rf.fit(X_train, Y_train);\n",
    "predictions = rf.predict(X_test)\n",
    "predictions=np.round(predictions,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6810344827586207"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error= predictions==Y_test\n",
    "np.sum(error)/len(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for different number of trees in random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_values=[]\n",
    "acc_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(int(math.sqrt(n_B)),20*n_B, 2):\n",
    "    rf = RandomForestRegressor(n_estimators =n ,max_features=\"auto\", random_state = 42)\n",
    "    rf.fit(X_train, Y_train);\n",
    "    predictions = rf.predict(X_test)\n",
    "    predictions=np.round(predictions,0)\n",
    "    acc_values.append(np.sum(predictions==Y_test)/len(Y_test))\n",
    "    B_values.append(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f71f79922d0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(B_values,acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_treeN=[x for (x,y) in zip(B_values,acc_values) if y==max(acc_values)][0]\n",
    "best_treeN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for different depths of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth_values=[]\n",
    "acc_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,12):\n",
    "    rf = RandomForestRegressor(n_estimators =best_treeN ,max_depth=n,max_samples=n,max_features=\"auto\", random_state = 42)\n",
    "    rf.fit(X_train, Y_train);\n",
    "    predictions = rf.predict(X_test)\n",
    "    predictions=np.round(predictions,0)\n",
    "    acc_values.append(np.sum(predictions==Y_test)/len(Y_test))\n",
    "    Depth_values.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f71f6d79490>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(Depth_values,acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_depth=[x for (x,y) in zip(Depth_values,acc_values) if y==max(acc_values)][0]\n",
    "best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5431034482758621"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for different sizes of samples to draw from X to train each base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1_values=[]\n",
    "acc_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(int(math.sqrt(n_B)),len(X_train)):\n",
    "    rf = RandomForestRegressor(n_estimators =best_treeN,max_depth=best_depth,max_samples=n, bootstrap=True,max_features=\"auto\", random_state = 42)\n",
    "    rf.fit(X_train, Y_train);\n",
    "    predictions = rf.predict(X_test)\n",
    "    predictions=np.round(predictions,0)\n",
    "    acc_values.append(np.sum(predictions==Y_test)/len(Y_test))\n",
    "    B1_values.append(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f71f6d0b9d0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(B1_values,acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bootstrap=[x for (x,y) in zip(B1_values,acc_values) if y==max(acc_values)][0]\n",
    "best_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189655172413793"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_values[315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362068965517241"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_values[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bootstrap=acc_values[106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  1, ..., -1, -1, -1],\n",
       "       [ 0, 10,  1, ..., -1, -1, -1],\n",
       "       [ 0,  2,  9, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [10,  1,  7, ..., -1, -1, -1],\n",
       "       [10,  6,  3, ..., -1, -1, -1],\n",
       "       [10,  4,  8, ..., 11, -1, -1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 2., 2., 1., 0., 0., 3., 2., 2., 0., 1., 0., 0., 2., 3., 2.,\n",
       "       0., 1., 3., 2., 2., 3., 2., 2., 3., 2., 1., 3., 3., 2., 1., 1., 0.,\n",
       "       0., 1., 3., 3., 1., 1., 2., 2., 3., 3., 3., 0., 2., 2., 1., 3., 2.,\n",
       "       2., 1., 2., 1., 0., 3., 2., 2., 1., 1., 2., 0., 3., 3., 3., 1., 1.,\n",
       "       1., 0., 2., 1., 2., 1., 2., 1., 0., 3., 3., 2., 0., 2., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 3., 1., 0., 1., 2., 1., 3., 3., 3., 1., 0., 2.,\n",
       "       3., 1., 1., 0., 0., 1., 2., 1., 0., 0., 3., 3., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 3., 2., 3., 3., 0., 2., 0., 0., 0., 3., 3., 1.,\n",
       "       0., 2., 2., 1., 3., 0., 0., 2., 2., 1., 0., 1., 2., 2., 1., 0., 1.,\n",
       "       2., 2., 2., 2., 2., 1., 2., 2., 3., 3., 3., 1., 1., 1., 1., 1., 3.,\n",
       "       3., 2., 0., 0., 2., 3., 3., 1., 2., 1., 0., 1., 2., 2., 2., 1., 1.,\n",
       "       2., 2., 3., 3., 1., 0., 0., 0., 0., 3., 3., 3., 2., 1., 1., 1., 3.,\n",
       "       1., 2., 3., 1., 1., 0., 3., 3., 0., 0., 1., 2., 0., 3., 3., 3., 1.,\n",
       "       0., 2., 2., 3., 3., 3., 2., 1., 2., 1., 0., 2., 3., 1., 0., 0., 0.,\n",
       "       3., 2., 2., 0., 0., 2., 1., 1., 1., 2., 0., 0., 0., 3., 3., 3., 2.,\n",
       "       3., 1., 1., 2., 3., 3., 0., 2., 2., 1., 0., 3., 3., 3., 2., 1., 0.,\n",
       "       2., 3., 3., 3., 2., 1., 2., 1., 0., 3., 1., 0., 0., 0., 2., 3., 2.,\n",
       "       2., 1., 0., 0., 1., 1., 2., 0., 0., 0., 1., 2., 3., 3., 3., 3., 1.,\n",
       "       1., 2., 3., 0., 3., 3., 1., 0., 0., 2., 3., 2., 2., 3., 2., 0., 2.,\n",
       "       3., 2., 2., 0., 1., 1., 3., 3., 1., 2., 0., 1., 1., 3., 2., 1., 1.,\n",
       "       0., 2., 1., 3., 3., 2., 2., 2., 0., 0., 1., 2., 1., 1., 0., 2., 1.,\n",
       "       0., 3., 3., 2., 0., 0., 0., 3., 3., 0., 1., 3., 3., 0., 0., 2., 2.,\n",
       "       1., 0., 0., 0., 3., 3., 2., 1., 2., 2., 1., 3., 3., 3., 0., 2., 0.,\n",
       "       1., 1., 1., 2., 0., 0., 3., 0., 3., 3., 0., 1., 0., 0., 0., 3., 2.,\n",
       "       2., 2., 2., 1., 1., 3., 0., 0., 2., 0., 0., 0., 2., 1., 1., 0., 0.,\n",
       "       1., 1., 3., 3., 3., 2., 2., 1., 1., 3., 0., 2., 3., 1., 0., 0., 3.,\n",
       "       3., 3., 2., 2., 1., 1., 3., 2., 0., 0., 1., 1., 0., 3., 3., 0., 2.,\n",
       "       3., 3., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_s = np.zeros((462,4))\n",
    "for i in range(Y_output.shape[0]):\n",
    "    if Y_output[i] == 0 : Y_output_s[i][0] = 1\n",
    "    elif Y_output[i] == 1 : Y_output_s[i][1] = 1\n",
    "    elif Y_output[i] == 2 : Y_output_s[i][2] = 1\n",
    "    else : Y_output_s[i][3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_output_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_input,Y_output_s, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 164\n",
      "Trainable params: 164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 11, activation = 'sigmoid'))\n",
    "model.add(Dense(4, activation ='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 10\n",
    "callback_early_stopping =EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.8861 - accuracy: 0.2211 - val_loss: 1.6298 - val_accuracy: 0.2885\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 1.7097 - accuracy: 0.2449 - val_loss: 1.4949 - val_accuracy: 0.3462\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 1.5674 - accuracy: 0.2585 - val_loss: 1.3904 - val_accuracy: 0.3462\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 1.4529 - accuracy: 0.2687 - val_loss: 1.3147 - val_accuracy: 0.3269\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 1.3660 - accuracy: 0.2959 - val_loss: 1.2596 - val_accuracy: 0.3462\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 1.3009 - accuracy: 0.3503 - val_loss: 1.2175 - val_accuracy: 0.3462\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 1.2495 - accuracy: 0.3946 - val_loss: 1.1856 - val_accuracy: 0.3846\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 1.2070 - accuracy: 0.4558 - val_loss: 1.1600 - val_accuracy: 0.4615\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 1.1700 - accuracy: 0.4932 - val_loss: 1.1332 - val_accuracy: 0.5385\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 1.1333 - accuracy: 0.5510 - val_loss: 1.1074 - val_accuracy: 0.5962\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 811us/step - loss: 1.0988 - accuracy: 0.5952 - val_loss: 1.0835 - val_accuracy: 0.5962\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 1.0645 - accuracy: 0.5986 - val_loss: 1.0592 - val_accuracy: 0.5769\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 1.0326 - accuracy: 0.6293 - val_loss: 1.0335 - val_accuracy: 0.6154\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 1.0034 - accuracy: 0.6531 - val_loss: 1.0090 - val_accuracy: 0.5962\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.9750 - accuracy: 0.6599 - val_loss: 0.9854 - val_accuracy: 0.5962\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.9499 - accuracy: 0.6769 - val_loss: 0.9604 - val_accuracy: 0.6346\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 648us/step - loss: 0.9259 - accuracy: 0.6871 - val_loss: 0.9417 - val_accuracy: 0.6154\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 713us/step - loss: 0.9050 - accuracy: 0.6939 - val_loss: 0.9211 - val_accuracy: 0.6346\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 726us/step - loss: 0.8844 - accuracy: 0.6973 - val_loss: 0.9014 - val_accuracy: 0.6538\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 857us/step - loss: 0.8666 - accuracy: 0.7007 - val_loss: 0.8843 - val_accuracy: 0.6538\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 658us/step - loss: 0.8492 - accuracy: 0.7041 - val_loss: 0.8687 - val_accuracy: 0.6731\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 788us/step - loss: 0.8333 - accuracy: 0.7109 - val_loss: 0.8489 - val_accuracy: 0.7115\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 593us/step - loss: 0.8195 - accuracy: 0.7177 - val_loss: 0.8368 - val_accuracy: 0.7115\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.8048 - accuracy: 0.7211 - val_loss: 0.8187 - val_accuracy: 0.7115\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.7919 - accuracy: 0.7279 - val_loss: 0.8054 - val_accuracy: 0.7308\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.7805 - accuracy: 0.7347 - val_loss: 0.7896 - val_accuracy: 0.7308\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.7680 - accuracy: 0.7415 - val_loss: 0.7772 - val_accuracy: 0.7308\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 750us/step - loss: 0.7568 - accuracy: 0.7381 - val_loss: 0.7661 - val_accuracy: 0.7308\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 743us/step - loss: 0.7467 - accuracy: 0.7517 - val_loss: 0.7522 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.7363 - accuracy: 0.7585 - val_loss: 0.7416 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 716us/step - loss: 0.7264 - accuracy: 0.7551 - val_loss: 0.7280 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.7181 - accuracy: 0.7517 - val_loss: 0.7204 - val_accuracy: 0.7692\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 700us/step - loss: 0.7073 - accuracy: 0.7551 - val_loss: 0.7097 - val_accuracy: 0.7692\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 635us/step - loss: 0.6981 - accuracy: 0.7551 - val_loss: 0.6939 - val_accuracy: 0.7692\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 798us/step - loss: 0.6888 - accuracy: 0.7517 - val_loss: 0.6856 - val_accuracy: 0.7692\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 884us/step - loss: 0.6812 - accuracy: 0.7517 - val_loss: 0.6778 - val_accuracy: 0.7692\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.6734 - accuracy: 0.7551 - val_loss: 0.6700 - val_accuracy: 0.7692\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.6661 - accuracy: 0.7517 - val_loss: 0.6605 - val_accuracy: 0.7692\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.6593 - accuracy: 0.7551 - val_loss: 0.6552 - val_accuracy: 0.7692\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.6529 - accuracy: 0.7551 - val_loss: 0.6497 - val_accuracy: 0.7692\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6537 - accuracy: 0.75 - 0s 478us/step - loss: 0.6474 - accuracy: 0.7551 - val_loss: 0.6439 - val_accuracy: 0.7692\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.6414 - accuracy: 0.7585 - val_loss: 0.6371 - val_accuracy: 0.7692\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.6365 - accuracy: 0.7619 - val_loss: 0.6351 - val_accuracy: 0.7692\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 749us/step - loss: 0.6314 - accuracy: 0.7585 - val_loss: 0.6258 - val_accuracy: 0.7692\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.6269 - accuracy: 0.7551 - val_loss: 0.6216 - val_accuracy: 0.7692\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.6226 - accuracy: 0.7585 - val_loss: 0.6156 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.6181 - accuracy: 0.7585 - val_loss: 0.6092 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.6141 - accuracy: 0.7585 - val_loss: 0.6051 - val_accuracy: 0.7885\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.6105 - accuracy: 0.7551 - val_loss: 0.5996 - val_accuracy: 0.7885\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 628us/step - loss: 0.6058 - accuracy: 0.7551 - val_loss: 0.5994 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.6029 - accuracy: 0.7653 - val_loss: 0.5954 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5997 - accuracy: 0.7619 - val_loss: 0.5915 - val_accuracy: 0.7885\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5964 - accuracy: 0.7721 - val_loss: 0.5854 - val_accuracy: 0.7885\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5934 - accuracy: 0.7721 - val_loss: 0.5800 - val_accuracy: 0.7885\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.5899 - accuracy: 0.7755 - val_loss: 0.5801 - val_accuracy: 0.7885\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 531us/step - loss: 0.5869 - accuracy: 0.7687 - val_loss: 0.5722 - val_accuracy: 0.7885\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5839 - accuracy: 0.7755 - val_loss: 0.5710 - val_accuracy: 0.7885\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5813 - accuracy: 0.7755 - val_loss: 0.5694 - val_accuracy: 0.7885\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5784 - accuracy: 0.7755 - val_loss: 0.5611 - val_accuracy: 0.7885\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5759 - accuracy: 0.7721 - val_loss: 0.5599 - val_accuracy: 0.7885\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5728 - accuracy: 0.7721 - val_loss: 0.5610 - val_accuracy: 0.7885\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5701 - accuracy: 0.7857 - val_loss: 0.5616 - val_accuracy: 0.8077\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5678 - accuracy: 0.7789 - val_loss: 0.5575 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5657 - accuracy: 0.7823 - val_loss: 0.5529 - val_accuracy: 0.7885\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.5633 - accuracy: 0.7789 - val_loss: 0.5524 - val_accuracy: 0.7885\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5604 - accuracy: 0.7721 - val_loss: 0.5490 - val_accuracy: 0.7885\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5585 - accuracy: 0.7823 - val_loss: 0.5453 - val_accuracy: 0.8077\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.5566 - accuracy: 0.7721 - val_loss: 0.5427 - val_accuracy: 0.8077\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.5542 - accuracy: 0.7823 - val_loss: 0.5429 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5515 - accuracy: 0.7857 - val_loss: 0.5402 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5494 - accuracy: 0.7823 - val_loss: 0.5375 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5497 - accuracy: 0.7857 - val_loss: 0.5373 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5462 - accuracy: 0.7823 - val_loss: 0.5342 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.5440 - accuracy: 0.7823 - val_loss: 0.5337 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5426 - accuracy: 0.7823 - val_loss: 0.5320 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5413 - accuracy: 0.7823 - val_loss: 0.5308 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5394 - accuracy: 0.7823 - val_loss: 0.5291 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 705us/step - loss: 0.5381 - accuracy: 0.7823 - val_loss: 0.5244 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5363 - accuracy: 0.7823 - val_loss: 0.5230 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5341 - accuracy: 0.7857 - val_loss: 0.5252 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.5346 - accuracy: 0.7857 - val_loss: 0.5273 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.5315 - accuracy: 0.7857 - val_loss: 0.5211 - val_accuracy: 0.8654\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.5306 - accuracy: 0.7857 - val_loss: 0.5220 - val_accuracy: 0.8654\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5296 - accuracy: 0.7857 - val_loss: 0.5221 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5278 - accuracy: 0.7857 - val_loss: 0.5204 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5261 - accuracy: 0.7857 - val_loss: 0.5202 - val_accuracy: 0.8654\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5245 - accuracy: 0.7857 - val_loss: 0.5166 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.5236 - accuracy: 0.7857 - val_loss: 0.5157 - val_accuracy: 0.8654\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5220 - accuracy: 0.7857 - val_loss: 0.5175 - val_accuracy: 0.8654\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.5208 - accuracy: 0.7857 - val_loss: 0.5181 - val_accuracy: 0.8654\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.5203 - accuracy: 0.7857 - val_loss: 0.5157 - val_accuracy: 0.8654\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.5185 - accuracy: 0.7857 - val_loss: 0.5155 - val_accuracy: 0.8654\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5196 - accuracy: 0.7823 - val_loss: 0.5119 - val_accuracy: 0.8654\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.5163 - accuracy: 0.7857 - val_loss: 0.5121 - val_accuracy: 0.8654\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.5156 - accuracy: 0.7857 - val_loss: 0.5129 - val_accuracy: 0.8654\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5142 - accuracy: 0.7857 - val_loss: 0.5110 - val_accuracy: 0.8654\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.5133 - accuracy: 0.7925 - val_loss: 0.5056 - val_accuracy: 0.8654\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 761us/step - loss: 0.5131 - accuracy: 0.7925 - val_loss: 0.5064 - val_accuracy: 0.8654\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5118 - accuracy: 0.7857 - val_loss: 0.5065 - val_accuracy: 0.8654\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.5107 - accuracy: 0.7959 - val_loss: 0.5038 - val_accuracy: 0.8654\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5087 - accuracy: 0.7925 - val_loss: 0.5040 - val_accuracy: 0.8654\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 237us/step - loss: 0.5083 - accuracy: 0.7891 - val_loss: 0.5048 - val_accuracy: 0.8654\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5099 - accuracy: 0.7857 - val_loss: 0.5054 - val_accuracy: 0.8654\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5054 - accuracy: 0.7925 - val_loss: 0.5000 - val_accuracy: 0.8654\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.5056 - accuracy: 0.7959 - val_loss: 0.4981 - val_accuracy: 0.8654\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5048 - accuracy: 0.7959 - val_loss: 0.5014 - val_accuracy: 0.8654\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5035 - accuracy: 0.7925 - val_loss: 0.5018 - val_accuracy: 0.8654\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5035 - accuracy: 0.7959 - val_loss: 0.5015 - val_accuracy: 0.8654\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5027 - accuracy: 0.7925 - val_loss: 0.5035 - val_accuracy: 0.8654\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5017 - accuracy: 0.7925 - val_loss: 0.4979 - val_accuracy: 0.8654\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5005 - accuracy: 0.7959 - val_loss: 0.4978 - val_accuracy: 0.8654\n",
      "Epoch 112/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 439us/step - loss: 0.4996 - accuracy: 0.7959 - val_loss: 0.4999 - val_accuracy: 0.8654\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.4991 - accuracy: 0.7959 - val_loss: 0.5012 - val_accuracy: 0.8654\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4980 - accuracy: 0.7925 - val_loss: 0.5022 - val_accuracy: 0.8654\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4973 - accuracy: 0.7959 - val_loss: 0.4986 - val_accuracy: 0.8846\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.4971 - accuracy: 0.8027 - val_loss: 0.4975 - val_accuracy: 0.8846\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4960 - accuracy: 0.7925 - val_loss: 0.4988 - val_accuracy: 0.8846\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.4947 - accuracy: 0.7925 - val_loss: 0.4959 - val_accuracy: 0.8846\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.4942 - accuracy: 0.7959 - val_loss: 0.4960 - val_accuracy: 0.8846\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.79 - 0s 506us/step - loss: 0.4934 - accuracy: 0.7959 - val_loss: 0.4975 - val_accuracy: 0.8654\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.4937 - accuracy: 0.7993 - val_loss: 0.4926 - val_accuracy: 0.8846\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4920 - accuracy: 0.8027 - val_loss: 0.4964 - val_accuracy: 0.8846\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4925 - accuracy: 0.7993 - val_loss: 0.4943 - val_accuracy: 0.8846\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.4905 - accuracy: 0.7959 - val_loss: 0.4967 - val_accuracy: 0.8846\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4907 - accuracy: 0.7993 - val_loss: 0.4957 - val_accuracy: 0.8654\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4891 - accuracy: 0.7993 - val_loss: 0.4934 - val_accuracy: 0.8846\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.4887 - accuracy: 0.7993 - val_loss: 0.4957 - val_accuracy: 0.8846\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4883 - accuracy: 0.7993 - val_loss: 0.4956 - val_accuracy: 0.8846\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4879 - accuracy: 0.7959 - val_loss: 0.4944 - val_accuracy: 0.8846\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4870 - accuracy: 0.7959 - val_loss: 0.4989 - val_accuracy: 0.8846\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4860 - accuracy: 0.7959 - val_loss: 0.4959 - val_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size = 10, epochs = 150, validation_split= 0.15, verbose = 1, \n",
    "         callbacks = [callback_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 441us/step\n"
     ]
    }
   ],
   "source": [
    "y_test,accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.34\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accurancy for different number of neurons in one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_opt_1 = int(math.sqrt(X_input[0].shape[0] * Y_output_s[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_opt_2 = int(X_input[0].shape[0]/2 + Y_output_s[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_opt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_opt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 10\n",
    "callback_early_stopping =EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "\n",
    "history_all = []\n",
    "accuracy_all = []\n",
    "n_value = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5826 - accuracy: 0.1156 - val_loss: 1.6327 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 729us/step - loss: 1.5314 - accuracy: 0.1327 - val_loss: 1.5689 - val_accuracy: 0.0769\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 1.4818 - accuracy: 0.1224 - val_loss: 1.5111 - val_accuracy: 0.0577\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 1.4352 - accuracy: 0.1395 - val_loss: 1.4540 - val_accuracy: 0.1346\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 602us/step - loss: 1.3888 - accuracy: 0.2279 - val_loss: 1.4098 - val_accuracy: 0.2308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 1.3543 - accuracy: 0.3061 - val_loss: 1.3754 - val_accuracy: 0.2692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 1.3323 - accuracy: 0.3469 - val_loss: 1.3540 - val_accuracy: 0.3462\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 567us/step - loss: 1.3177 - accuracy: 0.3946 - val_loss: 1.3372 - val_accuracy: 0.3846\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 1.3070 - accuracy: 0.4218 - val_loss: 1.3230 - val_accuracy: 0.4231\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 1.2966 - accuracy: 0.4354 - val_loss: 1.3117 - val_accuracy: 0.4615\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 1.2863 - accuracy: 0.4558 - val_loss: 1.2991 - val_accuracy: 0.4231\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 1.2759 - accuracy: 0.4728 - val_loss: 1.2870 - val_accuracy: 0.4615\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 1.2640 - accuracy: 0.4864 - val_loss: 1.2732 - val_accuracy: 0.5000\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 1.2523 - accuracy: 0.5170 - val_loss: 1.2578 - val_accuracy: 0.5192\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 599us/step - loss: 1.2383 - accuracy: 0.5578 - val_loss: 1.2441 - val_accuracy: 0.5577\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 731us/step - loss: 1.2232 - accuracy: 0.5646 - val_loss: 1.2294 - val_accuracy: 0.5769\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 1.2064 - accuracy: 0.5986 - val_loss: 1.2155 - val_accuracy: 0.5962\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 1.1897 - accuracy: 0.6156 - val_loss: 1.2010 - val_accuracy: 0.6346\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 653us/step - loss: 1.1715 - accuracy: 0.6497 - val_loss: 1.1858 - val_accuracy: 0.6346\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 1.1538 - accuracy: 0.6599 - val_loss: 1.1712 - val_accuracy: 0.6346\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 716us/step - loss: 1.1353 - accuracy: 0.6735 - val_loss: 1.1552 - val_accuracy: 0.6538\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 600us/step - loss: 1.1172 - accuracy: 0.6837 - val_loss: 1.1403 - val_accuracy: 0.6731\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 1.0989 - accuracy: 0.6905 - val_loss: 1.1251 - val_accuracy: 0.6538\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 1.0814 - accuracy: 0.6939 - val_loss: 1.1104 - val_accuracy: 0.6538\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 1.0639 - accuracy: 0.6973 - val_loss: 1.0948 - val_accuracy: 0.6731\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 602us/step - loss: 1.0459 - accuracy: 0.7041 - val_loss: 1.0827 - val_accuracy: 0.6731\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 1.0288 - accuracy: 0.7041 - val_loss: 1.0663 - val_accuracy: 0.6731\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 1.0126 - accuracy: 0.7109 - val_loss: 1.0528 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.9968 - accuracy: 0.7041 - val_loss: 1.0372 - val_accuracy: 0.6731\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 624us/step - loss: 0.9826 - accuracy: 0.7109 - val_loss: 1.0221 - val_accuracy: 0.6731\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.9687 - accuracy: 0.7109 - val_loss: 1.0097 - val_accuracy: 0.7115\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 795us/step - loss: 0.9556 - accuracy: 0.7075 - val_loss: 0.9972 - val_accuracy: 0.6923\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 719us/step - loss: 0.9439 - accuracy: 0.7075 - val_loss: 0.9848 - val_accuracy: 0.6923\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.9324 - accuracy: 0.7109 - val_loss: 0.9747 - val_accuracy: 0.7115\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 782us/step - loss: 0.9218 - accuracy: 0.7109 - val_loss: 0.9646 - val_accuracy: 0.7115\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.9118 - accuracy: 0.7109 - val_loss: 0.9531 - val_accuracy: 0.7115\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.9018 - accuracy: 0.7075 - val_loss: 0.9447 - val_accuracy: 0.7115\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.8930 - accuracy: 0.7041 - val_loss: 0.9356 - val_accuracy: 0.7115\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 954us/step - loss: 0.8846 - accuracy: 0.7041 - val_loss: 0.9283 - val_accuracy: 0.7308\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 854us/step - loss: 0.8760 - accuracy: 0.7143 - val_loss: 0.9191 - val_accuracy: 0.7308\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 938us/step - loss: 0.8682 - accuracy: 0.7143 - val_loss: 0.9125 - val_accuracy: 0.7308\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.8607 - accuracy: 0.7143 - val_loss: 0.9046 - val_accuracy: 0.7308\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.8531 - accuracy: 0.7211 - val_loss: 0.8979 - val_accuracy: 0.7308\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.8462 - accuracy: 0.7211 - val_loss: 0.8902 - val_accuracy: 0.7308\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.8394 - accuracy: 0.7245 - val_loss: 0.8847 - val_accuracy: 0.7308\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 773us/step - loss: 0.8327 - accuracy: 0.7245 - val_loss: 0.8779 - val_accuracy: 0.7308\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.8265 - accuracy: 0.7211 - val_loss: 0.8718 - val_accuracy: 0.7308\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.8207 - accuracy: 0.7245 - val_loss: 0.8653 - val_accuracy: 0.7308\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 784us/step - loss: 0.8152 - accuracy: 0.7211 - val_loss: 0.8610 - val_accuracy: 0.7308\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.8093 - accuracy: 0.7211 - val_loss: 0.8546 - val_accuracy: 0.7308\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.8037 - accuracy: 0.7211 - val_loss: 0.8479 - val_accuracy: 0.7308\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.7988 - accuracy: 0.7211 - val_loss: 0.8432 - val_accuracy: 0.7308\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.7931 - accuracy: 0.7279 - val_loss: 0.8378 - val_accuracy: 0.7500\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.7886 - accuracy: 0.7279 - val_loss: 0.8318 - val_accuracy: 0.7500\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.7840 - accuracy: 0.7279 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 629us/step - loss: 0.7790 - accuracy: 0.7245 - val_loss: 0.8225 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.7750 - accuracy: 0.7245 - val_loss: 0.8187 - val_accuracy: 0.7692\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.7699 - accuracy: 0.7279 - val_loss: 0.8133 - val_accuracy: 0.7692\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.7657 - accuracy: 0.7279 - val_loss: 0.8074 - val_accuracy: 0.7692\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.7614 - accuracy: 0.7279 - val_loss: 0.8066 - val_accuracy: 0.7692\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.7579 - accuracy: 0.7245 - val_loss: 0.8037 - val_accuracy: 0.7692\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.7546 - accuracy: 0.7245 - val_loss: 0.7978 - val_accuracy: 0.7692\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.7505 - accuracy: 0.7279 - val_loss: 0.7944 - val_accuracy: 0.7692\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.7462 - accuracy: 0.7347 - val_loss: 0.7910 - val_accuracy: 0.7692\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.7420 - accuracy: 0.7347 - val_loss: 0.7854 - val_accuracy: 0.7692\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.7389 - accuracy: 0.7313 - val_loss: 0.7804 - val_accuracy: 0.7500\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.7357 - accuracy: 0.7381 - val_loss: 0.7778 - val_accuracy: 0.7500\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.7318 - accuracy: 0.7415 - val_loss: 0.7737 - val_accuracy: 0.7500\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 779us/step - loss: 0.7285 - accuracy: 0.7347 - val_loss: 0.7714 - val_accuracy: 0.7500\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.7255 - accuracy: 0.7347 - val_loss: 0.7670 - val_accuracy: 0.7692\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 778us/step - loss: 0.7222 - accuracy: 0.7449 - val_loss: 0.7658 - val_accuracy: 0.7692\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.7189 - accuracy: 0.7449 - val_loss: 0.7628 - val_accuracy: 0.7692\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 816us/step - loss: 0.7166 - accuracy: 0.7381 - val_loss: 0.7601 - val_accuracy: 0.7692\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.7135 - accuracy: 0.7483 - val_loss: 0.7543 - val_accuracy: 0.7692\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.7112 - accuracy: 0.7483 - val_loss: 0.7510 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.7073 - accuracy: 0.7449 - val_loss: 0.7498 - val_accuracy: 0.7692\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.7052 - accuracy: 0.7449 - val_loss: 0.7464 - val_accuracy: 0.7692\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.7026 - accuracy: 0.7449 - val_loss: 0.7427 - val_accuracy: 0.7692\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.6997 - accuracy: 0.7483 - val_loss: 0.7398 - val_accuracy: 0.7692\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.6970 - accuracy: 0.7449 - val_loss: 0.7381 - val_accuracy: 0.7692\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.6941 - accuracy: 0.7483 - val_loss: 0.7342 - val_accuracy: 0.7692\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.6919 - accuracy: 0.7517 - val_loss: 0.7308 - val_accuracy: 0.7692\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.6903 - accuracy: 0.7585 - val_loss: 0.7289 - val_accuracy: 0.7692\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6893 - accuracy: 0.7415 - val_loss: 0.7242 - val_accuracy: 0.7692\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.6851 - accuracy: 0.7483 - val_loss: 0.7234 - val_accuracy: 0.7500\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.6828 - accuracy: 0.7517 - val_loss: 0.7216 - val_accuracy: 0.7692\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 812us/step - loss: 0.6802 - accuracy: 0.7619 - val_loss: 0.7195 - val_accuracy: 0.7692\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 754us/step - loss: 0.6780 - accuracy: 0.7619 - val_loss: 0.7167 - val_accuracy: 0.7692\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.6765 - accuracy: 0.7619 - val_loss: 0.7158 - val_accuracy: 0.7692\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 662us/step - loss: 0.6739 - accuracy: 0.7585 - val_loss: 0.7111 - val_accuracy: 0.7692\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 757us/step - loss: 0.6718 - accuracy: 0.7585 - val_loss: 0.7092 - val_accuracy: 0.7692\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.6701 - accuracy: 0.7687 - val_loss: 0.7060 - val_accuracy: 0.7885\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.6681 - accuracy: 0.7653 - val_loss: 0.7026 - val_accuracy: 0.7692\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.6661 - accuracy: 0.7653 - val_loss: 0.7016 - val_accuracy: 0.7692\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.6639 - accuracy: 0.7449 - val_loss: 0.7005 - val_accuracy: 0.8077\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.6618 - accuracy: 0.7415 - val_loss: 0.6966 - val_accuracy: 0.8077\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.6600 - accuracy: 0.7517 - val_loss: 0.6946 - val_accuracy: 0.8077\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.6583 - accuracy: 0.7483 - val_loss: 0.6953 - val_accuracy: 0.7885\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.6567 - accuracy: 0.7415 - val_loss: 0.6919 - val_accuracy: 0.8077\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6544 - accuracy: 0.7449 - val_loss: 0.6911 - val_accuracy: 0.8077\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.6531 - accuracy: 0.7517 - val_loss: 0.6888 - val_accuracy: 0.8077\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.6529 - accuracy: 0.7483 - val_loss: 0.6845 - val_accuracy: 0.8077\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.6494 - accuracy: 0.7483 - val_loss: 0.6835 - val_accuracy: 0.7885\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.6482 - accuracy: 0.7483 - val_loss: 0.6814 - val_accuracy: 0.7885\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.6461 - accuracy: 0.7551 - val_loss: 0.6822 - val_accuracy: 0.7885\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.6445 - accuracy: 0.7517 - val_loss: 0.6801 - val_accuracy: 0.7885\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 716us/step - loss: 0.6431 - accuracy: 0.7449 - val_loss: 0.6779 - val_accuracy: 0.7885\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 835us/step - loss: 0.6415 - accuracy: 0.7517 - val_loss: 0.6765 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.6394 - accuracy: 0.7517 - val_loss: 0.6736 - val_accuracy: 0.7885\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.6381 - accuracy: 0.7517 - val_loss: 0.6744 - val_accuracy: 0.7692\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.6373 - accuracy: 0.7517 - val_loss: 0.6719 - val_accuracy: 0.7885\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.6355 - accuracy: 0.7517 - val_loss: 0.6719 - val_accuracy: 0.7885\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 610us/step - loss: 0.6348 - accuracy: 0.7483 - val_loss: 0.6692 - val_accuracy: 0.8077\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.6324 - accuracy: 0.7415 - val_loss: 0.6683 - val_accuracy: 0.7885\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6309 - accuracy: 0.7517 - val_loss: 0.6672 - val_accuracy: 0.7885\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6298 - accuracy: 0.7381 - val_loss: 0.6653 - val_accuracy: 0.8077\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6286 - accuracy: 0.7415 - val_loss: 0.6631 - val_accuracy: 0.8077\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.6268 - accuracy: 0.7415 - val_loss: 0.6631 - val_accuracy: 0.8077\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.6258 - accuracy: 0.7449 - val_loss: 0.6617 - val_accuracy: 0.8077\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.6248 - accuracy: 0.7415 - val_loss: 0.6585 - val_accuracy: 0.8077\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.6226 - accuracy: 0.7449 - val_loss: 0.6601 - val_accuracy: 0.8077\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.6219 - accuracy: 0.7483 - val_loss: 0.6577 - val_accuracy: 0.8077\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.6199 - accuracy: 0.7381 - val_loss: 0.6538 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.6188 - accuracy: 0.7449 - val_loss: 0.6545 - val_accuracy: 0.8077\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.6176 - accuracy: 0.7517 - val_loss: 0.6526 - val_accuracy: 0.8269\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6167 - accuracy: 0.7415 - val_loss: 0.6520 - val_accuracy: 0.8077\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.6157 - accuracy: 0.7449 - val_loss: 0.6519 - val_accuracy: 0.8269\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.6141 - accuracy: 0.7449 - val_loss: 0.6513 - val_accuracy: 0.8269\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.6135 - accuracy: 0.7449 - val_loss: 0.6476 - val_accuracy: 0.8269\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.6117 - accuracy: 0.7483 - val_loss: 0.6485 - val_accuracy: 0.8269\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.6106 - accuracy: 0.7483 - val_loss: 0.6464 - val_accuracy: 0.8269\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.6093 - accuracy: 0.7483 - val_loss: 0.6458 - val_accuracy: 0.8269\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.6092 - accuracy: 0.7517 - val_loss: 0.6447 - val_accuracy: 0.8269\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.6072 - accuracy: 0.7483 - val_loss: 0.6451 - val_accuracy: 0.8269\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.6062 - accuracy: 0.7517 - val_loss: 0.6440 - val_accuracy: 0.8269\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.6047 - accuracy: 0.7483 - val_loss: 0.6414 - val_accuracy: 0.8269\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 652us/step - loss: 0.6039 - accuracy: 0.7449 - val_loss: 0.6409 - val_accuracy: 0.8269\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.6023 - accuracy: 0.7483 - val_loss: 0.6389 - val_accuracy: 0.8269\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.6014 - accuracy: 0.7517 - val_loss: 0.6388 - val_accuracy: 0.8269\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6003 - accuracy: 0.7517 - val_loss: 0.6376 - val_accuracy: 0.8269\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.5993 - accuracy: 0.7517 - val_loss: 0.6392 - val_accuracy: 0.8269\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5986 - accuracy: 0.7449 - val_loss: 0.6349 - val_accuracy: 0.8269\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 669us/step - loss: 0.5968 - accuracy: 0.7517 - val_loss: 0.6335 - val_accuracy: 0.8269\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 551us/step - loss: 0.5960 - accuracy: 0.7517 - val_loss: 0.6332 - val_accuracy: 0.8269\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5950 - accuracy: 0.7517 - val_loss: 0.6323 - val_accuracy: 0.8269\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.5944 - accuracy: 0.7551 - val_loss: 0.6317 - val_accuracy: 0.8269\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5948 - accuracy: 0.7483 - val_loss: 0.6310 - val_accuracy: 0.8269\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5920 - accuracy: 0.7517 - val_loss: 0.6301 - val_accuracy: 0.8269\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5911 - accuracy: 0.7585 - val_loss: 0.6285 - val_accuracy: 0.8269\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5905 - accuracy: 0.7551 - val_loss: 0.6269 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 198us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4315 - accuracy: 0.2381 - val_loss: 1.4427 - val_accuracy: 0.1731\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 1.4070 - accuracy: 0.2347 - val_loss: 1.4214 - val_accuracy: 0.1923\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 1.3872 - accuracy: 0.2687 - val_loss: 1.4027 - val_accuracy: 0.2692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 1.3685 - accuracy: 0.2891 - val_loss: 1.3858 - val_accuracy: 0.2885\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 444us/step - loss: 1.3517 - accuracy: 0.3265 - val_loss: 1.3694 - val_accuracy: 0.3077\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 1.3352 - accuracy: 0.3469 - val_loss: 1.3541 - val_accuracy: 0.2885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 1.3175 - accuracy: 0.3980 - val_loss: 1.3357 - val_accuracy: 0.3269\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 1.2976 - accuracy: 0.4218 - val_loss: 1.3179 - val_accuracy: 0.3654\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 1.2767 - accuracy: 0.4558 - val_loss: 1.2977 - val_accuracy: 0.4231\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 1.2550 - accuracy: 0.4932 - val_loss: 1.2769 - val_accuracy: 0.4231\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 1.2359 - accuracy: 0.5068 - val_loss: 1.2596 - val_accuracy: 0.4231\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 1.2179 - accuracy: 0.5408 - val_loss: 1.2451 - val_accuracy: 0.4423\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 1.2009 - accuracy: 0.5646 - val_loss: 1.2311 - val_accuracy: 0.4808\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 1.1840 - accuracy: 0.5714 - val_loss: 1.2165 - val_accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 1.1682 - accuracy: 0.5748 - val_loss: 1.2033 - val_accuracy: 0.5000\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 1.1526 - accuracy: 0.5816 - val_loss: 1.1881 - val_accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 1.1374 - accuracy: 0.5816 - val_loss: 1.1723 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 365us/step - loss: 1.1224 - accuracy: 0.5986 - val_loss: 1.1543 - val_accuracy: 0.5192\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 1.1065 - accuracy: 0.6088 - val_loss: 1.1349 - val_accuracy: 0.5577\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 1.0893 - accuracy: 0.6190 - val_loss: 1.1078 - val_accuracy: 0.6154\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 1.0706 - accuracy: 0.6361 - val_loss: 1.0851 - val_accuracy: 0.6538\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 1.0535 - accuracy: 0.6429 - val_loss: 1.0607 - val_accuracy: 0.6731\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 1.0361 - accuracy: 0.6531 - val_loss: 1.0413 - val_accuracy: 0.6731\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 1.0205 - accuracy: 0.6667 - val_loss: 1.0233 - val_accuracy: 0.6923\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 1.0066 - accuracy: 0.6701 - val_loss: 1.0059 - val_accuracy: 0.7308\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 821us/step - loss: 0.9933 - accuracy: 0.6837 - val_loss: 0.9911 - val_accuracy: 0.7308\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.9814 - accuracy: 0.6837 - val_loss: 0.9782 - val_accuracy: 0.7308\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.9701 - accuracy: 0.6837 - val_loss: 0.9635 - val_accuracy: 0.7308\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.9597 - accuracy: 0.6871 - val_loss: 0.9522 - val_accuracy: 0.7308\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.9500 - accuracy: 0.6939 - val_loss: 0.9416 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.9405 - accuracy: 0.7007 - val_loss: 0.9329 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.9313 - accuracy: 0.7075 - val_loss: 0.9210 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.9232 - accuracy: 0.7143 - val_loss: 0.9116 - val_accuracy: 0.7308\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.9152 - accuracy: 0.7143 - val_loss: 0.9053 - val_accuracy: 0.7308\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.9082 - accuracy: 0.7143 - val_loss: 0.8964 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.8998 - accuracy: 0.7177 - val_loss: 0.8892 - val_accuracy: 0.7308\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.8926 - accuracy: 0.7177 - val_loss: 0.8814 - val_accuracy: 0.7308\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.8865 - accuracy: 0.7211 - val_loss: 0.8717 - val_accuracy: 0.7308\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.8798 - accuracy: 0.7279 - val_loss: 0.8650 - val_accuracy: 0.7692\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.8728 - accuracy: 0.7245 - val_loss: 0.8587 - val_accuracy: 0.7692\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 865us/step - loss: 0.8659 - accuracy: 0.7279 - val_loss: 0.8503 - val_accuracy: 0.7692\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 830us/step - loss: 0.8599 - accuracy: 0.7347 - val_loss: 0.8422 - val_accuracy: 0.7692\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 614us/step - loss: 0.8535 - accuracy: 0.7313 - val_loss: 0.8325 - val_accuracy: 0.7692\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 709us/step - loss: 0.8477 - accuracy: 0.7415 - val_loss: 0.8267 - val_accuracy: 0.7692\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 622us/step - loss: 0.8412 - accuracy: 0.7517 - val_loss: 0.8186 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.8355 - accuracy: 0.7517 - val_loss: 0.8130 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.8299 - accuracy: 0.7551 - val_loss: 0.8075 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.8242 - accuracy: 0.7551 - val_loss: 0.7990 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 660us/step - loss: 0.8187 - accuracy: 0.7517 - val_loss: 0.7938 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 716us/step - loss: 0.8133 - accuracy: 0.7551 - val_loss: 0.7845 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.8087 - accuracy: 0.7517 - val_loss: 0.7787 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.8031 - accuracy: 0.7483 - val_loss: 0.7723 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.7981 - accuracy: 0.7551 - val_loss: 0.7696 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.7929 - accuracy: 0.7517 - val_loss: 0.7613 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.7883 - accuracy: 0.7483 - val_loss: 0.7570 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.7837 - accuracy: 0.7517 - val_loss: 0.7515 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.7792 - accuracy: 0.7483 - val_loss: 0.7479 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 0.7744 - accuracy: 0.7517 - val_loss: 0.7415 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.7702 - accuracy: 0.7517 - val_loss: 0.7351 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 765us/step - loss: 0.7655 - accuracy: 0.7585 - val_loss: 0.7317 - val_accuracy: 0.8077\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 750us/step - loss: 0.7618 - accuracy: 0.7551 - val_loss: 0.7282 - val_accuracy: 0.8077\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.7572 - accuracy: 0.7585 - val_loss: 0.7228 - val_accuracy: 0.8077\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.7534 - accuracy: 0.7653 - val_loss: 0.7189 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.7494 - accuracy: 0.7687 - val_loss: 0.7144 - val_accuracy: 0.7885\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.7451 - accuracy: 0.7721 - val_loss: 0.7079 - val_accuracy: 0.8077\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.7415 - accuracy: 0.7687 - val_loss: 0.7036 - val_accuracy: 0.8077\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 688us/step - loss: 0.7379 - accuracy: 0.7687 - val_loss: 0.6986 - val_accuracy: 0.8077\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.7346 - accuracy: 0.7687 - val_loss: 0.6988 - val_accuracy: 0.7885\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.7309 - accuracy: 0.7721 - val_loss: 0.6940 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.7272 - accuracy: 0.7755 - val_loss: 0.6893 - val_accuracy: 0.8077\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.7243 - accuracy: 0.7755 - val_loss: 0.6880 - val_accuracy: 0.8077\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.7205 - accuracy: 0.7755 - val_loss: 0.6827 - val_accuracy: 0.8077\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 828us/step - loss: 0.7171 - accuracy: 0.7755 - val_loss: 0.6766 - val_accuracy: 0.8077\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 780us/step - loss: 0.7144 - accuracy: 0.7755 - val_loss: 0.6726 - val_accuracy: 0.8077\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 716us/step - loss: 0.7111 - accuracy: 0.7755 - val_loss: 0.6673 - val_accuracy: 0.8077\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 703us/step - loss: 0.7088 - accuracy: 0.7755 - val_loss: 0.6701 - val_accuracy: 0.8077\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 719us/step - loss: 0.7054 - accuracy: 0.7789 - val_loss: 0.6647 - val_accuracy: 0.8077\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.7025 - accuracy: 0.7755 - val_loss: 0.6587 - val_accuracy: 0.8077\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.7000 - accuracy: 0.7755 - val_loss: 0.6557 - val_accuracy: 0.8077\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.6976 - accuracy: 0.7755 - val_loss: 0.6517 - val_accuracy: 0.8077\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.6940 - accuracy: 0.7755 - val_loss: 0.6499 - val_accuracy: 0.8077\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.6911 - accuracy: 0.7789 - val_loss: 0.6469 - val_accuracy: 0.8077\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.6890 - accuracy: 0.7789 - val_loss: 0.6453 - val_accuracy: 0.8077\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.6872 - accuracy: 0.7823 - val_loss: 0.6410 - val_accuracy: 0.8077\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 786us/step - loss: 0.6842 - accuracy: 0.7789 - val_loss: 0.6435 - val_accuracy: 0.8077\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.6821 - accuracy: 0.7823 - val_loss: 0.6358 - val_accuracy: 0.8077\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.6792 - accuracy: 0.7789 - val_loss: 0.6351 - val_accuracy: 0.8077\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 679us/step - loss: 0.6770 - accuracy: 0.7823 - val_loss: 0.6307 - val_accuracy: 0.8077\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.6743 - accuracy: 0.7789 - val_loss: 0.6312 - val_accuracy: 0.8077\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.6729 - accuracy: 0.7857 - val_loss: 0.6250 - val_accuracy: 0.8077\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.6699 - accuracy: 0.7857 - val_loss: 0.6263 - val_accuracy: 0.8077\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.6682 - accuracy: 0.7857 - val_loss: 0.6209 - val_accuracy: 0.8077\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.6662 - accuracy: 0.7857 - val_loss: 0.6190 - val_accuracy: 0.8077\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 937us/step - loss: 0.6634 - accuracy: 0.7857 - val_loss: 0.6147 - val_accuracy: 0.8077\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.6617 - accuracy: 0.7857 - val_loss: 0.6121 - val_accuracy: 0.8077\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.6594 - accuracy: 0.7857 - val_loss: 0.6104 - val_accuracy: 0.8077\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.6585 - accuracy: 0.7857 - val_loss: 0.6121 - val_accuracy: 0.8077\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.6556 - accuracy: 0.7857 - val_loss: 0.6065 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 722us/step - loss: 0.6534 - accuracy: 0.7857 - val_loss: 0.6037 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 695us/step - loss: 0.6518 - accuracy: 0.7857 - val_loss: 0.6014 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.6497 - accuracy: 0.7857 - val_loss: 0.6002 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.6479 - accuracy: 0.7857 - val_loss: 0.5985 - val_accuracy: 0.8269\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.6463 - accuracy: 0.7857 - val_loss: 0.5975 - val_accuracy: 0.8269\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 928us/step - loss: 0.6439 - accuracy: 0.7891 - val_loss: 0.5937 - val_accuracy: 0.8269\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 840us/step - loss: 0.6431 - accuracy: 0.7891 - val_loss: 0.5910 - val_accuracy: 0.8269\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 975us/step - loss: 0.6407 - accuracy: 0.7891 - val_loss: 0.5879 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.6389 - accuracy: 0.7891 - val_loss: 0.5882 - val_accuracy: 0.8269\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.6380 - accuracy: 0.7959 - val_loss: 0.5869 - val_accuracy: 0.8269\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.6359 - accuracy: 0.7891 - val_loss: 0.5847 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.6342 - accuracy: 0.7993 - val_loss: 0.5802 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.6317 - accuracy: 0.7925 - val_loss: 0.5799 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.6305 - accuracy: 0.7925 - val_loss: 0.5788 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.6297 - accuracy: 0.7891 - val_loss: 0.5744 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.6277 - accuracy: 0.7891 - val_loss: 0.5735 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.6257 - accuracy: 0.7925 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.6236 - accuracy: 0.7925 - val_loss: 0.5713 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.6224 - accuracy: 0.7891 - val_loss: 0.5752 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 766us/step - loss: 0.6212 - accuracy: 0.7891 - val_loss: 0.5721 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.6189 - accuracy: 0.7925 - val_loss: 0.5684 - val_accuracy: 0.8462\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6177 - accuracy: 0.7891 - val_loss: 0.5684 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.6166 - accuracy: 0.7925 - val_loss: 0.5667 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.6151 - accuracy: 0.7891 - val_loss: 0.5636 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6131 - accuracy: 0.7891 - val_loss: 0.5641 - val_accuracy: 0.8462\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.6115 - accuracy: 0.7891 - val_loss: 0.5627 - val_accuracy: 0.8462\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6103 - accuracy: 0.7925 - val_loss: 0.5597 - val_accuracy: 0.8462\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.6085 - accuracy: 0.7959 - val_loss: 0.5576 - val_accuracy: 0.8462\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.6082 - accuracy: 0.7891 - val_loss: 0.5587 - val_accuracy: 0.8462\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 642us/step - loss: 0.6056 - accuracy: 0.7891 - val_loss: 0.5568 - val_accuracy: 0.8462\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.6044 - accuracy: 0.7925 - val_loss: 0.5557 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.6028 - accuracy: 0.7993 - val_loss: 0.5529 - val_accuracy: 0.8462\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.6016 - accuracy: 0.7959 - val_loss: 0.5523 - val_accuracy: 0.8462\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.6004 - accuracy: 0.7959 - val_loss: 0.5529 - val_accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5987 - accuracy: 0.7959 - val_loss: 0.5501 - val_accuracy: 0.8462\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5977 - accuracy: 0.7925 - val_loss: 0.5493 - val_accuracy: 0.8462\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.5961 - accuracy: 0.7925 - val_loss: 0.5461 - val_accuracy: 0.8462\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.5950 - accuracy: 0.7925 - val_loss: 0.5472 - val_accuracy: 0.8462\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5939 - accuracy: 0.7993 - val_loss: 0.5434 - val_accuracy: 0.8462\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 752us/step - loss: 0.5922 - accuracy: 0.8027 - val_loss: 0.5438 - val_accuracy: 0.8462\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5912 - accuracy: 0.7993 - val_loss: 0.5425 - val_accuracy: 0.8462\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.5907 - accuracy: 0.7925 - val_loss: 0.5461 - val_accuracy: 0.8462\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5894 - accuracy: 0.7925 - val_loss: 0.5416 - val_accuracy: 0.8462\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.5883 - accuracy: 0.7993 - val_loss: 0.5426 - val_accuracy: 0.8462\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.5874 - accuracy: 0.7993 - val_loss: 0.5378 - val_accuracy: 0.8462\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5858 - accuracy: 0.7925 - val_loss: 0.5387 - val_accuracy: 0.8462\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.5855 - accuracy: 0.7993 - val_loss: 0.5371 - val_accuracy: 0.8462\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.5834 - accuracy: 0.8027 - val_loss: 0.5371 - val_accuracy: 0.8462\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.5834 - accuracy: 0.8027 - val_loss: 0.5366 - val_accuracy: 0.8462\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.5816 - accuracy: 0.8027 - val_loss: 0.5347 - val_accuracy: 0.8462\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5810 - accuracy: 0.7993 - val_loss: 0.5324 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5799 - accuracy: 0.8027 - val_loss: 0.5311 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 98us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4523 - accuracy: 0.2177 - val_loss: 1.3530 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 1.4119 - accuracy: 0.2041 - val_loss: 1.3131 - val_accuracy: 0.3654\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 1.3784 - accuracy: 0.2279 - val_loss: 1.2823 - val_accuracy: 0.4615\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 1.3490 - accuracy: 0.2483 - val_loss: 1.2545 - val_accuracy: 0.4231\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 1.3251 - accuracy: 0.2483 - val_loss: 1.2271 - val_accuracy: 0.4231\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 1.3028 - accuracy: 0.2755 - val_loss: 1.2068 - val_accuracy: 0.4423\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 764us/step - loss: 1.2846 - accuracy: 0.3265 - val_loss: 1.1886 - val_accuracy: 0.5000\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 1.2671 - accuracy: 0.3537 - val_loss: 1.1707 - val_accuracy: 0.4808\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 1.2512 - accuracy: 0.3810 - val_loss: 1.1564 - val_accuracy: 0.4808\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 551us/step - loss: 1.2364 - accuracy: 0.4014 - val_loss: 1.1412 - val_accuracy: 0.5962\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 1.2221 - accuracy: 0.4252 - val_loss: 1.1286 - val_accuracy: 0.5962\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 820us/step - loss: 1.2080 - accuracy: 0.4660 - val_loss: 1.1162 - val_accuracy: 0.6154\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 1.1951 - accuracy: 0.4796 - val_loss: 1.1028 - val_accuracy: 0.6154\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 208us/step - loss: 1.1820 - accuracy: 0.4728 - val_loss: 1.0918 - val_accuracy: 0.6346\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 1.1692 - accuracy: 0.4728 - val_loss: 1.0804 - val_accuracy: 0.6346\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 1.1562 - accuracy: 0.4830 - val_loss: 1.0691 - val_accuracy: 0.6731\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 1.1434 - accuracy: 0.4898 - val_loss: 1.0574 - val_accuracy: 0.6731\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 1.1299 - accuracy: 0.5068 - val_loss: 1.0459 - val_accuracy: 0.6731\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 1.1169 - accuracy: 0.5170 - val_loss: 1.0332 - val_accuracy: 0.6731\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 1.1020 - accuracy: 0.5340 - val_loss: 1.0202 - val_accuracy: 0.6731\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 1.0875 - accuracy: 0.5408 - val_loss: 1.0071 - val_accuracy: 0.6731\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 1.0732 - accuracy: 0.5442 - val_loss: 0.9931 - val_accuracy: 0.6923\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 770us/step - loss: 1.0579 - accuracy: 0.5476 - val_loss: 0.9776 - val_accuracy: 0.7115\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 1.0425 - accuracy: 0.5578 - val_loss: 0.9615 - val_accuracy: 0.7308\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 1.0270 - accuracy: 0.5782 - val_loss: 0.9432 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 1.0089 - accuracy: 0.6020 - val_loss: 0.9241 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 623us/step - loss: 0.9908 - accuracy: 0.6156 - val_loss: 0.9003 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 640us/step - loss: 0.9701 - accuracy: 0.6327 - val_loss: 0.8791 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.9501 - accuracy: 0.6429 - val_loss: 0.8550 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.9295 - accuracy: 0.6633 - val_loss: 0.8355 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.9095 - accuracy: 0.6633 - val_loss: 0.8148 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.8915 - accuracy: 0.6735 - val_loss: 0.7987 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.8750 - accuracy: 0.6803 - val_loss: 0.7845 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.8594 - accuracy: 0.6871 - val_loss: 0.7706 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 286us/step - loss: 0.8452 - accuracy: 0.6973 - val_loss: 0.7579 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.8314 - accuracy: 0.7075 - val_loss: 0.7448 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.8202 - accuracy: 0.7109 - val_loss: 0.7316 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 0.8070 - accuracy: 0.7075 - val_loss: 0.7213 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.7953 - accuracy: 0.7109 - val_loss: 0.7107 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.7847 - accuracy: 0.7177 - val_loss: 0.7004 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.7746 - accuracy: 0.7211 - val_loss: 0.6924 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 542us/step - loss: 0.7652 - accuracy: 0.7313 - val_loss: 0.6825 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 729us/step - loss: 0.7563 - accuracy: 0.7381 - val_loss: 0.6756 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.7485 - accuracy: 0.7381 - val_loss: 0.6638 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.7533 - accuracy: 0.73 - 0s 302us/step - loss: 0.7398 - accuracy: 0.7449 - val_loss: 0.6583 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.7319 - accuracy: 0.7415 - val_loss: 0.6509 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.7246 - accuracy: 0.7483 - val_loss: 0.6454 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.7177 - accuracy: 0.7449 - val_loss: 0.6400 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.7111 - accuracy: 0.7415 - val_loss: 0.6323 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.7048 - accuracy: 0.7449 - val_loss: 0.6277 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.6988 - accuracy: 0.7415 - val_loss: 0.6214 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.6941 - accuracy: 0.7551 - val_loss: 0.6183 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6877 - accuracy: 0.7483 - val_loss: 0.6120 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.6828 - accuracy: 0.7449 - val_loss: 0.6075 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.6778 - accuracy: 0.7517 - val_loss: 0.6033 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.6730 - accuracy: 0.7551 - val_loss: 0.5997 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6683 - accuracy: 0.7551 - val_loss: 0.5942 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.6642 - accuracy: 0.7585 - val_loss: 0.5910 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.6603 - accuracy: 0.7551 - val_loss: 0.5861 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.6560 - accuracy: 0.7517 - val_loss: 0.5847 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.6522 - accuracy: 0.7653 - val_loss: 0.5809 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 0.6488 - accuracy: 0.7653 - val_loss: 0.5783 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.6454 - accuracy: 0.7653 - val_loss: 0.5778 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.6426 - accuracy: 0.7687 - val_loss: 0.5733 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.76 - 0s 438us/step - loss: 0.6391 - accuracy: 0.7687 - val_loss: 0.5692 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.6355 - accuracy: 0.7687 - val_loss: 0.5662 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.6333 - accuracy: 0.7687 - val_loss: 0.5675 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.6297 - accuracy: 0.7687 - val_loss: 0.5632 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6280 - accuracy: 0.7721 - val_loss: 0.5633 - val_accuracy: 0.8654\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.6247 - accuracy: 0.7687 - val_loss: 0.5604 - val_accuracy: 0.8654\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.6224 - accuracy: 0.7687 - val_loss: 0.5554 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 620us/step - loss: 0.6193 - accuracy: 0.7687 - val_loss: 0.5571 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6170 - accuracy: 0.7687 - val_loss: 0.5527 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6145 - accuracy: 0.7687 - val_loss: 0.5510 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.6118 - accuracy: 0.7687 - val_loss: 0.5502 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.6098 - accuracy: 0.7687 - val_loss: 0.5490 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.78 - 0s 264us/step - loss: 0.6075 - accuracy: 0.7687 - val_loss: 0.5449 - val_accuracy: 0.8654\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 660us/step - loss: 0.6054 - accuracy: 0.7687 - val_loss: 0.5451 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.6035 - accuracy: 0.7687 - val_loss: 0.5436 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.6012 - accuracy: 0.7721 - val_loss: 0.5455 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5995 - accuracy: 0.7721 - val_loss: 0.5407 - val_accuracy: 0.8654\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5969 - accuracy: 0.7687 - val_loss: 0.5403 - val_accuracy: 0.8654\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.5957 - accuracy: 0.7687 - val_loss: 0.5407 - val_accuracy: 0.8654\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 651us/step - loss: 0.5934 - accuracy: 0.7687 - val_loss: 0.5404 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5912 - accuracy: 0.7687 - val_loss: 0.5381 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5894 - accuracy: 0.7687 - val_loss: 0.5362 - val_accuracy: 0.8654\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5874 - accuracy: 0.7687 - val_loss: 0.5357 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5858 - accuracy: 0.7687 - val_loss: 0.5363 - val_accuracy: 0.8654\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5840 - accuracy: 0.7687 - val_loss: 0.5345 - val_accuracy: 0.8654\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 312us/step - loss: 0.5821 - accuracy: 0.7687 - val_loss: 0.5350 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5811 - accuracy: 0.7687 - val_loss: 0.5340 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5786 - accuracy: 0.7687 - val_loss: 0.5325 - val_accuracy: 0.8654\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5768 - accuracy: 0.7687 - val_loss: 0.5304 - val_accuracy: 0.8654\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5759 - accuracy: 0.7653 - val_loss: 0.5330 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.5735 - accuracy: 0.7687 - val_loss: 0.5297 - val_accuracy: 0.8654\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5720 - accuracy: 0.7755 - val_loss: 0.5312 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5698 - accuracy: 0.7721 - val_loss: 0.5282 - val_accuracy: 0.8654\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.5683 - accuracy: 0.7687 - val_loss: 0.5296 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5669 - accuracy: 0.7687 - val_loss: 0.5271 - val_accuracy: 0.8654\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 645us/step - loss: 0.5654 - accuracy: 0.7721 - val_loss: 0.5292 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7721 - val_loss: 0.5256 - val_accuracy: 0.8654\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5627 - accuracy: 0.7721 - val_loss: 0.5253 - val_accuracy: 0.8654\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.5604 - accuracy: 0.7755 - val_loss: 0.5253 - val_accuracy: 0.8654\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5599 - accuracy: 0.7687 - val_loss: 0.5273 - val_accuracy: 0.8269\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5578 - accuracy: 0.7721 - val_loss: 0.5236 - val_accuracy: 0.8654\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5570 - accuracy: 0.7755 - val_loss: 0.5197 - val_accuracy: 0.8654\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.5549 - accuracy: 0.7721 - val_loss: 0.5197 - val_accuracy: 0.8654\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5535 - accuracy: 0.7721 - val_loss: 0.5179 - val_accuracy: 0.8654\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5528 - accuracy: 0.7721 - val_loss: 0.5177 - val_accuracy: 0.8654\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5513 - accuracy: 0.7755 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5506 - accuracy: 0.7721 - val_loss: 0.5153 - val_accuracy: 0.8654\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 248us/step - loss: 0.5487 - accuracy: 0.7721 - val_loss: 0.5168 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5476 - accuracy: 0.7721 - val_loss: 0.5165 - val_accuracy: 0.8654\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5467 - accuracy: 0.7721 - val_loss: 0.5150 - val_accuracy: 0.8654\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 256us/step - loss: 0.5455 - accuracy: 0.7721 - val_loss: 0.5123 - val_accuracy: 0.8654\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5443 - accuracy: 0.7755 - val_loss: 0.5132 - val_accuracy: 0.8654\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5435 - accuracy: 0.7755 - val_loss: 0.5121 - val_accuracy: 0.8654\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5424 - accuracy: 0.7789 - val_loss: 0.5125 - val_accuracy: 0.8654\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5414 - accuracy: 0.7755 - val_loss: 0.5109 - val_accuracy: 0.8654\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5399 - accuracy: 0.7755 - val_loss: 0.5078 - val_accuracy: 0.8654\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5392 - accuracy: 0.7755 - val_loss: 0.5075 - val_accuracy: 0.8654\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5381 - accuracy: 0.7789 - val_loss: 0.5079 - val_accuracy: 0.8654\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5370 - accuracy: 0.7721 - val_loss: 0.5068 - val_accuracy: 0.8654\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5365 - accuracy: 0.7721 - val_loss: 0.5089 - val_accuracy: 0.8654\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5354 - accuracy: 0.7789 - val_loss: 0.5046 - val_accuracy: 0.8654\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5345 - accuracy: 0.7755 - val_loss: 0.5042 - val_accuracy: 0.8654\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.5338 - accuracy: 0.7755 - val_loss: 0.5050 - val_accuracy: 0.8654\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5329 - accuracy: 0.7755 - val_loss: 0.5035 - val_accuracy: 0.8654\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5322 - accuracy: 0.7755 - val_loss: 0.5028 - val_accuracy: 0.8654\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.5309 - accuracy: 0.7721 - val_loss: 0.5018 - val_accuracy: 0.8654\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5303 - accuracy: 0.7721 - val_loss: 0.4998 - val_accuracy: 0.8654\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5291 - accuracy: 0.7755 - val_loss: 0.5003 - val_accuracy: 0.8654\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5284 - accuracy: 0.7789 - val_loss: 0.4986 - val_accuracy: 0.8654\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 631us/step - loss: 0.5278 - accuracy: 0.7755 - val_loss: 0.4985 - val_accuracy: 0.8654\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5269 - accuracy: 0.7755 - val_loss: 0.5001 - val_accuracy: 0.8654\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5261 - accuracy: 0.7755 - val_loss: 0.4993 - val_accuracy: 0.8654\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5254 - accuracy: 0.7755 - val_loss: 0.4978 - val_accuracy: 0.8654\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5251 - accuracy: 0.7721 - val_loss: 0.4981 - val_accuracy: 0.8654\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.5237 - accuracy: 0.7755 - val_loss: 0.4970 - val_accuracy: 0.8654\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5229 - accuracy: 0.7755 - val_loss: 0.4946 - val_accuracy: 0.8654\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.5221 - accuracy: 0.7755 - val_loss: 0.4927 - val_accuracy: 0.8654\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5218 - accuracy: 0.7755 - val_loss: 0.4944 - val_accuracy: 0.8654\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.5208 - accuracy: 0.7755 - val_loss: 0.4931 - val_accuracy: 0.8654\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 0.5202 - accuracy: 0.7755 - val_loss: 0.4935 - val_accuracy: 0.8654\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5198 - accuracy: 0.7755 - val_loss: 0.4927 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 0.5189 - accuracy: 0.7755 - val_loss: 0.4908 - val_accuracy: 0.8654\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5187 - accuracy: 0.7755 - val_loss: 0.4914 - val_accuracy: 0.8654\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 0.5176 - accuracy: 0.7755 - val_loss: 0.4918 - val_accuracy: 0.8654\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 251us/step - loss: 0.5170 - accuracy: 0.7755 - val_loss: 0.4897 - val_accuracy: 0.8654\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5166 - accuracy: 0.7755 - val_loss: 0.4900 - val_accuracy: 0.8654\n",
      "116/116 [==============================] - 0s 88us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.5756 - accuracy: 0.1497 - val_loss: 1.5419 - val_accuracy: 0.0769\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 1.5251 - accuracy: 0.1531 - val_loss: 1.4864 - val_accuracy: 0.0962\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 1.4803 - accuracy: 0.1497 - val_loss: 1.4398 - val_accuracy: 0.0962\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 1.4383 - accuracy: 0.1497 - val_loss: 1.4022 - val_accuracy: 0.1538\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 1.3990 - accuracy: 0.1565 - val_loss: 1.3656 - val_accuracy: 0.1346\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 1.3607 - accuracy: 0.1803 - val_loss: 1.3331 - val_accuracy: 0.1538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 1.3251 - accuracy: 0.2483 - val_loss: 1.3001 - val_accuracy: 0.2308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 663us/step - loss: 1.2946 - accuracy: 0.2959 - val_loss: 1.2728 - val_accuracy: 0.3077\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 1.2687 - accuracy: 0.3639 - val_loss: 1.2491 - val_accuracy: 0.3462\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 1.2459 - accuracy: 0.4048 - val_loss: 1.2247 - val_accuracy: 0.3654\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 1.2245 - accuracy: 0.4490 - val_loss: 1.2027 - val_accuracy: 0.3846\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 1.2042 - accuracy: 0.4762 - val_loss: 1.1809 - val_accuracy: 0.4038\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 1.1843 - accuracy: 0.5170 - val_loss: 1.1579 - val_accuracy: 0.4615\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 1.1645 - accuracy: 0.5408 - val_loss: 1.1345 - val_accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 1.1452 - accuracy: 0.5748 - val_loss: 1.1123 - val_accuracy: 0.5192\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 551us/step - loss: 1.1257 - accuracy: 0.5986 - val_loss: 1.0933 - val_accuracy: 0.5577\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 627us/step - loss: 1.1067 - accuracy: 0.6156 - val_loss: 1.0718 - val_accuracy: 0.6154\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 1.0884 - accuracy: 0.6190 - val_loss: 1.0530 - val_accuracy: 0.6154\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 615us/step - loss: 1.0711 - accuracy: 0.6463 - val_loss: 1.0353 - val_accuracy: 0.6538\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 1.0553 - accuracy: 0.6497 - val_loss: 1.0170 - val_accuracy: 0.6538\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 1.0390 - accuracy: 0.6599 - val_loss: 1.0022 - val_accuracy: 0.6538\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 1.0245 - accuracy: 0.6599 - val_loss: 0.9846 - val_accuracy: 0.6538\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 1.0104 - accuracy: 0.6463 - val_loss: 0.9721 - val_accuracy: 0.7115\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.9968 - accuracy: 0.6463 - val_loss: 0.9545 - val_accuracy: 0.6923\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.9835 - accuracy: 0.6497 - val_loss: 0.9414 - val_accuracy: 0.7308\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.9712 - accuracy: 0.6497 - val_loss: 0.9286 - val_accuracy: 0.7692\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.9592 - accuracy: 0.6565 - val_loss: 0.9160 - val_accuracy: 0.7692\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.9479 - accuracy: 0.6395 - val_loss: 0.9035 - val_accuracy: 0.7500\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.9369 - accuracy: 0.6463 - val_loss: 0.8883 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.9259 - accuracy: 0.6633 - val_loss: 0.8766 - val_accuracy: 0.7692\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.9154 - accuracy: 0.6735 - val_loss: 0.8653 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.9045 - accuracy: 0.6871 - val_loss: 0.8554 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.8945 - accuracy: 0.6871 - val_loss: 0.8452 - val_accuracy: 0.7308\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.8847 - accuracy: 0.6905 - val_loss: 0.8327 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.8755 - accuracy: 0.7007 - val_loss: 0.8242 - val_accuracy: 0.7308\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.8664 - accuracy: 0.7041 - val_loss: 0.8154 - val_accuracy: 0.7308\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 597us/step - loss: 0.8580 - accuracy: 0.7143 - val_loss: 0.8041 - val_accuracy: 0.7308\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 708us/step - loss: 0.8496 - accuracy: 0.7041 - val_loss: 0.7953 - val_accuracy: 0.7308\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 764us/step - loss: 0.8421 - accuracy: 0.7109 - val_loss: 0.7880 - val_accuracy: 0.7115\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 806us/step - loss: 0.8341 - accuracy: 0.7143 - val_loss: 0.7805 - val_accuracy: 0.7115\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 858us/step - loss: 0.8275 - accuracy: 0.7075 - val_loss: 0.7705 - val_accuracy: 0.7308\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 672us/step - loss: 0.8207 - accuracy: 0.7211 - val_loss: 0.7647 - val_accuracy: 0.7500\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.8133 - accuracy: 0.7211 - val_loss: 0.7557 - val_accuracy: 0.7308\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.8071 - accuracy: 0.7177 - val_loss: 0.7528 - val_accuracy: 0.7500\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.8005 - accuracy: 0.7143 - val_loss: 0.7430 - val_accuracy: 0.7500\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.7948 - accuracy: 0.7177 - val_loss: 0.7360 - val_accuracy: 0.7500\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.7892 - accuracy: 0.7109 - val_loss: 0.7319 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 786us/step - loss: 0.7833 - accuracy: 0.7245 - val_loss: 0.7260 - val_accuracy: 0.7500\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.7779 - accuracy: 0.7211 - val_loss: 0.7207 - val_accuracy: 0.7692\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.7728 - accuracy: 0.7245 - val_loss: 0.7148 - val_accuracy: 0.7692\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 474us/step - loss: 0.7678 - accuracy: 0.7245 - val_loss: 0.7112 - val_accuracy: 0.7692\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.7624 - accuracy: 0.7279 - val_loss: 0.7047 - val_accuracy: 0.7692\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.7572 - accuracy: 0.7245 - val_loss: 0.7024 - val_accuracy: 0.7692\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.7522 - accuracy: 0.7279 - val_loss: 0.6959 - val_accuracy: 0.7692\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.7478 - accuracy: 0.7279 - val_loss: 0.6899 - val_accuracy: 0.7692\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.7434 - accuracy: 0.7347 - val_loss: 0.6877 - val_accuracy: 0.7692\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.7387 - accuracy: 0.7381 - val_loss: 0.6817 - val_accuracy: 0.7692\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.7353 - accuracy: 0.7279 - val_loss: 0.6770 - val_accuracy: 0.7692\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.7307 - accuracy: 0.7381 - val_loss: 0.6754 - val_accuracy: 0.7692\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.7260 - accuracy: 0.7381 - val_loss: 0.6732 - val_accuracy: 0.7692\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.7223 - accuracy: 0.7381 - val_loss: 0.6687 - val_accuracy: 0.7692\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.7185 - accuracy: 0.7381 - val_loss: 0.6654 - val_accuracy: 0.7692\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.7156 - accuracy: 0.7381 - val_loss: 0.6623 - val_accuracy: 0.7692\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.7114 - accuracy: 0.7347 - val_loss: 0.6616 - val_accuracy: 0.7692\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.7077 - accuracy: 0.7347 - val_loss: 0.6599 - val_accuracy: 0.7692\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.7033 - accuracy: 0.7415 - val_loss: 0.6541 - val_accuracy: 0.7692\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.7004 - accuracy: 0.7347 - val_loss: 0.6502 - val_accuracy: 0.7692\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.6978 - accuracy: 0.7313 - val_loss: 0.6505 - val_accuracy: 0.7692\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.6943 - accuracy: 0.7381 - val_loss: 0.6408 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.6912 - accuracy: 0.7415 - val_loss: 0.6423 - val_accuracy: 0.7692\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.6870 - accuracy: 0.7381 - val_loss: 0.6383 - val_accuracy: 0.8077\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.6838 - accuracy: 0.7211 - val_loss: 0.6403 - val_accuracy: 0.7692\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.6809 - accuracy: 0.7381 - val_loss: 0.6325 - val_accuracy: 0.8077\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.6765 - accuracy: 0.7347 - val_loss: 0.6315 - val_accuracy: 0.8077\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.6728 - accuracy: 0.7381 - val_loss: 0.6299 - val_accuracy: 0.7692\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.6695 - accuracy: 0.7347 - val_loss: 0.6279 - val_accuracy: 0.7692\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.6654 - accuracy: 0.7313 - val_loss: 0.6271 - val_accuracy: 0.7692\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.6610 - accuracy: 0.7313 - val_loss: 0.6198 - val_accuracy: 0.8077\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.6576 - accuracy: 0.7381 - val_loss: 0.6163 - val_accuracy: 0.8077\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6533 - accuracy: 0.7347 - val_loss: 0.6127 - val_accuracy: 0.8077\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.6507 - accuracy: 0.7381 - val_loss: 0.6108 - val_accuracy: 0.8077\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.6455 - accuracy: 0.7347 - val_loss: 0.6097 - val_accuracy: 0.8077\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6411 - accuracy: 0.7313 - val_loss: 0.6032 - val_accuracy: 0.8077\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.6366 - accuracy: 0.7313 - val_loss: 0.6034 - val_accuracy: 0.8077\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.6320 - accuracy: 0.7279 - val_loss: 0.5995 - val_accuracy: 0.8077\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.6280 - accuracy: 0.7313 - val_loss: 0.5968 - val_accuracy: 0.8077\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6244 - accuracy: 0.7245 - val_loss: 0.5965 - val_accuracy: 0.8077\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.6210 - accuracy: 0.7313 - val_loss: 0.5915 - val_accuracy: 0.8077\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.6180 - accuracy: 0.7279 - val_loss: 0.5893 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.6160 - accuracy: 0.7279 - val_loss: 0.5851 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.6128 - accuracy: 0.7279 - val_loss: 0.5829 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.6103 - accuracy: 0.7313 - val_loss: 0.5806 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6078 - accuracy: 0.7279 - val_loss: 0.5808 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.6049 - accuracy: 0.7279 - val_loss: 0.5795 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 239us/step - loss: 0.6025 - accuracy: 0.7245 - val_loss: 0.5778 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 0.6003 - accuracy: 0.7313 - val_loss: 0.5741 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5983 - accuracy: 0.7415 - val_loss: 0.5735 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5966 - accuracy: 0.7279 - val_loss: 0.5699 - val_accuracy: 0.8654\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 213us/step - loss: 0.5937 - accuracy: 0.7381 - val_loss: 0.5707 - val_accuracy: 0.8654\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5916 - accuracy: 0.7483 - val_loss: 0.5701 - val_accuracy: 0.8654\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.5900 - accuracy: 0.7449 - val_loss: 0.5663 - val_accuracy: 0.8654\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5880 - accuracy: 0.7517 - val_loss: 0.5652 - val_accuracy: 0.8654\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5858 - accuracy: 0.7517 - val_loss: 0.5629 - val_accuracy: 0.8654\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5842 - accuracy: 0.7517 - val_loss: 0.5600 - val_accuracy: 0.8654\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5831 - accuracy: 0.7551 - val_loss: 0.5595 - val_accuracy: 0.8654\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 213us/step - loss: 0.5811 - accuracy: 0.7517 - val_loss: 0.5573 - val_accuracy: 0.8654\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 295us/step - loss: 0.5787 - accuracy: 0.7517 - val_loss: 0.5581 - val_accuracy: 0.8654\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5771 - accuracy: 0.7585 - val_loss: 0.5577 - val_accuracy: 0.8654\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5759 - accuracy: 0.7653 - val_loss: 0.5542 - val_accuracy: 0.8654\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5743 - accuracy: 0.7585 - val_loss: 0.5544 - val_accuracy: 0.8654\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5728 - accuracy: 0.7585 - val_loss: 0.5553 - val_accuracy: 0.8654\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.5714 - accuracy: 0.7585 - val_loss: 0.5534 - val_accuracy: 0.8654\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.5692 - accuracy: 0.7687 - val_loss: 0.5499 - val_accuracy: 0.8654\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5680 - accuracy: 0.7687 - val_loss: 0.5469 - val_accuracy: 0.8654\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5670 - accuracy: 0.7687 - val_loss: 0.5481 - val_accuracy: 0.8654\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5654 - accuracy: 0.7687 - val_loss: 0.5482 - val_accuracy: 0.8654\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5639 - accuracy: 0.7687 - val_loss: 0.5481 - val_accuracy: 0.8654\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.5628 - accuracy: 0.7687 - val_loss: 0.5462 - val_accuracy: 0.8654\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5620 - accuracy: 0.7721 - val_loss: 0.5432 - val_accuracy: 0.8654\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.5600 - accuracy: 0.7721 - val_loss: 0.5433 - val_accuracy: 0.8654\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5590 - accuracy: 0.7687 - val_loss: 0.5433 - val_accuracy: 0.8654\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5583 - accuracy: 0.7687 - val_loss: 0.5393 - val_accuracy: 0.8654\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.5563 - accuracy: 0.7721 - val_loss: 0.5425 - val_accuracy: 0.8654\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.5567 - accuracy: 0.7687 - val_loss: 0.5466 - val_accuracy: 0.8654\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5547 - accuracy: 0.7721 - val_loss: 0.5386 - val_accuracy: 0.8654\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5538 - accuracy: 0.7653 - val_loss: 0.5383 - val_accuracy: 0.8654\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5520 - accuracy: 0.7721 - val_loss: 0.5376 - val_accuracy: 0.8654\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5518 - accuracy: 0.7687 - val_loss: 0.5409 - val_accuracy: 0.8654\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5503 - accuracy: 0.7687 - val_loss: 0.5396 - val_accuracy: 0.8654\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5490 - accuracy: 0.7721 - val_loss: 0.5375 - val_accuracy: 0.8654\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5483 - accuracy: 0.7755 - val_loss: 0.5376 - val_accuracy: 0.8654\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.5474 - accuracy: 0.7687 - val_loss: 0.5369 - val_accuracy: 0.8654\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5459 - accuracy: 0.7687 - val_loss: 0.5407 - val_accuracy: 0.8654\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.5456 - accuracy: 0.7721 - val_loss: 0.5393 - val_accuracy: 0.8654\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5447 - accuracy: 0.7721 - val_loss: 0.5400 - val_accuracy: 0.8654\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5437 - accuracy: 0.7619 - val_loss: 0.5376 - val_accuracy: 0.8654\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5423 - accuracy: 0.7721 - val_loss: 0.5373 - val_accuracy: 0.8654\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5413 - accuracy: 0.7721 - val_loss: 0.5381 - val_accuracy: 0.8654\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5402 - accuracy: 0.7721 - val_loss: 0.5350 - val_accuracy: 0.8654\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5397 - accuracy: 0.7653 - val_loss: 0.5338 - val_accuracy: 0.8654\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5391 - accuracy: 0.7755 - val_loss: 0.5392 - val_accuracy: 0.8654\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.5382 - accuracy: 0.7755 - val_loss: 0.5338 - val_accuracy: 0.8654\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5369 - accuracy: 0.7687 - val_loss: 0.5380 - val_accuracy: 0.8654\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5359 - accuracy: 0.7721 - val_loss: 0.5395 - val_accuracy: 0.8654\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5352 - accuracy: 0.7755 - val_loss: 0.5351 - val_accuracy: 0.8654\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.5346 - accuracy: 0.7721 - val_loss: 0.5359 - val_accuracy: 0.8654\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.5334 - accuracy: 0.7687 - val_loss: 0.5371 - val_accuracy: 0.8654\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5325 - accuracy: 0.7755 - val_loss: 0.5331 - val_accuracy: 0.8654\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5320 - accuracy: 0.7653 - val_loss: 0.5341 - val_accuracy: 0.8654\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5311 - accuracy: 0.7755 - val_loss: 0.5367 - val_accuracy: 0.8654\n",
      "116/116 [==============================] - 0s 481us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5246 - accuracy: 0.2279 - val_loss: 1.5258 - val_accuracy: 0.2308\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 1.4500 - accuracy: 0.2245 - val_loss: 1.4641 - val_accuracy: 0.2500\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 1.3961 - accuracy: 0.2517 - val_loss: 1.4183 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 1.3561 - accuracy: 0.2789 - val_loss: 1.3800 - val_accuracy: 0.2692\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 1.3220 - accuracy: 0.2993 - val_loss: 1.3478 - val_accuracy: 0.3269\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 1.2922 - accuracy: 0.3503 - val_loss: 1.3188 - val_accuracy: 0.3654\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 1.2641 - accuracy: 0.3810 - val_loss: 1.2900 - val_accuracy: 0.3846\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 1.2379 - accuracy: 0.4048 - val_loss: 1.2628 - val_accuracy: 0.4615\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 1.2128 - accuracy: 0.4524 - val_loss: 1.2355 - val_accuracy: 0.5000\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 1.1889 - accuracy: 0.4830 - val_loss: 1.2083 - val_accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 1.1646 - accuracy: 0.5000 - val_loss: 1.1782 - val_accuracy: 0.5000\n",
      "Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 386us/step - loss: 1.1401 - accuracy: 0.5272 - val_loss: 1.1488 - val_accuracy: 0.5577\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 1.1152 - accuracy: 0.5646 - val_loss: 1.1201 - val_accuracy: 0.5769\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 1.0898 - accuracy: 0.6020 - val_loss: 1.0919 - val_accuracy: 0.5962\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 1.0650 - accuracy: 0.6293 - val_loss: 1.0647 - val_accuracy: 0.5962\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 1.0400 - accuracy: 0.6463 - val_loss: 1.0406 - val_accuracy: 0.6346\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 1.0181 - accuracy: 0.6361 - val_loss: 1.0186 - val_accuracy: 0.6538\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.9957 - accuracy: 0.6327 - val_loss: 0.9961 - val_accuracy: 0.6731\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.9758 - accuracy: 0.6463 - val_loss: 0.9738 - val_accuracy: 0.7115\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.9574 - accuracy: 0.6531 - val_loss: 0.9585 - val_accuracy: 0.6923\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.9387 - accuracy: 0.6837 - val_loss: 0.9405 - val_accuracy: 0.6923\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.9216 - accuracy: 0.7007 - val_loss: 0.9253 - val_accuracy: 0.6923\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.9060 - accuracy: 0.7041 - val_loss: 0.9120 - val_accuracy: 0.7115\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.8898 - accuracy: 0.7177 - val_loss: 0.8942 - val_accuracy: 0.7500\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.8749 - accuracy: 0.7313 - val_loss: 0.8820 - val_accuracy: 0.7500\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.8602 - accuracy: 0.7279 - val_loss: 0.8691 - val_accuracy: 0.7500\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.8459 - accuracy: 0.7381 - val_loss: 0.8558 - val_accuracy: 0.7308\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.8318 - accuracy: 0.7449 - val_loss: 0.8409 - val_accuracy: 0.7308\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.8186 - accuracy: 0.7517 - val_loss: 0.8290 - val_accuracy: 0.7308\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.8040 - accuracy: 0.7551 - val_loss: 0.8143 - val_accuracy: 0.7308\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.7907 - accuracy: 0.7551 - val_loss: 0.8043 - val_accuracy: 0.7308\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.7775 - accuracy: 0.7585 - val_loss: 0.7921 - val_accuracy: 0.7308\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.7649 - accuracy: 0.7585 - val_loss: 0.7783 - val_accuracy: 0.7692\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.7518 - accuracy: 0.7619 - val_loss: 0.7664 - val_accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.7383 - accuracy: 0.7585 - val_loss: 0.7555 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.7258 - accuracy: 0.7585 - val_loss: 0.7469 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.7149 - accuracy: 0.7585 - val_loss: 0.7393 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.7058 - accuracy: 0.7585 - val_loss: 0.7343 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.6959 - accuracy: 0.7653 - val_loss: 0.7212 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.6884 - accuracy: 0.7653 - val_loss: 0.7125 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.6820 - accuracy: 0.7619 - val_loss: 0.7044 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.6752 - accuracy: 0.7619 - val_loss: 0.6963 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.6684 - accuracy: 0.7653 - val_loss: 0.6883 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.6627 - accuracy: 0.7653 - val_loss: 0.6833 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.6575 - accuracy: 0.7687 - val_loss: 0.6781 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.6520 - accuracy: 0.7619 - val_loss: 0.6730 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.6467 - accuracy: 0.7653 - val_loss: 0.6642 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6419 - accuracy: 0.7687 - val_loss: 0.6589 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.6368 - accuracy: 0.7721 - val_loss: 0.6549 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.6325 - accuracy: 0.7653 - val_loss: 0.6493 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.6284 - accuracy: 0.7585 - val_loss: 0.6469 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.6247 - accuracy: 0.7721 - val_loss: 0.6386 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.6195 - accuracy: 0.7721 - val_loss: 0.6358 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.6158 - accuracy: 0.7789 - val_loss: 0.6334 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6121 - accuracy: 0.7721 - val_loss: 0.6276 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.6080 - accuracy: 0.7755 - val_loss: 0.6268 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.6045 - accuracy: 0.7721 - val_loss: 0.6245 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.6002 - accuracy: 0.7721 - val_loss: 0.6186 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.5974 - accuracy: 0.7687 - val_loss: 0.6181 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5935 - accuracy: 0.7687 - val_loss: 0.6122 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5897 - accuracy: 0.7721 - val_loss: 0.6084 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.5869 - accuracy: 0.7755 - val_loss: 0.6028 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5844 - accuracy: 0.7755 - val_loss: 0.5991 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5807 - accuracy: 0.7755 - val_loss: 0.6004 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 248us/step - loss: 0.5783 - accuracy: 0.7721 - val_loss: 0.5957 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5759 - accuracy: 0.7721 - val_loss: 0.5956 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.5741 - accuracy: 0.7687 - val_loss: 0.5938 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 308us/step - loss: 0.5708 - accuracy: 0.7687 - val_loss: 0.5912 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5689 - accuracy: 0.7755 - val_loss: 0.5847 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5659 - accuracy: 0.7755 - val_loss: 0.5824 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5634 - accuracy: 0.7687 - val_loss: 0.5840 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.5610 - accuracy: 0.7687 - val_loss: 0.5811 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5590 - accuracy: 0.7687 - val_loss: 0.5783 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5558 - accuracy: 0.7721 - val_loss: 0.5739 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5552 - accuracy: 0.7755 - val_loss: 0.5780 - val_accuracy: 0.8077\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5534 - accuracy: 0.7721 - val_loss: 0.5733 - val_accuracy: 0.8077\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.5504 - accuracy: 0.7721 - val_loss: 0.5737 - val_accuracy: 0.8077\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.5479 - accuracy: 0.7687 - val_loss: 0.5715 - val_accuracy: 0.8077\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5467 - accuracy: 0.7721 - val_loss: 0.5676 - val_accuracy: 0.8077\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5453 - accuracy: 0.7755 - val_loss: 0.5652 - val_accuracy: 0.8077\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5429 - accuracy: 0.7755 - val_loss: 0.5622 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5420 - accuracy: 0.7687 - val_loss: 0.5651 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5397 - accuracy: 0.7721 - val_loss: 0.5604 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5379 - accuracy: 0.7755 - val_loss: 0.5580 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5364 - accuracy: 0.7755 - val_loss: 0.5573 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5356 - accuracy: 0.7755 - val_loss: 0.5579 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5334 - accuracy: 0.7789 - val_loss: 0.5575 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5323 - accuracy: 0.7755 - val_loss: 0.5579 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5308 - accuracy: 0.7789 - val_loss: 0.5573 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5294 - accuracy: 0.7721 - val_loss: 0.5580 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5286 - accuracy: 0.7857 - val_loss: 0.5512 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5267 - accuracy: 0.7823 - val_loss: 0.5535 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5251 - accuracy: 0.7823 - val_loss: 0.5520 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5239 - accuracy: 0.7823 - val_loss: 0.5520 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 0.5239 - accuracy: 0.7823 - val_loss: 0.5467 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5219 - accuracy: 0.7857 - val_loss: 0.5488 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5204 - accuracy: 0.7857 - val_loss: 0.5478 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5203 - accuracy: 0.7823 - val_loss: 0.5475 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.5190 - accuracy: 0.7857 - val_loss: 0.5469 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5176 - accuracy: 0.7857 - val_loss: 0.5465 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5163 - accuracy: 0.7891 - val_loss: 0.5486 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.5151 - accuracy: 0.7857 - val_loss: 0.5490 - val_accuracy: 0.8269\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5151 - accuracy: 0.7891 - val_loss: 0.5459 - val_accuracy: 0.8269\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5134 - accuracy: 0.7891 - val_loss: 0.5437 - val_accuracy: 0.8269\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.5128 - accuracy: 0.7857 - val_loss: 0.5452 - val_accuracy: 0.8269\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5113 - accuracy: 0.7891 - val_loss: 0.5459 - val_accuracy: 0.8269\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5112 - accuracy: 0.7789 - val_loss: 0.5419 - val_accuracy: 0.8269\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5098 - accuracy: 0.7857 - val_loss: 0.5437 - val_accuracy: 0.8269\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5088 - accuracy: 0.7857 - val_loss: 0.5434 - val_accuracy: 0.8269\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5091 - accuracy: 0.7891 - val_loss: 0.5404 - val_accuracy: 0.8269\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5076 - accuracy: 0.7891 - val_loss: 0.5399 - val_accuracy: 0.8269\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5066 - accuracy: 0.7891 - val_loss: 0.5407 - val_accuracy: 0.8269\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5053 - accuracy: 0.7857 - val_loss: 0.5390 - val_accuracy: 0.8269\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5054 - accuracy: 0.7823 - val_loss: 0.5433 - val_accuracy: 0.8269\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5041 - accuracy: 0.7823 - val_loss: 0.5346 - val_accuracy: 0.8269\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5045 - accuracy: 0.7857 - val_loss: 0.5364 - val_accuracy: 0.8269\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5024 - accuracy: 0.7925 - val_loss: 0.5383 - val_accuracy: 0.8269\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5013 - accuracy: 0.7891 - val_loss: 0.5362 - val_accuracy: 0.8269\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5012 - accuracy: 0.7857 - val_loss: 0.5387 - val_accuracy: 0.8269\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5008 - accuracy: 0.7857 - val_loss: 0.5373 - val_accuracy: 0.8269\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5004 - accuracy: 0.7857 - val_loss: 0.5349 - val_accuracy: 0.8269\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.4995 - accuracy: 0.7857 - val_loss: 0.5376 - val_accuracy: 0.8269\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4982 - accuracy: 0.7823 - val_loss: 0.5375 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 266us/step - loss: 0.4984 - accuracy: 0.7789 - val_loss: 0.5386 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4976 - accuracy: 0.7823 - val_loss: 0.5412 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 99us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4365 - accuracy: 0.2313 - val_loss: 1.4823 - val_accuracy: 0.1731\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 1.3888 - accuracy: 0.2687 - val_loss: 1.4409 - val_accuracy: 0.2308\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 1.3477 - accuracy: 0.2959 - val_loss: 1.4027 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 1.3086 - accuracy: 0.3197 - val_loss: 1.3627 - val_accuracy: 0.2885\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 1.2731 - accuracy: 0.3741 - val_loss: 1.3237 - val_accuracy: 0.3654\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 1.2376 - accuracy: 0.4252 - val_loss: 1.2815 - val_accuracy: 0.3846\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 1.2027 - accuracy: 0.4354 - val_loss: 1.2422 - val_accuracy: 0.4231\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 1.1708 - accuracy: 0.4728 - val_loss: 1.2042 - val_accuracy: 0.4423\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 1.1401 - accuracy: 0.5068 - val_loss: 1.1641 - val_accuracy: 0.4615\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 1.1107 - accuracy: 0.5578 - val_loss: 1.1277 - val_accuracy: 0.5000\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 1.0793 - accuracy: 0.5918 - val_loss: 1.0774 - val_accuracy: 0.5769\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 1.0408 - accuracy: 0.6327 - val_loss: 1.0198 - val_accuracy: 0.6346\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.9976 - accuracy: 0.6429 - val_loss: 0.9662 - val_accuracy: 0.6346\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.9645 - accuracy: 0.6463 - val_loss: 0.9307 - val_accuracy: 0.6538\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.9366 - accuracy: 0.6735 - val_loss: 0.8991 - val_accuracy: 0.6538\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.9141 - accuracy: 0.6837 - val_loss: 0.8752 - val_accuracy: 0.6538\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.8923 - accuracy: 0.6837 - val_loss: 0.8549 - val_accuracy: 0.6923\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.8716 - accuracy: 0.6871 - val_loss: 0.8309 - val_accuracy: 0.7115\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.8519 - accuracy: 0.7143 - val_loss: 0.8107 - val_accuracy: 0.7308\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.8338 - accuracy: 0.7245 - val_loss: 0.7972 - val_accuracy: 0.7308\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.8149 - accuracy: 0.7245 - val_loss: 0.7799 - val_accuracy: 0.7308\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.7983 - accuracy: 0.7381 - val_loss: 0.7625 - val_accuracy: 0.7692\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.7829 - accuracy: 0.7415 - val_loss: 0.7475 - val_accuracy: 0.7692\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.7680 - accuracy: 0.7449 - val_loss: 0.7328 - val_accuracy: 0.7500\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 211us/step - loss: 0.7550 - accuracy: 0.7415 - val_loss: 0.7186 - val_accuracy: 0.7500\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 212us/step - loss: 0.7431 - accuracy: 0.7517 - val_loss: 0.7072 - val_accuracy: 0.7500\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.7322 - accuracy: 0.7517 - val_loss: 0.6932 - val_accuracy: 0.7500\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.7216 - accuracy: 0.7585 - val_loss: 0.6865 - val_accuracy: 0.7500\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.7122 - accuracy: 0.7585 - val_loss: 0.6729 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.7034 - accuracy: 0.7585 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.6960 - accuracy: 0.7619 - val_loss: 0.6578 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.6881 - accuracy: 0.7619 - val_loss: 0.6506 - val_accuracy: 0.7500\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.6815 - accuracy: 0.7551 - val_loss: 0.6417 - val_accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.6756 - accuracy: 0.7653 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.6693 - accuracy: 0.7653 - val_loss: 0.6300 - val_accuracy: 0.7500\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.6642 - accuracy: 0.7721 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.6580 - accuracy: 0.7653 - val_loss: 0.6192 - val_accuracy: 0.7500\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.6533 - accuracy: 0.7653 - val_loss: 0.6129 - val_accuracy: 0.7692\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.6490 - accuracy: 0.7721 - val_loss: 0.6077 - val_accuracy: 0.7692\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6446 - accuracy: 0.7721 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.6391 - accuracy: 0.7789 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.6361 - accuracy: 0.7721 - val_loss: 0.5965 - val_accuracy: 0.7692\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6326 - accuracy: 0.7755 - val_loss: 0.5941 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6279 - accuracy: 0.7789 - val_loss: 0.5946 - val_accuracy: 0.7885\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.6252 - accuracy: 0.7823 - val_loss: 0.5903 - val_accuracy: 0.7692\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.6204 - accuracy: 0.7823 - val_loss: 0.5860 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.6177 - accuracy: 0.7755 - val_loss: 0.5826 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.6137 - accuracy: 0.7789 - val_loss: 0.5831 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.6109 - accuracy: 0.7823 - val_loss: 0.5795 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.6081 - accuracy: 0.7857 - val_loss: 0.5825 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.6052 - accuracy: 0.7823 - val_loss: 0.5774 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6030 - accuracy: 0.7857 - val_loss: 0.5758 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5989 - accuracy: 0.7857 - val_loss: 0.5748 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 294us/step - loss: 0.5972 - accuracy: 0.7857 - val_loss: 0.5765 - val_accuracy: 0.7885\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5948 - accuracy: 0.7823 - val_loss: 0.5738 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5924 - accuracy: 0.7891 - val_loss: 0.5734 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5901 - accuracy: 0.7891 - val_loss: 0.5711 - val_accuracy: 0.7885\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5875 - accuracy: 0.7891 - val_loss: 0.5742 - val_accuracy: 0.7885\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5852 - accuracy: 0.7891 - val_loss: 0.5706 - val_accuracy: 0.7885\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5831 - accuracy: 0.7891 - val_loss: 0.5680 - val_accuracy: 0.7885\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.5807 - accuracy: 0.7891 - val_loss: 0.5691 - val_accuracy: 0.7885\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.5799 - accuracy: 0.7891 - val_loss: 0.5707 - val_accuracy: 0.7885\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5780 - accuracy: 0.7857 - val_loss: 0.5674 - val_accuracy: 0.7885\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 254us/step - loss: 0.5756 - accuracy: 0.7891 - val_loss: 0.5649 - val_accuracy: 0.7885\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 248us/step - loss: 0.5737 - accuracy: 0.7857 - val_loss: 0.5650 - val_accuracy: 0.7885\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5721 - accuracy: 0.7891 - val_loss: 0.5653 - val_accuracy: 0.7885\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 0.5706 - accuracy: 0.7891 - val_loss: 0.5630 - val_accuracy: 0.7885\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 247us/step - loss: 0.5705 - accuracy: 0.7891 - val_loss: 0.5656 - val_accuracy: 0.7885\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 258us/step - loss: 0.5677 - accuracy: 0.7891 - val_loss: 0.5605 - val_accuracy: 0.7885\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 255us/step - loss: 0.5658 - accuracy: 0.7857 - val_loss: 0.5614 - val_accuracy: 0.7885\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 247us/step - loss: 0.5645 - accuracy: 0.7891 - val_loss: 0.5636 - val_accuracy: 0.7885\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5635 - accuracy: 0.7857 - val_loss: 0.5649 - val_accuracy: 0.7885\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5617 - accuracy: 0.7925 - val_loss: 0.5630 - val_accuracy: 0.7885\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 241us/step - loss: 0.5599 - accuracy: 0.7891 - val_loss: 0.5607 - val_accuracy: 0.7885\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.5590 - accuracy: 0.7925 - val_loss: 0.5598 - val_accuracy: 0.7885\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5576 - accuracy: 0.7857 - val_loss: 0.5597 - val_accuracy: 0.7885\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5563 - accuracy: 0.7823 - val_loss: 0.5600 - val_accuracy: 0.7885\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5550 - accuracy: 0.7857 - val_loss: 0.5579 - val_accuracy: 0.7885\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5548 - accuracy: 0.7823 - val_loss: 0.5549 - val_accuracy: 0.7885\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5530 - accuracy: 0.7857 - val_loss: 0.5595 - val_accuracy: 0.7885\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5519 - accuracy: 0.7891 - val_loss: 0.5599 - val_accuracy: 0.7885\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5510 - accuracy: 0.7891 - val_loss: 0.5589 - val_accuracy: 0.7885\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5502 - accuracy: 0.7891 - val_loss: 0.5586 - val_accuracy: 0.7885\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5483 - accuracy: 0.7891 - val_loss: 0.5573 - val_accuracy: 0.7885\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5477 - accuracy: 0.7891 - val_loss: 0.5529 - val_accuracy: 0.8077\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.5470 - accuracy: 0.7925 - val_loss: 0.5549 - val_accuracy: 0.7885\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5455 - accuracy: 0.7891 - val_loss: 0.5526 - val_accuracy: 0.7885\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.5450 - accuracy: 0.7891 - val_loss: 0.5568 - val_accuracy: 0.7885\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5431 - accuracy: 0.7891 - val_loss: 0.5535 - val_accuracy: 0.7885\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5432 - accuracy: 0.7891 - val_loss: 0.5567 - val_accuracy: 0.7885\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5420 - accuracy: 0.7891 - val_loss: 0.5518 - val_accuracy: 0.8077\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5405 - accuracy: 0.7891 - val_loss: 0.5473 - val_accuracy: 0.8077\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5394 - accuracy: 0.7891 - val_loss: 0.5495 - val_accuracy: 0.8077\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 255us/step - loss: 0.5393 - accuracy: 0.7891 - val_loss: 0.5513 - val_accuracy: 0.7885\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5389 - accuracy: 0.7891 - val_loss: 0.5540 - val_accuracy: 0.7885\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5379 - accuracy: 0.7925 - val_loss: 0.5511 - val_accuracy: 0.7885\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5369 - accuracy: 0.7891 - val_loss: 0.5450 - val_accuracy: 0.8077\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 255us/step - loss: 0.5358 - accuracy: 0.7891 - val_loss: 0.5486 - val_accuracy: 0.8077\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5350 - accuracy: 0.7891 - val_loss: 0.5451 - val_accuracy: 0.8077\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5342 - accuracy: 0.7891 - val_loss: 0.5436 - val_accuracy: 0.8077\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5338 - accuracy: 0.7891 - val_loss: 0.5425 - val_accuracy: 0.8077\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.5326 - accuracy: 0.7891 - val_loss: 0.5453 - val_accuracy: 0.8077\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.5320 - accuracy: 0.7891 - val_loss: 0.5452 - val_accuracy: 0.8077\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.5309 - accuracy: 0.7891 - val_loss: 0.5443 - val_accuracy: 0.8077\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5306 - accuracy: 0.7891 - val_loss: 0.5426 - val_accuracy: 0.8077\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5294 - accuracy: 0.7925 - val_loss: 0.5405 - val_accuracy: 0.8077\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5289 - accuracy: 0.7891 - val_loss: 0.5417 - val_accuracy: 0.8077\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5283 - accuracy: 0.7891 - val_loss: 0.5467 - val_accuracy: 0.8077\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.5280 - accuracy: 0.7891 - val_loss: 0.5456 - val_accuracy: 0.8077\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 476us/step - loss: 0.5268 - accuracy: 0.7891 - val_loss: 0.5431 - val_accuracy: 0.8077\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 184us/step - loss: 0.5261 - accuracy: 0.7925 - val_loss: 0.5416 - val_accuracy: 0.8077\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5260 - accuracy: 0.7891 - val_loss: 0.5414 - val_accuracy: 0.8077\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5260 - accuracy: 0.7891 - val_loss: 0.5434 - val_accuracy: 0.8077\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 258us/step - loss: 0.5243 - accuracy: 0.7891 - val_loss: 0.5406 - val_accuracy: 0.8077\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.5241 - accuracy: 0.7857 - val_loss: 0.5407 - val_accuracy: 0.8077\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.5228 - accuracy: 0.7891 - val_loss: 0.5444 - val_accuracy: 0.8077\n",
      "116/116 [==============================] - 0s 77us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.4621 - accuracy: 0.3912 - val_loss: 1.5111 - val_accuracy: 0.3654\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 1.3904 - accuracy: 0.4150 - val_loss: 1.4251 - val_accuracy: 0.3462\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 1.3279 - accuracy: 0.4218 - val_loss: 1.3543 - val_accuracy: 0.3462\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 1.2733 - accuracy: 0.4456 - val_loss: 1.2929 - val_accuracy: 0.3654\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 1.2227 - accuracy: 0.4830 - val_loss: 1.2312 - val_accuracy: 0.4615\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 1.1742 - accuracy: 0.5306 - val_loss: 1.1774 - val_accuracy: 0.4615\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 1.1253 - accuracy: 0.5646 - val_loss: 1.1324 - val_accuracy: 0.4808\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 1.0810 - accuracy: 0.6020 - val_loss: 1.0880 - val_accuracy: 0.5192\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 1.0363 - accuracy: 0.6361 - val_loss: 1.0455 - val_accuracy: 0.5577\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.9959 - accuracy: 0.6429 - val_loss: 1.0092 - val_accuracy: 0.5769\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.9612 - accuracy: 0.6667 - val_loss: 0.9735 - val_accuracy: 0.6346\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.9301 - accuracy: 0.7075 - val_loss: 0.9418 - val_accuracy: 0.6538\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.9029 - accuracy: 0.6973 - val_loss: 0.9159 - val_accuracy: 0.6731\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.8810 - accuracy: 0.7041 - val_loss: 0.8920 - val_accuracy: 0.7308\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.8585 - accuracy: 0.7075 - val_loss: 0.8708 - val_accuracy: 0.7500\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.8398 - accuracy: 0.7075 - val_loss: 0.8536 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.8236 - accuracy: 0.7313 - val_loss: 0.8370 - val_accuracy: 0.7500\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.8082 - accuracy: 0.7279 - val_loss: 0.8239 - val_accuracy: 0.7692\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 708us/step - loss: 0.7941 - accuracy: 0.7313 - val_loss: 0.8078 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.7809 - accuracy: 0.7483 - val_loss: 0.7948 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.7684 - accuracy: 0.7585 - val_loss: 0.7828 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.7577 - accuracy: 0.7449 - val_loss: 0.7725 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.7477 - accuracy: 0.7585 - val_loss: 0.7657 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.7394 - accuracy: 0.7585 - val_loss: 0.7540 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.7301 - accuracy: 0.7517 - val_loss: 0.7458 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.7220 - accuracy: 0.7619 - val_loss: 0.7401 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.7133 - accuracy: 0.7585 - val_loss: 0.7312 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.7067 - accuracy: 0.7585 - val_loss: 0.7262 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.6997 - accuracy: 0.7551 - val_loss: 0.7172 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.6931 - accuracy: 0.7619 - val_loss: 0.7136 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.6872 - accuracy: 0.7619 - val_loss: 0.7070 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.6810 - accuracy: 0.7585 - val_loss: 0.6999 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.6748 - accuracy: 0.7619 - val_loss: 0.6970 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.6700 - accuracy: 0.7687 - val_loss: 0.6919 - val_accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.6657 - accuracy: 0.7653 - val_loss: 0.6861 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.6594 - accuracy: 0.7619 - val_loss: 0.6835 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6550 - accuracy: 0.7687 - val_loss: 0.6772 - val_accuracy: 0.7885\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6509 - accuracy: 0.7789 - val_loss: 0.6744 - val_accuracy: 0.7885\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 823us/step - loss: 0.6468 - accuracy: 0.7687 - val_loss: 0.6726 - val_accuracy: 0.7885\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.6428 - accuracy: 0.7619 - val_loss: 0.6674 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.6380 - accuracy: 0.7687 - val_loss: 0.6645 - val_accuracy: 0.7885\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.6350 - accuracy: 0.7721 - val_loss: 0.6610 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.6309 - accuracy: 0.7687 - val_loss: 0.6564 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.6279 - accuracy: 0.7653 - val_loss: 0.6564 - val_accuracy: 0.7885\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.6236 - accuracy: 0.7619 - val_loss: 0.6523 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.6209 - accuracy: 0.7653 - val_loss: 0.6511 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.6169 - accuracy: 0.7687 - val_loss: 0.6442 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 0.6143 - accuracy: 0.7721 - val_loss: 0.6422 - val_accuracy: 0.7885\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 517us/step - loss: 0.6109 - accuracy: 0.7687 - val_loss: 0.6393 - val_accuracy: 0.7885\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.6086 - accuracy: 0.7721 - val_loss: 0.6366 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 718us/step - loss: 0.6054 - accuracy: 0.7721 - val_loss: 0.6354 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.6029 - accuracy: 0.7755 - val_loss: 0.6318 - val_accuracy: 0.7885\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6010 - accuracy: 0.7721 - val_loss: 0.6307 - val_accuracy: 0.7885\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5974 - accuracy: 0.7687 - val_loss: 0.6280 - val_accuracy: 0.7885\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 611us/step - loss: 0.5954 - accuracy: 0.7789 - val_loss: 0.6260 - val_accuracy: 0.7885\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.5927 - accuracy: 0.7755 - val_loss: 0.6255 - val_accuracy: 0.7885\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.5900 - accuracy: 0.7755 - val_loss: 0.6220 - val_accuracy: 0.7885\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5881 - accuracy: 0.7823 - val_loss: 0.6224 - val_accuracy: 0.7885\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.5856 - accuracy: 0.7857 - val_loss: 0.6185 - val_accuracy: 0.7885\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 691us/step - loss: 0.5838 - accuracy: 0.7789 - val_loss: 0.6180 - val_accuracy: 0.7885\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.5811 - accuracy: 0.7823 - val_loss: 0.6173 - val_accuracy: 0.7885\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.5797 - accuracy: 0.7823 - val_loss: 0.6116 - val_accuracy: 0.7885\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.5778 - accuracy: 0.7857 - val_loss: 0.6123 - val_accuracy: 0.7885\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 711us/step - loss: 0.5752 - accuracy: 0.7857 - val_loss: 0.6088 - val_accuracy: 0.7885\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5734 - accuracy: 0.7857 - val_loss: 0.6096 - val_accuracy: 0.7885\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.5720 - accuracy: 0.7823 - val_loss: 0.6049 - val_accuracy: 0.7885\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 651us/step - loss: 0.5695 - accuracy: 0.7789 - val_loss: 0.6082 - val_accuracy: 0.7885\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.5674 - accuracy: 0.7823 - val_loss: 0.6031 - val_accuracy: 0.7885\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5668 - accuracy: 0.7789 - val_loss: 0.5995 - val_accuracy: 0.7885\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 890us/step - loss: 0.5643 - accuracy: 0.7857 - val_loss: 0.5968 - val_accuracy: 0.7885\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 599us/step - loss: 0.5627 - accuracy: 0.7789 - val_loss: 0.5971 - val_accuracy: 0.7885\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5619 - accuracy: 0.7857 - val_loss: 0.5984 - val_accuracy: 0.7885\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.5595 - accuracy: 0.7789 - val_loss: 0.5956 - val_accuracy: 0.7885\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5580 - accuracy: 0.7823 - val_loss: 0.5957 - val_accuracy: 0.7885\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.5561 - accuracy: 0.7823 - val_loss: 0.5954 - val_accuracy: 0.7885\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5549 - accuracy: 0.7857 - val_loss: 0.5902 - val_accuracy: 0.7885\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 672us/step - loss: 0.5536 - accuracy: 0.7823 - val_loss: 0.5937 - val_accuracy: 0.7885\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5521 - accuracy: 0.7823 - val_loss: 0.5884 - val_accuracy: 0.7885\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5504 - accuracy: 0.7857 - val_loss: 0.5910 - val_accuracy: 0.7885\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5490 - accuracy: 0.7857 - val_loss: 0.5918 - val_accuracy: 0.7885\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 796us/step - loss: 0.5479 - accuracy: 0.7857 - val_loss: 0.5918 - val_accuracy: 0.7885\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 802us/step - loss: 0.5462 - accuracy: 0.7857 - val_loss: 0.5890 - val_accuracy: 0.7885\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 699us/step - loss: 0.5453 - accuracy: 0.7857 - val_loss: 0.5873 - val_accuracy: 0.7885\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7857 - val_loss: 0.5881 - val_accuracy: 0.7885\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5435 - accuracy: 0.7789 - val_loss: 0.5879 - val_accuracy: 0.7885\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.5405 - accuracy: 0.7857 - val_loss: 0.5905 - val_accuracy: 0.7885\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.5398 - accuracy: 0.7857 - val_loss: 0.5944 - val_accuracy: 0.7885\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.5380 - accuracy: 0.7959 - val_loss: 0.5882 - val_accuracy: 0.7885\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 852us/step - loss: 0.5358 - accuracy: 0.7891 - val_loss: 0.5868 - val_accuracy: 0.7885\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5346 - accuracy: 0.7857 - val_loss: 0.5873 - val_accuracy: 0.7885\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5331 - accuracy: 0.7857 - val_loss: 0.5871 - val_accuracy: 0.7885\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5317 - accuracy: 0.7891 - val_loss: 0.5877 - val_accuracy: 0.7885\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5301 - accuracy: 0.7891 - val_loss: 0.5893 - val_accuracy: 0.7885\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5296 - accuracy: 0.7891 - val_loss: 0.5830 - val_accuracy: 0.7885\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.5275 - accuracy: 0.7891 - val_loss: 0.5836 - val_accuracy: 0.7885\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 0.5257 - accuracy: 0.7857 - val_loss: 0.5819 - val_accuracy: 0.7885\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5245 - accuracy: 0.7891 - val_loss: 0.5821 - val_accuracy: 0.7885\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.5240 - accuracy: 0.7891 - val_loss: 0.5825 - val_accuracy: 0.7885\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 652us/step - loss: 0.5218 - accuracy: 0.7891 - val_loss: 0.5817 - val_accuracy: 0.7885\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.5204 - accuracy: 0.7925 - val_loss: 0.5794 - val_accuracy: 0.7885\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5198 - accuracy: 0.7891 - val_loss: 0.5785 - val_accuracy: 0.7885\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.5186 - accuracy: 0.7891 - val_loss: 0.5767 - val_accuracy: 0.7885\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.5178 - accuracy: 0.7891 - val_loss: 0.5798 - val_accuracy: 0.7885\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5156 - accuracy: 0.7891 - val_loss: 0.5735 - val_accuracy: 0.7885\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 422us/step - loss: 0.5141 - accuracy: 0.7891 - val_loss: 0.5739 - val_accuracy: 0.7885\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5152 - accuracy: 0.7891 - val_loss: 0.5733 - val_accuracy: 0.8077\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.5125 - accuracy: 0.7891 - val_loss: 0.5722 - val_accuracy: 0.8077\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5115 - accuracy: 0.7925 - val_loss: 0.5737 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5101 - accuracy: 0.7993 - val_loss: 0.5719 - val_accuracy: 0.8077\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5102 - accuracy: 0.7959 - val_loss: 0.5676 - val_accuracy: 0.8269\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5083 - accuracy: 0.7925 - val_loss: 0.5729 - val_accuracy: 0.7885\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 469us/step - loss: 0.5075 - accuracy: 0.7925 - val_loss: 0.5701 - val_accuracy: 0.7885\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 593us/step - loss: 0.5067 - accuracy: 0.7959 - val_loss: 0.5704 - val_accuracy: 0.7885\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5054 - accuracy: 0.7925 - val_loss: 0.5711 - val_accuracy: 0.7885\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5044 - accuracy: 0.7993 - val_loss: 0.5700 - val_accuracy: 0.7885\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5038 - accuracy: 0.7993 - val_loss: 0.5686 - val_accuracy: 0.8077\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.5019 - accuracy: 0.7993 - val_loss: 0.5681 - val_accuracy: 0.7885\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.5010 - accuracy: 0.8027 - val_loss: 0.5670 - val_accuracy: 0.7885\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.5000 - accuracy: 0.7959 - val_loss: 0.5646 - val_accuracy: 0.7885\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.4986 - accuracy: 0.8027 - val_loss: 0.5654 - val_accuracy: 0.7885\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4986 - accuracy: 0.7959 - val_loss: 0.5574 - val_accuracy: 0.8269\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.4967 - accuracy: 0.7959 - val_loss: 0.5591 - val_accuracy: 0.8077\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4956 - accuracy: 0.7993 - val_loss: 0.5558 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.4944 - accuracy: 0.8027 - val_loss: 0.5560 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4938 - accuracy: 0.8027 - val_loss: 0.5546 - val_accuracy: 0.8269\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4928 - accuracy: 0.7993 - val_loss: 0.5536 - val_accuracy: 0.8269\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.4920 - accuracy: 0.7993 - val_loss: 0.5511 - val_accuracy: 0.8269\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.4908 - accuracy: 0.8027 - val_loss: 0.5537 - val_accuracy: 0.8269\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.4916 - accuracy: 0.7925 - val_loss: 0.5535 - val_accuracy: 0.8269\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.4898 - accuracy: 0.7959 - val_loss: 0.5513 - val_accuracy: 0.8269\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4890 - accuracy: 0.7959 - val_loss: 0.5546 - val_accuracy: 0.8077\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.4882 - accuracy: 0.7959 - val_loss: 0.5564 - val_accuracy: 0.8077\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.4878 - accuracy: 0.7993 - val_loss: 0.5492 - val_accuracy: 0.8269\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.4868 - accuracy: 0.7959 - val_loss: 0.5524 - val_accuracy: 0.8077\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.4859 - accuracy: 0.7959 - val_loss: 0.5526 - val_accuracy: 0.8269\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4856 - accuracy: 0.7959 - val_loss: 0.5488 - val_accuracy: 0.8269\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.4850 - accuracy: 0.7959 - val_loss: 0.5503 - val_accuracy: 0.8269\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.4839 - accuracy: 0.7959 - val_loss: 0.5476 - val_accuracy: 0.8269\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4836 - accuracy: 0.7959 - val_loss: 0.5452 - val_accuracy: 0.8269\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4821 - accuracy: 0.7993 - val_loss: 0.5470 - val_accuracy: 0.8269\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.4828 - accuracy: 0.8027 - val_loss: 0.5498 - val_accuracy: 0.8269\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.4811 - accuracy: 0.8027 - val_loss: 0.5470 - val_accuracy: 0.8269\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4806 - accuracy: 0.7993 - val_loss: 0.5476 - val_accuracy: 0.8269\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.4802 - accuracy: 0.8027 - val_loss: 0.5431 - val_accuracy: 0.8269\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 789us/step - loss: 0.4791 - accuracy: 0.7993 - val_loss: 0.5452 - val_accuracy: 0.8269\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 695us/step - loss: 0.4783 - accuracy: 0.7993 - val_loss: 0.5436 - val_accuracy: 0.8269\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.4775 - accuracy: 0.7959 - val_loss: 0.5438 - val_accuracy: 0.8269\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4770 - accuracy: 0.7993 - val_loss: 0.5460 - val_accuracy: 0.8269\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4762 - accuracy: 0.7959 - val_loss: 0.5390 - val_accuracy: 0.8269\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.4764 - accuracy: 0.7959 - val_loss: 0.5398 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 352us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4962 - accuracy: 0.2619 - val_loss: 1.4589 - val_accuracy: 0.2885\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 1.4347 - accuracy: 0.3061 - val_loss: 1.4198 - val_accuracy: 0.2692\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 1.3798 - accuracy: 0.3299 - val_loss: 1.3785 - val_accuracy: 0.2692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 1.3276 - accuracy: 0.3571 - val_loss: 1.3339 - val_accuracy: 0.2885\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 1.2762 - accuracy: 0.3469 - val_loss: 1.2933 - val_accuracy: 0.3654\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 1.2246 - accuracy: 0.4116 - val_loss: 1.2492 - val_accuracy: 0.4615\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 1.1747 - accuracy: 0.5408 - val_loss: 1.2008 - val_accuracy: 0.5769\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 1.1280 - accuracy: 0.6259 - val_loss: 1.1533 - val_accuracy: 0.6154\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 1.0832 - accuracy: 0.6769 - val_loss: 1.1032 - val_accuracy: 0.6346\n",
      "Epoch 10/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 582us/step - loss: 1.0406 - accuracy: 0.6803 - val_loss: 1.0587 - val_accuracy: 0.6346\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 709us/step - loss: 1.0002 - accuracy: 0.6871 - val_loss: 1.0115 - val_accuracy: 0.6731\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.9624 - accuracy: 0.7007 - val_loss: 0.9735 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.9278 - accuracy: 0.7143 - val_loss: 0.9398 - val_accuracy: 0.7115\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.8951 - accuracy: 0.7279 - val_loss: 0.9089 - val_accuracy: 0.7115\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.8668 - accuracy: 0.7415 - val_loss: 0.8802 - val_accuracy: 0.7308\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.8398 - accuracy: 0.7415 - val_loss: 0.8525 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 656us/step - loss: 0.8170 - accuracy: 0.7449 - val_loss: 0.8277 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.7963 - accuracy: 0.7483 - val_loss: 0.8014 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.7780 - accuracy: 0.7449 - val_loss: 0.7816 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.7610 - accuracy: 0.7517 - val_loss: 0.7668 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.7466 - accuracy: 0.7551 - val_loss: 0.7481 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.7328 - accuracy: 0.7619 - val_loss: 0.7320 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.7210 - accuracy: 0.7585 - val_loss: 0.7198 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.7087 - accuracy: 0.7619 - val_loss: 0.7032 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.6984 - accuracy: 0.7585 - val_loss: 0.6899 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.6903 - accuracy: 0.7585 - val_loss: 0.6820 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.6796 - accuracy: 0.7619 - val_loss: 0.6671 - val_accuracy: 0.8462\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 781us/step - loss: 0.6704 - accuracy: 0.7551 - val_loss: 0.6565 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.6626 - accuracy: 0.7585 - val_loss: 0.6448 - val_accuracy: 0.8654\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6525 - accuracy: 0.7585 - val_loss: 0.6336 - val_accuracy: 0.8654\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.6442 - accuracy: 0.7585 - val_loss: 0.6255 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6360 - accuracy: 0.7551 - val_loss: 0.6168 - val_accuracy: 0.8654\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.6294 - accuracy: 0.7585 - val_loss: 0.6069 - val_accuracy: 0.8846\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6239 - accuracy: 0.7585 - val_loss: 0.5989 - val_accuracy: 0.8846\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6185 - accuracy: 0.7619 - val_loss: 0.5948 - val_accuracy: 0.8654\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.6136 - accuracy: 0.7585 - val_loss: 0.5887 - val_accuracy: 0.8654\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.6099 - accuracy: 0.7585 - val_loss: 0.5847 - val_accuracy: 0.8846\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.6047 - accuracy: 0.7687 - val_loss: 0.5835 - val_accuracy: 0.8846\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.6009 - accuracy: 0.7619 - val_loss: 0.5720 - val_accuracy: 0.8654\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5976 - accuracy: 0.7619 - val_loss: 0.5727 - val_accuracy: 0.8654\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5938 - accuracy: 0.7619 - val_loss: 0.5665 - val_accuracy: 0.8654\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5901 - accuracy: 0.7653 - val_loss: 0.5652 - val_accuracy: 0.8654\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5869 - accuracy: 0.7653 - val_loss: 0.5590 - val_accuracy: 0.8654\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5840 - accuracy: 0.7619 - val_loss: 0.5604 - val_accuracy: 0.8654\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5805 - accuracy: 0.7619 - val_loss: 0.5564 - val_accuracy: 0.8654\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.5781 - accuracy: 0.7619 - val_loss: 0.5552 - val_accuracy: 0.8654\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 0.5744 - accuracy: 0.7619 - val_loss: 0.5520 - val_accuracy: 0.8654\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5727 - accuracy: 0.7619 - val_loss: 0.5493 - val_accuracy: 0.8654\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5698 - accuracy: 0.7653 - val_loss: 0.5491 - val_accuracy: 0.8654\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5671 - accuracy: 0.7687 - val_loss: 0.5449 - val_accuracy: 0.8654\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5647 - accuracy: 0.7653 - val_loss: 0.5459 - val_accuracy: 0.8654\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 641us/step - loss: 0.5623 - accuracy: 0.7687 - val_loss: 0.5400 - val_accuracy: 0.8654\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.5609 - accuracy: 0.7721 - val_loss: 0.5410 - val_accuracy: 0.8654\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5579 - accuracy: 0.7619 - val_loss: 0.5417 - val_accuracy: 0.8654\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.5560 - accuracy: 0.7687 - val_loss: 0.5368 - val_accuracy: 0.8654\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5539 - accuracy: 0.7721 - val_loss: 0.5383 - val_accuracy: 0.8654\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 666us/step - loss: 0.5517 - accuracy: 0.7687 - val_loss: 0.5383 - val_accuracy: 0.8654\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 0.5500 - accuracy: 0.7687 - val_loss: 0.5385 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5480 - accuracy: 0.7653 - val_loss: 0.5368 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5470 - accuracy: 0.7755 - val_loss: 0.5379 - val_accuracy: 0.8654\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 708us/step - loss: 0.5444 - accuracy: 0.7755 - val_loss: 0.5304 - val_accuracy: 0.8654\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5442 - accuracy: 0.7721 - val_loss: 0.5302 - val_accuracy: 0.8654\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5418 - accuracy: 0.7755 - val_loss: 0.5299 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 768us/step - loss: 0.5399 - accuracy: 0.7721 - val_loss: 0.5341 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.5385 - accuracy: 0.7755 - val_loss: 0.5292 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 436us/step - loss: 0.5367 - accuracy: 0.7721 - val_loss: 0.5274 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.5349 - accuracy: 0.7755 - val_loss: 0.5278 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5339 - accuracy: 0.7687 - val_loss: 0.5265 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.5329 - accuracy: 0.7755 - val_loss: 0.5247 - val_accuracy: 0.8654\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 840us/step - loss: 0.5312 - accuracy: 0.7755 - val_loss: 0.5243 - val_accuracy: 0.8654\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.5306 - accuracy: 0.7721 - val_loss: 0.5270 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5285 - accuracy: 0.7755 - val_loss: 0.5236 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 751us/step - loss: 0.5277 - accuracy: 0.7721 - val_loss: 0.5241 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.5258 - accuracy: 0.7687 - val_loss: 0.5243 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 786us/step - loss: 0.5252 - accuracy: 0.7755 - val_loss: 0.5182 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5241 - accuracy: 0.7687 - val_loss: 0.5223 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5235 - accuracy: 0.7755 - val_loss: 0.5182 - val_accuracy: 0.8654\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.5219 - accuracy: 0.7721 - val_loss: 0.5245 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 679us/step - loss: 0.5212 - accuracy: 0.7755 - val_loss: 0.5189 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5199 - accuracy: 0.7721 - val_loss: 0.5224 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 713us/step - loss: 0.5177 - accuracy: 0.7721 - val_loss: 0.5228 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 669us/step - loss: 0.5166 - accuracy: 0.7755 - val_loss: 0.5219 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5161 - accuracy: 0.7755 - val_loss: 0.5242 - val_accuracy: 0.8654\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.5151 - accuracy: 0.7755 - val_loss: 0.5211 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5144 - accuracy: 0.7721 - val_loss: 0.5189 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 99us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4125 - accuracy: 0.3571 - val_loss: 1.4308 - val_accuracy: 0.3269\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 1.3586 - accuracy: 0.4184 - val_loss: 1.3865 - val_accuracy: 0.4231\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 1.3133 - accuracy: 0.4524 - val_loss: 1.3443 - val_accuracy: 0.4231\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 1.2712 - accuracy: 0.4728 - val_loss: 1.3109 - val_accuracy: 0.4808\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 1.2329 - accuracy: 0.5136 - val_loss: 1.2745 - val_accuracy: 0.4808\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 1.1971 - accuracy: 0.5714 - val_loss: 1.2364 - val_accuracy: 0.5962\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 1.1602 - accuracy: 0.6293 - val_loss: 1.2048 - val_accuracy: 0.6346\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 1.1260 - accuracy: 0.6565 - val_loss: 1.1695 - val_accuracy: 0.6538\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 1.0921 - accuracy: 0.6803 - val_loss: 1.1366 - val_accuracy: 0.6538\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 1.0618 - accuracy: 0.6905 - val_loss: 1.1002 - val_accuracy: 0.6923\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 1.0327 - accuracy: 0.7007 - val_loss: 1.0707 - val_accuracy: 0.6923\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 1.0049 - accuracy: 0.7041 - val_loss: 1.0454 - val_accuracy: 0.6923\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 804us/step - loss: 0.9796 - accuracy: 0.6973 - val_loss: 1.0195 - val_accuracy: 0.7115\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.9555 - accuracy: 0.6939 - val_loss: 0.9906 - val_accuracy: 0.7308\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 691us/step - loss: 0.9328 - accuracy: 0.7109 - val_loss: 0.9668 - val_accuracy: 0.7308\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.9118 - accuracy: 0.7211 - val_loss: 0.9443 - val_accuracy: 0.7308\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.8926 - accuracy: 0.7177 - val_loss: 0.9232 - val_accuracy: 0.7500\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.8749 - accuracy: 0.7245 - val_loss: 0.9003 - val_accuracy: 0.7500\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.8590 - accuracy: 0.7279 - val_loss: 0.8823 - val_accuracy: 0.7500\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.8437 - accuracy: 0.7313 - val_loss: 0.8643 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.8293 - accuracy: 0.7347 - val_loss: 0.8435 - val_accuracy: 0.7500\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.8150 - accuracy: 0.7483 - val_loss: 0.8249 - val_accuracy: 0.7692\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.8010 - accuracy: 0.7415 - val_loss: 0.8064 - val_accuracy: 0.7500\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.7869 - accuracy: 0.7449 - val_loss: 0.7894 - val_accuracy: 0.7692\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.7694 - accuracy: 0.7415 - val_loss: 0.7745 - val_accuracy: 0.7500\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.7501 - accuracy: 0.7449 - val_loss: 0.7529 - val_accuracy: 0.7692\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.7320 - accuracy: 0.7415 - val_loss: 0.7229 - val_accuracy: 0.7692\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 552us/step - loss: 0.7160 - accuracy: 0.7449 - val_loss: 0.7079 - val_accuracy: 0.7692\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.7047 - accuracy: 0.7449 - val_loss: 0.6918 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.6950 - accuracy: 0.7483 - val_loss: 0.6773 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.6860 - accuracy: 0.7517 - val_loss: 0.6677 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.6766 - accuracy: 0.7483 - val_loss: 0.6579 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 0.6697 - accuracy: 0.7483 - val_loss: 0.6505 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.6636 - accuracy: 0.7517 - val_loss: 0.6366 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 835us/step - loss: 0.6572 - accuracy: 0.7483 - val_loss: 0.6348 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 499us/step - loss: 0.6511 - accuracy: 0.7483 - val_loss: 0.6277 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 694us/step - loss: 0.6459 - accuracy: 0.7483 - val_loss: 0.6243 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6400 - accuracy: 0.7517 - val_loss: 0.6156 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.6357 - accuracy: 0.7517 - val_loss: 0.6075 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.6299 - accuracy: 0.7551 - val_loss: 0.6054 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.6261 - accuracy: 0.7551 - val_loss: 0.6015 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.6220 - accuracy: 0.7551 - val_loss: 0.5953 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.6178 - accuracy: 0.7551 - val_loss: 0.5942 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.6145 - accuracy: 0.7551 - val_loss: 0.5898 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.6107 - accuracy: 0.7517 - val_loss: 0.5837 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.6078 - accuracy: 0.7585 - val_loss: 0.5813 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 593us/step - loss: 0.6033 - accuracy: 0.7585 - val_loss: 0.5746 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.6004 - accuracy: 0.7585 - val_loss: 0.5748 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5972 - accuracy: 0.7585 - val_loss: 0.5707 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.5938 - accuracy: 0.7619 - val_loss: 0.5645 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5911 - accuracy: 0.7619 - val_loss: 0.5628 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.5885 - accuracy: 0.7551 - val_loss: 0.5643 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 616us/step - loss: 0.5858 - accuracy: 0.7619 - val_loss: 0.5592 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.5834 - accuracy: 0.7653 - val_loss: 0.5604 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5802 - accuracy: 0.7619 - val_loss: 0.5524 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.5791 - accuracy: 0.7653 - val_loss: 0.5566 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.5748 - accuracy: 0.7653 - val_loss: 0.5509 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 0.5738 - accuracy: 0.7653 - val_loss: 0.5511 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5714 - accuracy: 0.7653 - val_loss: 0.5483 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.5695 - accuracy: 0.7687 - val_loss: 0.5413 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5668 - accuracy: 0.7721 - val_loss: 0.5430 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.5649 - accuracy: 0.7687 - val_loss: 0.5436 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.5623 - accuracy: 0.7687 - val_loss: 0.5379 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 700us/step - loss: 0.5610 - accuracy: 0.7721 - val_loss: 0.5358 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.5595 - accuracy: 0.7687 - val_loss: 0.5356 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 184us/step - loss: 0.5573 - accuracy: 0.7721 - val_loss: 0.5361 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 571us/step - loss: 0.5557 - accuracy: 0.7721 - val_loss: 0.5411 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 752us/step - loss: 0.5537 - accuracy: 0.7721 - val_loss: 0.5383 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.5530 - accuracy: 0.7721 - val_loss: 0.5338 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 622us/step - loss: 0.5504 - accuracy: 0.7721 - val_loss: 0.5321 - val_accuracy: 0.8654\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.5481 - accuracy: 0.7721 - val_loss: 0.5309 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5468 - accuracy: 0.7687 - val_loss: 0.5305 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 837us/step - loss: 0.5454 - accuracy: 0.7687 - val_loss: 0.5345 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 614us/step - loss: 0.5444 - accuracy: 0.7687 - val_loss: 0.5280 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 842us/step - loss: 0.5431 - accuracy: 0.7721 - val_loss: 0.5262 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 699us/step - loss: 0.5415 - accuracy: 0.7721 - val_loss: 0.5289 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 833us/step - loss: 0.5404 - accuracy: 0.7721 - val_loss: 0.5251 - val_accuracy: 0.8654\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 790us/step - loss: 0.5386 - accuracy: 0.7653 - val_loss: 0.5272 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 0.5367 - accuracy: 0.7687 - val_loss: 0.5234 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.5371 - accuracy: 0.7653 - val_loss: 0.5254 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 756us/step - loss: 0.5343 - accuracy: 0.7653 - val_loss: 0.5234 - val_accuracy: 0.8654\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5340 - accuracy: 0.7653 - val_loss: 0.5257 - val_accuracy: 0.8654\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5318 - accuracy: 0.7653 - val_loss: 0.5207 - val_accuracy: 0.8654\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.5316 - accuracy: 0.7687 - val_loss: 0.5158 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5297 - accuracy: 0.7687 - val_loss: 0.5183 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5287 - accuracy: 0.7721 - val_loss: 0.5215 - val_accuracy: 0.8654\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5277 - accuracy: 0.7721 - val_loss: 0.5212 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5258 - accuracy: 0.7721 - val_loss: 0.5217 - val_accuracy: 0.8654\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5254 - accuracy: 0.7687 - val_loss: 0.5217 - val_accuracy: 0.8654\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 207us/step - loss: 0.5256 - accuracy: 0.7653 - val_loss: 0.5257 - val_accuracy: 0.8654\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5226 - accuracy: 0.7721 - val_loss: 0.5177 - val_accuracy: 0.8654\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 817us/step - loss: 0.5222 - accuracy: 0.7687 - val_loss: 0.5180 - val_accuracy: 0.8654\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 0.5218 - accuracy: 0.7687 - val_loss: 0.5178 - val_accuracy: 0.8654\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5211 - accuracy: 0.7721 - val_loss: 0.5187 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 122us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 4ms/step - loss: 1.5344 - accuracy: 0.1463 - val_loss: 1.4943 - val_accuracy: 0.1154\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 1.4632 - accuracy: 0.1565 - val_loss: 1.4305 - val_accuracy: 0.1731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 1.4082 - accuracy: 0.1905 - val_loss: 1.3838 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 680us/step - loss: 1.3625 - accuracy: 0.2279 - val_loss: 1.3394 - val_accuracy: 0.3269\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 651us/step - loss: 1.3229 - accuracy: 0.2925 - val_loss: 1.3019 - val_accuracy: 0.3654\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 831us/step - loss: 1.2845 - accuracy: 0.3844 - val_loss: 1.2619 - val_accuracy: 0.4808\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 963us/step - loss: 1.2481 - accuracy: 0.4694 - val_loss: 1.2253 - val_accuracy: 0.5769\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 622us/step - loss: 1.2135 - accuracy: 0.5068 - val_loss: 1.1911 - val_accuracy: 0.5769\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 955us/step - loss: 1.1794 - accuracy: 0.5714 - val_loss: 1.1555 - val_accuracy: 0.6154\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 740us/step - loss: 1.1436 - accuracy: 0.5952 - val_loss: 1.1195 - val_accuracy: 0.6538\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 949us/step - loss: 1.1090 - accuracy: 0.6463 - val_loss: 1.0832 - val_accuracy: 0.6346\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 736us/step - loss: 1.0752 - accuracy: 0.6667 - val_loss: 1.0504 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 873us/step - loss: 1.0428 - accuracy: 0.6803 - val_loss: 1.0152 - val_accuracy: 0.6923\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 849us/step - loss: 1.0115 - accuracy: 0.6769 - val_loss: 0.9864 - val_accuracy: 0.6923\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 747us/step - loss: 0.9815 - accuracy: 0.6871 - val_loss: 0.9554 - val_accuracy: 0.7308\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 775us/step - loss: 0.9544 - accuracy: 0.7041 - val_loss: 0.9293 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 642us/step - loss: 0.9282 - accuracy: 0.7143 - val_loss: 0.9039 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.9047 - accuracy: 0.7245 - val_loss: 0.8782 - val_accuracy: 0.7692\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.7211 - val_loss: 0.8602 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 742us/step - loss: 0.8616 - accuracy: 0.7245 - val_loss: 0.8394 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 650us/step - loss: 0.8431 - accuracy: 0.7245 - val_loss: 0.8196 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 599us/step - loss: 0.8241 - accuracy: 0.7381 - val_loss: 0.8058 - val_accuracy: 0.7692\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 759us/step - loss: 0.8065 - accuracy: 0.7347 - val_loss: 0.7906 - val_accuracy: 0.7692\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 851us/step - loss: 0.7905 - accuracy: 0.7347 - val_loss: 0.7731 - val_accuracy: 0.7692\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 764us/step - loss: 0.7762 - accuracy: 0.7347 - val_loss: 0.7569 - val_accuracy: 0.7692\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 774us/step - loss: 0.7626 - accuracy: 0.7415 - val_loss: 0.7444 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 863us/step - loss: 0.7504 - accuracy: 0.7415 - val_loss: 0.7330 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.7382 - accuracy: 0.7483 - val_loss: 0.7214 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.7483 - val_loss: 0.7114 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.7483 - val_loss: 0.6983 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.7082 - accuracy: 0.7551 - val_loss: 0.6909 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.7449 - val_loss: 0.6844 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.6922 - accuracy: 0.7517 - val_loss: 0.6737 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.6853 - accuracy: 0.7517 - val_loss: 0.6662 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.6779 - accuracy: 0.7585 - val_loss: 0.6593 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.6711 - accuracy: 0.7483 - val_loss: 0.6531 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.6655 - accuracy: 0.7517 - val_loss: 0.6482 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.6591 - accuracy: 0.7551 - val_loss: 0.6409 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.6550 - accuracy: 0.7619 - val_loss: 0.6359 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.6480 - accuracy: 0.7483 - val_loss: 0.6339 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.6433 - accuracy: 0.7449 - val_loss: 0.6255 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 912us/step - loss: 0.6382 - accuracy: 0.7585 - val_loss: 0.6202 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 917us/step - loss: 0.6351 - accuracy: 0.7653 - val_loss: 0.6113 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 846us/step - loss: 0.6301 - accuracy: 0.7687 - val_loss: 0.6115 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.6248 - accuracy: 0.7721 - val_loss: 0.6057 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.6218 - accuracy: 0.7755 - val_loss: 0.6046 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 752us/step - loss: 0.6164 - accuracy: 0.7653 - val_loss: 0.6008 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 892us/step - loss: 0.6149 - accuracy: 0.7823 - val_loss: 0.5930 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 781us/step - loss: 0.6103 - accuracy: 0.7823 - val_loss: 0.5921 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.6051 - accuracy: 0.7755 - val_loss: 0.5903 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.6023 - accuracy: 0.7823 - val_loss: 0.5856 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 690us/step - loss: 0.5988 - accuracy: 0.7755 - val_loss: 0.5856 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 605us/step - loss: 0.5970 - accuracy: 0.7857 - val_loss: 0.5811 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5928 - accuracy: 0.7789 - val_loss: 0.5746 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.5901 - accuracy: 0.7857 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5861 - accuracy: 0.7857 - val_loss: 0.5689 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.5839 - accuracy: 0.7823 - val_loss: 0.5707 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 0.5805 - accuracy: 0.7823 - val_loss: 0.5667 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5776 - accuracy: 0.7857 - val_loss: 0.5655 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5763 - accuracy: 0.7891 - val_loss: 0.5616 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.5747 - accuracy: 0.7857 - val_loss: 0.5615 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 652us/step - loss: 0.5702 - accuracy: 0.7891 - val_loss: 0.5610 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5679 - accuracy: 0.7891 - val_loss: 0.5573 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5660 - accuracy: 0.7891 - val_loss: 0.5556 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5635 - accuracy: 0.7891 - val_loss: 0.5573 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5617 - accuracy: 0.7891 - val_loss: 0.5525 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5594 - accuracy: 0.7891 - val_loss: 0.5537 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5564 - accuracy: 0.7891 - val_loss: 0.5526 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 627us/step - loss: 0.5553 - accuracy: 0.7891 - val_loss: 0.5529 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.5527 - accuracy: 0.7891 - val_loss: 0.5497 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5516 - accuracy: 0.7891 - val_loss: 0.5461 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5495 - accuracy: 0.7891 - val_loss: 0.5470 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 709us/step - loss: 0.5468 - accuracy: 0.7925 - val_loss: 0.5465 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 603us/step - loss: 0.5475 - accuracy: 0.7891 - val_loss: 0.5427 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 929us/step - loss: 0.5444 - accuracy: 0.7857 - val_loss: 0.5473 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 808us/step - loss: 0.5423 - accuracy: 0.7925 - val_loss: 0.5435 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 788us/step - loss: 0.5408 - accuracy: 0.7857 - val_loss: 0.5425 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 866us/step - loss: 0.5392 - accuracy: 0.7857 - val_loss: 0.5412 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 760us/step - loss: 0.5376 - accuracy: 0.7857 - val_loss: 0.5417 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 791us/step - loss: 0.5361 - accuracy: 0.7857 - val_loss: 0.5426 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 688us/step - loss: 0.5348 - accuracy: 0.7857 - val_loss: 0.5427 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 0.5328 - accuracy: 0.7891 - val_loss: 0.5367 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 671us/step - loss: 0.5310 - accuracy: 0.7891 - val_loss: 0.5398 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.5294 - accuracy: 0.7857 - val_loss: 0.5396 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5284 - accuracy: 0.7891 - val_loss: 0.5340 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.5282 - accuracy: 0.7857 - val_loss: 0.5322 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5255 - accuracy: 0.7857 - val_loss: 0.5321 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5244 - accuracy: 0.7925 - val_loss: 0.5348 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5251 - accuracy: 0.7823 - val_loss: 0.5323 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5226 - accuracy: 0.7925 - val_loss: 0.5328 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5204 - accuracy: 0.7857 - val_loss: 0.5362 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5196 - accuracy: 0.7857 - val_loss: 0.5318 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 0.5188 - accuracy: 0.7857 - val_loss: 0.5310 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5171 - accuracy: 0.7857 - val_loss: 0.5292 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5165 - accuracy: 0.7857 - val_loss: 0.5306 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5145 - accuracy: 0.7857 - val_loss: 0.5301 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.5132 - accuracy: 0.7857 - val_loss: 0.5262 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5138 - accuracy: 0.7857 - val_loss: 0.5303 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.5119 - accuracy: 0.7891 - val_loss: 0.5280 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 660us/step - loss: 0.5111 - accuracy: 0.7857 - val_loss: 0.5301 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5095 - accuracy: 0.7925 - val_loss: 0.5245 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5090 - accuracy: 0.7925 - val_loss: 0.5252 - val_accuracy: 0.8269\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5076 - accuracy: 0.7891 - val_loss: 0.5259 - val_accuracy: 0.8269\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5080 - accuracy: 0.7857 - val_loss: 0.5232 - val_accuracy: 0.8269\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5061 - accuracy: 0.7925 - val_loss: 0.5285 - val_accuracy: 0.8269\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.5043 - accuracy: 0.7857 - val_loss: 0.5272 - val_accuracy: 0.8269\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5049 - accuracy: 0.7891 - val_loss: 0.5289 - val_accuracy: 0.8269\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.5031 - accuracy: 0.7891 - val_loss: 0.5240 - val_accuracy: 0.8269\n",
      "Epoch 109/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 285us/step - loss: 0.5028 - accuracy: 0.7959 - val_loss: 0.5205 - val_accuracy: 0.8269\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5019 - accuracy: 0.7959 - val_loss: 0.5220 - val_accuracy: 0.8269\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4997 - accuracy: 0.7925 - val_loss: 0.5256 - val_accuracy: 0.8269\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4991 - accuracy: 0.7891 - val_loss: 0.5247 - val_accuracy: 0.8269\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4993 - accuracy: 0.7925 - val_loss: 0.5252 - val_accuracy: 0.8269\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.4977 - accuracy: 0.7925 - val_loss: 0.5252 - val_accuracy: 0.8269\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.4974 - accuracy: 0.7857 - val_loss: 0.5283 - val_accuracy: 0.8269\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.4957 - accuracy: 0.7891 - val_loss: 0.5256 - val_accuracy: 0.8269\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 0.4957 - accuracy: 0.7891 - val_loss: 0.5286 - val_accuracy: 0.8269\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.4946 - accuracy: 0.7925 - val_loss: 0.5258 - val_accuracy: 0.8269\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.4939 - accuracy: 0.7891 - val_loss: 0.5267 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 172us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.5581 - accuracy: 0.2517 - val_loss: 1.5237 - val_accuracy: 0.2308\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 1.4660 - accuracy: 0.2823 - val_loss: 1.4391 - val_accuracy: 0.2885\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 1.3993 - accuracy: 0.3163 - val_loss: 1.3764 - val_accuracy: 0.3462\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 1.3459 - accuracy: 0.3401 - val_loss: 1.3121 - val_accuracy: 0.4231\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 746us/step - loss: 1.2952 - accuracy: 0.3912 - val_loss: 1.2498 - val_accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 696us/step - loss: 1.2465 - accuracy: 0.3980 - val_loss: 1.1890 - val_accuracy: 0.5192\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 1.1997 - accuracy: 0.4490 - val_loss: 1.1382 - val_accuracy: 0.5962\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 1.1550 - accuracy: 0.4626 - val_loss: 1.0852 - val_accuracy: 0.5962\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 1.1111 - accuracy: 0.4830 - val_loss: 1.0496 - val_accuracy: 0.5577\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 739us/step - loss: 1.0744 - accuracy: 0.5476 - val_loss: 1.0187 - val_accuracy: 0.6154\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 656us/step - loss: 1.0415 - accuracy: 0.5816 - val_loss: 0.9969 - val_accuracy: 0.6538\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 1.0112 - accuracy: 0.6122 - val_loss: 0.9727 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.9816 - accuracy: 0.6259 - val_loss: 0.9417 - val_accuracy: 0.7115\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.9532 - accuracy: 0.6599 - val_loss: 0.9220 - val_accuracy: 0.6923\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.9289 - accuracy: 0.6599 - val_loss: 0.9044 - val_accuracy: 0.6923\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.9031 - accuracy: 0.6905 - val_loss: 0.8803 - val_accuracy: 0.6923\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.8789 - accuracy: 0.6973 - val_loss: 0.8623 - val_accuracy: 0.6731\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.8558 - accuracy: 0.7075 - val_loss: 0.8376 - val_accuracy: 0.7115\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.8343 - accuracy: 0.7109 - val_loss: 0.8221 - val_accuracy: 0.7308\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.8116 - accuracy: 0.7109 - val_loss: 0.7975 - val_accuracy: 0.7500\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.7892 - accuracy: 0.7109 - val_loss: 0.7765 - val_accuracy: 0.7500\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 611us/step - loss: 0.7696 - accuracy: 0.7109 - val_loss: 0.7554 - val_accuracy: 0.7500\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.7520 - accuracy: 0.7109 - val_loss: 0.7397 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.7367 - accuracy: 0.7279 - val_loss: 0.7288 - val_accuracy: 0.7308\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.7212 - accuracy: 0.7279 - val_loss: 0.7157 - val_accuracy: 0.7692\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 542us/step - loss: 0.7094 - accuracy: 0.7211 - val_loss: 0.7037 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.6965 - accuracy: 0.7245 - val_loss: 0.6900 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.6856 - accuracy: 0.7279 - val_loss: 0.6834 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.6739 - accuracy: 0.7415 - val_loss: 0.6680 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.6640 - accuracy: 0.7415 - val_loss: 0.6570 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 642us/step - loss: 0.6548 - accuracy: 0.7483 - val_loss: 0.6491 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 0.6475 - accuracy: 0.7483 - val_loss: 0.6476 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.6396 - accuracy: 0.7517 - val_loss: 0.6337 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.6335 - accuracy: 0.7449 - val_loss: 0.6235 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6266 - accuracy: 0.7483 - val_loss: 0.6195 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.6208 - accuracy: 0.7517 - val_loss: 0.6138 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 854us/step - loss: 0.6148 - accuracy: 0.7551 - val_loss: 0.6128 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.6099 - accuracy: 0.7483 - val_loss: 0.6079 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.6046 - accuracy: 0.7483 - val_loss: 0.6012 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.6008 - accuracy: 0.7449 - val_loss: 0.5933 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5961 - accuracy: 0.7449 - val_loss: 0.5881 - val_accuracy: 0.8654\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5923 - accuracy: 0.7483 - val_loss: 0.5842 - val_accuracy: 0.8654\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 660us/step - loss: 0.5879 - accuracy: 0.7551 - val_loss: 0.5835 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.5843 - accuracy: 0.7551 - val_loss: 0.5793 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 493us/step - loss: 0.5818 - accuracy: 0.7517 - val_loss: 0.5743 - val_accuracy: 0.8654\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 634us/step - loss: 0.5773 - accuracy: 0.7551 - val_loss: 0.5738 - val_accuracy: 0.8654\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5744 - accuracy: 0.7619 - val_loss: 0.5722 - val_accuracy: 0.8654\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.5716 - accuracy: 0.7619 - val_loss: 0.5664 - val_accuracy: 0.8654\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5682 - accuracy: 0.7585 - val_loss: 0.5663 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5657 - accuracy: 0.7585 - val_loss: 0.5602 - val_accuracy: 0.8654\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5635 - accuracy: 0.7551 - val_loss: 0.5578 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5606 - accuracy: 0.7551 - val_loss: 0.5545 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5582 - accuracy: 0.7619 - val_loss: 0.5562 - val_accuracy: 0.8654\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5557 - accuracy: 0.7619 - val_loss: 0.5551 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.5540 - accuracy: 0.7653 - val_loss: 0.5530 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5527 - accuracy: 0.7687 - val_loss: 0.5440 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5485 - accuracy: 0.7687 - val_loss: 0.5507 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5465 - accuracy: 0.7653 - val_loss: 0.5443 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5454 - accuracy: 0.7721 - val_loss: 0.5442 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5437 - accuracy: 0.7687 - val_loss: 0.5394 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5418 - accuracy: 0.7789 - val_loss: 0.5446 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.5387 - accuracy: 0.7721 - val_loss: 0.5370 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5377 - accuracy: 0.7687 - val_loss: 0.5373 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5346 - accuracy: 0.7687 - val_loss: 0.5358 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5337 - accuracy: 0.7755 - val_loss: 0.5340 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5321 - accuracy: 0.7687 - val_loss: 0.5350 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5304 - accuracy: 0.7653 - val_loss: 0.5297 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5281 - accuracy: 0.7755 - val_loss: 0.5323 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.5262 - accuracy: 0.7755 - val_loss: 0.5317 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5248 - accuracy: 0.7789 - val_loss: 0.5307 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.5244 - accuracy: 0.7789 - val_loss: 0.5323 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5222 - accuracy: 0.7755 - val_loss: 0.5278 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 639us/step - loss: 0.5214 - accuracy: 0.7687 - val_loss: 0.5323 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 0.5198 - accuracy: 0.7721 - val_loss: 0.5311 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 597us/step - loss: 0.5178 - accuracy: 0.7823 - val_loss: 0.5275 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.5174 - accuracy: 0.7789 - val_loss: 0.5242 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5152 - accuracy: 0.7789 - val_loss: 0.5243 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 656us/step - loss: 0.5140 - accuracy: 0.7789 - val_loss: 0.5284 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.5138 - accuracy: 0.7721 - val_loss: 0.5252 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5113 - accuracy: 0.7755 - val_loss: 0.5240 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5109 - accuracy: 0.7755 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5103 - accuracy: 0.7823 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5088 - accuracy: 0.7789 - val_loss: 0.5202 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.5073 - accuracy: 0.7823 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5062 - accuracy: 0.7789 - val_loss: 0.5186 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.5049 - accuracy: 0.7789 - val_loss: 0.5183 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.5042 - accuracy: 0.7823 - val_loss: 0.5133 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5026 - accuracy: 0.7891 - val_loss: 0.5164 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 232us/step - loss: 0.5032 - accuracy: 0.7789 - val_loss: 0.5150 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5004 - accuracy: 0.7823 - val_loss: 0.5170 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4999 - accuracy: 0.7823 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.4985 - accuracy: 0.7789 - val_loss: 0.5151 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.4992 - accuracy: 0.7721 - val_loss: 0.5136 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.4982 - accuracy: 0.7755 - val_loss: 0.5125 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4962 - accuracy: 0.7789 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.4956 - accuracy: 0.7823 - val_loss: 0.5154 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 701us/step - loss: 0.4939 - accuracy: 0.7823 - val_loss: 0.5099 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4928 - accuracy: 0.7755 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4928 - accuracy: 0.7823 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4908 - accuracy: 0.7789 - val_loss: 0.5123 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 413us/step - loss: 0.4911 - accuracy: 0.7823 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4897 - accuracy: 0.7789 - val_loss: 0.5120 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4889 - accuracy: 0.7789 - val_loss: 0.5094 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.4873 - accuracy: 0.7721 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.4867 - accuracy: 0.7789 - val_loss: 0.5126 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.4876 - accuracy: 0.7857 - val_loss: 0.5082 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.4859 - accuracy: 0.7823 - val_loss: 0.5099 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4844 - accuracy: 0.7823 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.4834 - accuracy: 0.7823 - val_loss: 0.5063 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 665us/step - loss: 0.4830 - accuracy: 0.7857 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4814 - accuracy: 0.7823 - val_loss: 0.5060 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.4815 - accuracy: 0.7823 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.4809 - accuracy: 0.7823 - val_loss: 0.5071 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4786 - accuracy: 0.7891 - val_loss: 0.5064 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.4786 - accuracy: 0.7857 - val_loss: 0.5017 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4784 - accuracy: 0.7857 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.4779 - accuracy: 0.7891 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 764us/step - loss: 0.4767 - accuracy: 0.7823 - val_loss: 0.5069 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.4762 - accuracy: 0.7857 - val_loss: 0.5041 - val_accuracy: 0.8462\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.4750 - accuracy: 0.7857 - val_loss: 0.5044 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.4743 - accuracy: 0.7857 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.4747 - accuracy: 0.7789 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.4728 - accuracy: 0.7891 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.4717 - accuracy: 0.7857 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.4733 - accuracy: 0.7857 - val_loss: 0.5038 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 193us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4628 - accuracy: 0.2551 - val_loss: 1.5453 - val_accuracy: 0.2500\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 1.3758 - accuracy: 0.3639 - val_loss: 1.4491 - val_accuracy: 0.3269\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 1.3010 - accuracy: 0.4150 - val_loss: 1.3658 - val_accuracy: 0.3654\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 1.2354 - accuracy: 0.4592 - val_loss: 1.2903 - val_accuracy: 0.4615\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 1.1762 - accuracy: 0.5306 - val_loss: 1.2240 - val_accuracy: 0.5385\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 1.1201 - accuracy: 0.6190 - val_loss: 1.1600 - val_accuracy: 0.6346\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 1.0690 - accuracy: 0.6599 - val_loss: 1.1050 - val_accuracy: 0.6346\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 1.0253 - accuracy: 0.6633 - val_loss: 1.0569 - val_accuracy: 0.6346\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.9856 - accuracy: 0.6599 - val_loss: 1.0174 - val_accuracy: 0.6346\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.9502 - accuracy: 0.6871 - val_loss: 0.9816 - val_accuracy: 0.6346\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.9193 - accuracy: 0.6973 - val_loss: 0.9462 - val_accuracy: 0.6346\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.8933 - accuracy: 0.6939 - val_loss: 0.9161 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.8688 - accuracy: 0.7041 - val_loss: 0.8977 - val_accuracy: 0.7115\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.8447 - accuracy: 0.6973 - val_loss: 0.8739 - val_accuracy: 0.7308\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.8239 - accuracy: 0.7075 - val_loss: 0.8568 - val_accuracy: 0.7308\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.8050 - accuracy: 0.7177 - val_loss: 0.8372 - val_accuracy: 0.7308\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.7874 - accuracy: 0.7245 - val_loss: 0.8244 - val_accuracy: 0.7500\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.7702 - accuracy: 0.7347 - val_loss: 0.8075 - val_accuracy: 0.7308\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 707us/step - loss: 0.7539 - accuracy: 0.7415 - val_loss: 0.7950 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.7385 - accuracy: 0.7415 - val_loss: 0.7787 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.7234 - accuracy: 0.7415 - val_loss: 0.7749 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.7096 - accuracy: 0.7517 - val_loss: 0.7582 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 632us/step - loss: 0.6950 - accuracy: 0.7551 - val_loss: 0.7430 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.6837 - accuracy: 0.7619 - val_loss: 0.7367 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.6734 - accuracy: 0.7619 - val_loss: 0.7223 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.6645 - accuracy: 0.7619 - val_loss: 0.7085 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.6567 - accuracy: 0.7585 - val_loss: 0.6971 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 837us/step - loss: 0.6483 - accuracy: 0.7653 - val_loss: 0.6885 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.6414 - accuracy: 0.7721 - val_loss: 0.6810 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 700us/step - loss: 0.6350 - accuracy: 0.7687 - val_loss: 0.6667 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 424us/step - loss: 0.6278 - accuracy: 0.7653 - val_loss: 0.6682 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.6228 - accuracy: 0.7721 - val_loss: 0.6635 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 0.6191 - accuracy: 0.7721 - val_loss: 0.6488 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.6126 - accuracy: 0.7721 - val_loss: 0.6461 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.6094 - accuracy: 0.7721 - val_loss: 0.6358 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6044 - accuracy: 0.7721 - val_loss: 0.6291 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.6014 - accuracy: 0.7721 - val_loss: 0.6281 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.5948 - accuracy: 0.7789 - val_loss: 0.6181 - val_accuracy: 0.7885\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5912 - accuracy: 0.7755 - val_loss: 0.6127 - val_accuracy: 0.7885\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5884 - accuracy: 0.7755 - val_loss: 0.6103 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5850 - accuracy: 0.7755 - val_loss: 0.6057 - val_accuracy: 0.7885\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5821 - accuracy: 0.7721 - val_loss: 0.6028 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5783 - accuracy: 0.7721 - val_loss: 0.5942 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5775 - accuracy: 0.7789 - val_loss: 0.5922 - val_accuracy: 0.7885\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5728 - accuracy: 0.7823 - val_loss: 0.5901 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5701 - accuracy: 0.7755 - val_loss: 0.5907 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5684 - accuracy: 0.7755 - val_loss: 0.5851 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 542us/step - loss: 0.5659 - accuracy: 0.7789 - val_loss: 0.5816 - val_accuracy: 0.7885\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5635 - accuracy: 0.7755 - val_loss: 0.5791 - val_accuracy: 0.7885\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5609 - accuracy: 0.7789 - val_loss: 0.5757 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 795us/step - loss: 0.5598 - accuracy: 0.7789 - val_loss: 0.5705 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.5577 - accuracy: 0.7823 - val_loss: 0.5715 - val_accuracy: 0.7885\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5549 - accuracy: 0.7823 - val_loss: 0.5661 - val_accuracy: 0.7885\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5537 - accuracy: 0.7789 - val_loss: 0.5623 - val_accuracy: 0.7885\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5522 - accuracy: 0.7789 - val_loss: 0.5648 - val_accuracy: 0.7885\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 712us/step - loss: 0.5506 - accuracy: 0.7823 - val_loss: 0.5590 - val_accuracy: 0.7885\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5487 - accuracy: 0.7823 - val_loss: 0.5558 - val_accuracy: 0.7885\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.5470 - accuracy: 0.7789 - val_loss: 0.5577 - val_accuracy: 0.7885\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.5457 - accuracy: 0.7789 - val_loss: 0.5536 - val_accuracy: 0.7885\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5433 - accuracy: 0.7789 - val_loss: 0.5526 - val_accuracy: 0.7885\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5422 - accuracy: 0.7789 - val_loss: 0.5486 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5407 - accuracy: 0.7789 - val_loss: 0.5478 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5393 - accuracy: 0.7789 - val_loss: 0.5480 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5388 - accuracy: 0.7857 - val_loss: 0.5434 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.5370 - accuracy: 0.7857 - val_loss: 0.5450 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 201us/step - loss: 0.5357 - accuracy: 0.7789 - val_loss: 0.5437 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5338 - accuracy: 0.7789 - val_loss: 0.5400 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 636us/step - loss: 0.5339 - accuracy: 0.7789 - val_loss: 0.5366 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 762us/step - loss: 0.5322 - accuracy: 0.7823 - val_loss: 0.5394 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5316 - accuracy: 0.7857 - val_loss: 0.5374 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5295 - accuracy: 0.7823 - val_loss: 0.5346 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5283 - accuracy: 0.7789 - val_loss: 0.5335 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5268 - accuracy: 0.7857 - val_loss: 0.5324 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.5264 - accuracy: 0.7891 - val_loss: 0.5295 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5247 - accuracy: 0.7857 - val_loss: 0.5303 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5239 - accuracy: 0.7823 - val_loss: 0.5266 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.5234 - accuracy: 0.7891 - val_loss: 0.5262 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5218 - accuracy: 0.7891 - val_loss: 0.5232 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5211 - accuracy: 0.7891 - val_loss: 0.5269 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5207 - accuracy: 0.7857 - val_loss: 0.5222 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.5190 - accuracy: 0.7857 - val_loss: 0.5236 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5182 - accuracy: 0.7891 - val_loss: 0.5246 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5170 - accuracy: 0.7891 - val_loss: 0.5281 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.5158 - accuracy: 0.7891 - val_loss: 0.5224 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.5172 - accuracy: 0.7959 - val_loss: 0.5165 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5141 - accuracy: 0.7959 - val_loss: 0.5177 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 362us/step - loss: 0.5126 - accuracy: 0.7891 - val_loss: 0.5216 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5116 - accuracy: 0.7891 - val_loss: 0.5237 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5108 - accuracy: 0.7891 - val_loss: 0.5190 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5106 - accuracy: 0.7891 - val_loss: 0.5233 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 756us/step - loss: 0.5099 - accuracy: 0.7891 - val_loss: 0.5188 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 618us/step - loss: 0.5083 - accuracy: 0.7959 - val_loss: 0.5138 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.5085 - accuracy: 0.7925 - val_loss: 0.5182 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5080 - accuracy: 0.7857 - val_loss: 0.5209 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5055 - accuracy: 0.7959 - val_loss: 0.5091 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 615us/step - loss: 0.5063 - accuracy: 0.7959 - val_loss: 0.5142 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5036 - accuracy: 0.7959 - val_loss: 0.5093 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5031 - accuracy: 0.7993 - val_loss: 0.5065 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5018 - accuracy: 0.7993 - val_loss: 0.5093 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5027 - accuracy: 0.7959 - val_loss: 0.5116 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.5019 - accuracy: 0.7959 - val_loss: 0.5158 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.5004 - accuracy: 0.7993 - val_loss: 0.5058 - val_accuracy: 0.8269\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4984 - accuracy: 0.7993 - val_loss: 0.5059 - val_accuracy: 0.8269\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.4972 - accuracy: 0.7959 - val_loss: 0.5075 - val_accuracy: 0.8269\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.4974 - accuracy: 0.7959 - val_loss: 0.5097 - val_accuracy: 0.8269\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.4965 - accuracy: 0.7993 - val_loss: 0.5005 - val_accuracy: 0.8269\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 643us/step - loss: 0.4953 - accuracy: 0.7993 - val_loss: 0.5036 - val_accuracy: 0.8269\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.4944 - accuracy: 0.7993 - val_loss: 0.5032 - val_accuracy: 0.8269\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.4948 - accuracy: 0.7959 - val_loss: 0.5093 - val_accuracy: 0.8269\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.4931 - accuracy: 0.7993 - val_loss: 0.5060 - val_accuracy: 0.8269\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4916 - accuracy: 0.7993 - val_loss: 0.5005 - val_accuracy: 0.8269\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.4919 - accuracy: 0.7993 - val_loss: 0.4995 - val_accuracy: 0.8269\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.4909 - accuracy: 0.7993 - val_loss: 0.5012 - val_accuracy: 0.8269\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.4900 - accuracy: 0.7993 - val_loss: 0.5025 - val_accuracy: 0.8269\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.4886 - accuracy: 0.7993 - val_loss: 0.5050 - val_accuracy: 0.8269\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4876 - accuracy: 0.7993 - val_loss: 0.4984 - val_accuracy: 0.8269\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.4871 - accuracy: 0.7993 - val_loss: 0.5030 - val_accuracy: 0.8269\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 633us/step - loss: 0.4867 - accuracy: 0.7993 - val_loss: 0.5007 - val_accuracy: 0.8269\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4851 - accuracy: 0.7993 - val_loss: 0.5054 - val_accuracy: 0.8269\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.4846 - accuracy: 0.7993 - val_loss: 0.5022 - val_accuracy: 0.8269\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.4837 - accuracy: 0.7993 - val_loss: 0.5012 - val_accuracy: 0.8269\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.4823 - accuracy: 0.7993 - val_loss: 0.5030 - val_accuracy: 0.8269\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4811 - accuracy: 0.7993 - val_loss: 0.4998 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.4802 - accuracy: 0.7993 - val_loss: 0.5020 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.4798 - accuracy: 0.7993 - val_loss: 0.5008 - val_accuracy: 0.8269\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4794 - accuracy: 0.7993 - val_loss: 0.4993 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 91us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.6414 - accuracy: 0.2075 - val_loss: 1.5364 - val_accuracy: 0.1538\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 1.5139 - accuracy: 0.2075 - val_loss: 1.4242 - val_accuracy: 0.1731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 1.4268 - accuracy: 0.2483 - val_loss: 1.3361 - val_accuracy: 0.2500\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 1.3531 - accuracy: 0.3844 - val_loss: 1.2740 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 1.2930 - accuracy: 0.4728 - val_loss: 1.2219 - val_accuracy: 0.5385\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 1.2391 - accuracy: 0.5782 - val_loss: 1.1679 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 1.1884 - accuracy: 0.6088 - val_loss: 1.1287 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 1.1407 - accuracy: 0.6531 - val_loss: 1.0848 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 1.0968 - accuracy: 0.6803 - val_loss: 1.0411 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 1.0546 - accuracy: 0.7007 - val_loss: 1.0003 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 1.0147 - accuracy: 0.7041 - val_loss: 0.9604 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.9774 - accuracy: 0.7075 - val_loss: 0.9213 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.9420 - accuracy: 0.7279 - val_loss: 0.8872 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.9094 - accuracy: 0.7347 - val_loss: 0.8548 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.8792 - accuracy: 0.7381 - val_loss: 0.8266 - val_accuracy: 0.7500\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 266us/step - loss: 0.8524 - accuracy: 0.7483 - val_loss: 0.7955 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.8288 - accuracy: 0.7483 - val_loss: 0.7740 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.8054 - accuracy: 0.7551 - val_loss: 0.7483 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.7860 - accuracy: 0.7551 - val_loss: 0.7281 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.7678 - accuracy: 0.7585 - val_loss: 0.7090 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.7523 - accuracy: 0.7551 - val_loss: 0.6955 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.7372 - accuracy: 0.7517 - val_loss: 0.6727 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.7243 - accuracy: 0.7619 - val_loss: 0.6610 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.7116 - accuracy: 0.7585 - val_loss: 0.6518 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.7015 - accuracy: 0.7551 - val_loss: 0.6399 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6914 - accuracy: 0.7551 - val_loss: 0.6251 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.6814 - accuracy: 0.7653 - val_loss: 0.6180 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.6732 - accuracy: 0.7653 - val_loss: 0.6132 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.6656 - accuracy: 0.7721 - val_loss: 0.6005 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.6584 - accuracy: 0.7619 - val_loss: 0.5938 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.6516 - accuracy: 0.7687 - val_loss: 0.5896 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6456 - accuracy: 0.7721 - val_loss: 0.5832 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.6407 - accuracy: 0.7721 - val_loss: 0.5736 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.6336 - accuracy: 0.7653 - val_loss: 0.5642 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.6285 - accuracy: 0.7653 - val_loss: 0.5623 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.6243 - accuracy: 0.7687 - val_loss: 0.5577 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.6186 - accuracy: 0.7721 - val_loss: 0.5511 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.6147 - accuracy: 0.7721 - val_loss: 0.5495 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.6103 - accuracy: 0.7687 - val_loss: 0.5460 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.6063 - accuracy: 0.7653 - val_loss: 0.5463 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.6038 - accuracy: 0.7687 - val_loss: 0.5402 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5992 - accuracy: 0.7687 - val_loss: 0.5378 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5956 - accuracy: 0.7721 - val_loss: 0.5339 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.5929 - accuracy: 0.7687 - val_loss: 0.5279 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.5895 - accuracy: 0.7721 - val_loss: 0.5307 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.5860 - accuracy: 0.7721 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.5829 - accuracy: 0.7687 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5799 - accuracy: 0.7687 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5768 - accuracy: 0.7721 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5741 - accuracy: 0.7687 - val_loss: 0.5194 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5717 - accuracy: 0.7687 - val_loss: 0.5121 - val_accuracy: 0.8654\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 469us/step - loss: 0.5691 - accuracy: 0.7687 - val_loss: 0.5125 - val_accuracy: 0.8654\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5679 - accuracy: 0.7721 - val_loss: 0.5111 - val_accuracy: 0.8654\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5653 - accuracy: 0.7687 - val_loss: 0.5110 - val_accuracy: 0.8654\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5628 - accuracy: 0.7721 - val_loss: 0.5077 - val_accuracy: 0.8654\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.5635 - accuracy: 0.7755 - val_loss: 0.5121 - val_accuracy: 0.8654\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.5575 - accuracy: 0.7687 - val_loss: 0.5035 - val_accuracy: 0.8654\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.5564 - accuracy: 0.7755 - val_loss: 0.5074 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5535 - accuracy: 0.7755 - val_loss: 0.4994 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5517 - accuracy: 0.7789 - val_loss: 0.5015 - val_accuracy: 0.8654\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5495 - accuracy: 0.7789 - val_loss: 0.5028 - val_accuracy: 0.8654\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.5475 - accuracy: 0.7789 - val_loss: 0.5035 - val_accuracy: 0.8654\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5460 - accuracy: 0.7789 - val_loss: 0.5048 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5432 - accuracy: 0.7789 - val_loss: 0.5079 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5427 - accuracy: 0.7755 - val_loss: 0.5058 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5393 - accuracy: 0.7755 - val_loss: 0.5020 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5373 - accuracy: 0.7823 - val_loss: 0.5033 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5365 - accuracy: 0.7755 - val_loss: 0.5005 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 247us/step - loss: 0.5333 - accuracy: 0.7823 - val_loss: 0.5020 - val_accuracy: 0.8654\n",
      "116/116 [==============================] - 0s 263us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.3557 - accuracy: 0.2755 - val_loss: 1.1695 - val_accuracy: 0.4615\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 373us/step - loss: 1.2558 - accuracy: 0.3844 - val_loss: 1.0943 - val_accuracy: 0.5769\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 1.1823 - accuracy: 0.4864 - val_loss: 1.0398 - val_accuracy: 0.6731\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 1.1238 - accuracy: 0.5952 - val_loss: 0.9853 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 1.0727 - accuracy: 0.6429 - val_loss: 0.9418 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 1.0296 - accuracy: 0.6531 - val_loss: 0.9093 - val_accuracy: 0.7115\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.9904 - accuracy: 0.6633 - val_loss: 0.8722 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.9563 - accuracy: 0.6769 - val_loss: 0.8428 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.9266 - accuracy: 0.7041 - val_loss: 0.8217 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.8968 - accuracy: 0.7347 - val_loss: 0.7876 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.8720 - accuracy: 0.7279 - val_loss: 0.7691 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.8476 - accuracy: 0.7347 - val_loss: 0.7466 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.8250 - accuracy: 0.7381 - val_loss: 0.7253 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.8050 - accuracy: 0.7381 - val_loss: 0.7088 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.7848 - accuracy: 0.7449 - val_loss: 0.6977 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.7670 - accuracy: 0.7449 - val_loss: 0.6827 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.7510 - accuracy: 0.7517 - val_loss: 0.6745 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.7350 - accuracy: 0.7517 - val_loss: 0.6470 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.7173 - accuracy: 0.7517 - val_loss: 0.6473 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.7040 - accuracy: 0.7483 - val_loss: 0.6365 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 796us/step - loss: 0.6910 - accuracy: 0.7551 - val_loss: 0.6271 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.6792 - accuracy: 0.7517 - val_loss: 0.6161 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.73 - 0s 569us/step - loss: 0.6692 - accuracy: 0.7517 - val_loss: 0.6076 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.6589 - accuracy: 0.7517 - val_loss: 0.6003 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 0.6496 - accuracy: 0.7619 - val_loss: 0.5999 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.6417 - accuracy: 0.7619 - val_loss: 0.5913 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.6325 - accuracy: 0.7551 - val_loss: 0.5821 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.6259 - accuracy: 0.7585 - val_loss: 0.5764 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.6196 - accuracy: 0.7585 - val_loss: 0.5753 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.6139 - accuracy: 0.7551 - val_loss: 0.5729 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.7551 - val_loss: 0.5632 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 674us/step - loss: 0.6018 - accuracy: 0.7653 - val_loss: 0.5646 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 863us/step - loss: 0.5983 - accuracy: 0.7653 - val_loss: 0.5649 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 655us/step - loss: 0.5939 - accuracy: 0.7585 - val_loss: 0.5646 - val_accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5888 - accuracy: 0.7619 - val_loss: 0.5559 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.5847 - accuracy: 0.7653 - val_loss: 0.5529 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 758us/step - loss: 0.5805 - accuracy: 0.7653 - val_loss: 0.5490 - val_accuracy: 0.7885\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 858us/step - loss: 0.5767 - accuracy: 0.7653 - val_loss: 0.5475 - val_accuracy: 0.7885\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.5748 - accuracy: 0.7653 - val_loss: 0.5490 - val_accuracy: 0.7885\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 812us/step - loss: 0.5700 - accuracy: 0.7687 - val_loss: 0.5458 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 727us/step - loss: 0.5670 - accuracy: 0.7687 - val_loss: 0.5421 - val_accuracy: 0.7885\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5645 - accuracy: 0.7721 - val_loss: 0.5436 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5603 - accuracy: 0.7687 - val_loss: 0.5343 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.5575 - accuracy: 0.7721 - val_loss: 0.5351 - val_accuracy: 0.7885\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5549 - accuracy: 0.7687 - val_loss: 0.5328 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5519 - accuracy: 0.7687 - val_loss: 0.5347 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5492 - accuracy: 0.7687 - val_loss: 0.5338 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5474 - accuracy: 0.7687 - val_loss: 0.5314 - val_accuracy: 0.7885\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5447 - accuracy: 0.7687 - val_loss: 0.5298 - val_accuracy: 0.7885\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5420 - accuracy: 0.7755 - val_loss: 0.5295 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5417 - accuracy: 0.7721 - val_loss: 0.5260 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5387 - accuracy: 0.7721 - val_loss: 0.5296 - val_accuracy: 0.7885\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5356 - accuracy: 0.7755 - val_loss: 0.5234 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 0.5348 - accuracy: 0.7755 - val_loss: 0.5232 - val_accuracy: 0.7885\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5308 - accuracy: 0.7789 - val_loss: 0.5292 - val_accuracy: 0.7885\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5294 - accuracy: 0.7789 - val_loss: 0.5271 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5276 - accuracy: 0.7789 - val_loss: 0.5205 - val_accuracy: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5257 - accuracy: 0.7789 - val_loss: 0.5232 - val_accuracy: 0.7692\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5236 - accuracy: 0.7789 - val_loss: 0.5255 - val_accuracy: 0.7692\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.5227 - accuracy: 0.7755 - val_loss: 0.5260 - val_accuracy: 0.7692\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5210 - accuracy: 0.7755 - val_loss: 0.5256 - val_accuracy: 0.7692\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5187 - accuracy: 0.7755 - val_loss: 0.5231 - val_accuracy: 0.7692\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5164 - accuracy: 0.7789 - val_loss: 0.5214 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.5153 - accuracy: 0.7857 - val_loss: 0.5172 - val_accuracy: 0.8077\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5152 - accuracy: 0.7755 - val_loss: 0.5136 - val_accuracy: 0.8077\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5126 - accuracy: 0.7823 - val_loss: 0.5126 - val_accuracy: 0.8077\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5106 - accuracy: 0.7789 - val_loss: 0.5206 - val_accuracy: 0.7885\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5088 - accuracy: 0.7755 - val_loss: 0.5203 - val_accuracy: 0.8077\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.5079 - accuracy: 0.7823 - val_loss: 0.5121 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5075 - accuracy: 0.7789 - val_loss: 0.5138 - val_accuracy: 0.8077\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5038 - accuracy: 0.7823 - val_loss: 0.5137 - val_accuracy: 0.8077\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5036 - accuracy: 0.7721 - val_loss: 0.5157 - val_accuracy: 0.8077\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5017 - accuracy: 0.7755 - val_loss: 0.5181 - val_accuracy: 0.8077\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.5004 - accuracy: 0.7823 - val_loss: 0.5177 - val_accuracy: 0.8077\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 669us/step - loss: 0.5008 - accuracy: 0.7789 - val_loss: 0.5161 - val_accuracy: 0.8077\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4984 - accuracy: 0.7789 - val_loss: 0.5158 - val_accuracy: 0.8077\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.4967 - accuracy: 0.7789 - val_loss: 0.5164 - val_accuracy: 0.8077\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.4956 - accuracy: 0.7857 - val_loss: 0.5189 - val_accuracy: 0.8077\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4940 - accuracy: 0.7891 - val_loss: 0.5166 - val_accuracy: 0.8077\n",
      "116/116 [==============================] - 0s 95us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 0s 2ms/step - loss: 1.4137 - accuracy: 0.3299 - val_loss: 1.3873 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 1.3312 - accuracy: 0.4014 - val_loss: 1.2839 - val_accuracy: 0.5000\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 1.2664 - accuracy: 0.4694 - val_loss: 1.2278 - val_accuracy: 0.5577\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 1.2208 - accuracy: 0.5476 - val_loss: 1.1775 - val_accuracy: 0.5577\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 1.1806 - accuracy: 0.5952 - val_loss: 1.1302 - val_accuracy: 0.6154\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 1.1385 - accuracy: 0.6293 - val_loss: 1.0862 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 1.0995 - accuracy: 0.6531 - val_loss: 1.0408 - val_accuracy: 0.6538\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 1.0585 - accuracy: 0.6803 - val_loss: 1.0035 - val_accuracy: 0.7115\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 1.0217 - accuracy: 0.7109 - val_loss: 0.9659 - val_accuracy: 0.7308\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.9844 - accuracy: 0.7279 - val_loss: 0.9284 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.9468 - accuracy: 0.7347 - val_loss: 0.8879 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.9155 - accuracy: 0.7211 - val_loss: 0.8568 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.8817 - accuracy: 0.7313 - val_loss: 0.8208 - val_accuracy: 0.7500\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.8534 - accuracy: 0.7279 - val_loss: 0.7926 - val_accuracy: 0.7500\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.8240 - accuracy: 0.7313 - val_loss: 0.7675 - val_accuracy: 0.7500\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.7983 - accuracy: 0.7347 - val_loss: 0.7427 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.7717 - accuracy: 0.7415 - val_loss: 0.7231 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.7525 - accuracy: 0.7415 - val_loss: 0.7037 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.7351 - accuracy: 0.7483 - val_loss: 0.6847 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 593us/step - loss: 0.7212 - accuracy: 0.7517 - val_loss: 0.6705 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 820us/step - loss: 0.7068 - accuracy: 0.7415 - val_loss: 0.6631 - val_accuracy: 0.7692\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.6954 - accuracy: 0.7381 - val_loss: 0.6504 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.6859 - accuracy: 0.7483 - val_loss: 0.6374 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.6761 - accuracy: 0.7483 - val_loss: 0.6323 - val_accuracy: 0.7692\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.6678 - accuracy: 0.7449 - val_loss: 0.6244 - val_accuracy: 0.7692\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.6598 - accuracy: 0.7449 - val_loss: 0.6179 - val_accuracy: 0.7692\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.6523 - accuracy: 0.7517 - val_loss: 0.6088 - val_accuracy: 0.7692\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.6458 - accuracy: 0.7619 - val_loss: 0.6077 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.6385 - accuracy: 0.7653 - val_loss: 0.6067 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.6329 - accuracy: 0.7551 - val_loss: 0.6032 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.6278 - accuracy: 0.7619 - val_loss: 0.5972 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.6216 - accuracy: 0.7653 - val_loss: 0.5877 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.6169 - accuracy: 0.7619 - val_loss: 0.5863 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 422us/step - loss: 0.6120 - accuracy: 0.7585 - val_loss: 0.5788 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.6089 - accuracy: 0.7687 - val_loss: 0.5779 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.6021 - accuracy: 0.7721 - val_loss: 0.5751 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5980 - accuracy: 0.7653 - val_loss: 0.5741 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.5942 - accuracy: 0.7619 - val_loss: 0.5712 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5906 - accuracy: 0.7619 - val_loss: 0.5679 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5869 - accuracy: 0.7755 - val_loss: 0.5665 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5827 - accuracy: 0.7721 - val_loss: 0.5627 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5797 - accuracy: 0.7551 - val_loss: 0.5606 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5759 - accuracy: 0.7653 - val_loss: 0.5527 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.5727 - accuracy: 0.7721 - val_loss: 0.5576 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5697 - accuracy: 0.7653 - val_loss: 0.5511 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5693 - accuracy: 0.7687 - val_loss: 0.5527 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5640 - accuracy: 0.7687 - val_loss: 0.5508 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5608 - accuracy: 0.7721 - val_loss: 0.5457 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.5591 - accuracy: 0.7721 - val_loss: 0.5407 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 724us/step - loss: 0.5558 - accuracy: 0.7721 - val_loss: 0.5427 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.5524 - accuracy: 0.7721 - val_loss: 0.5471 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.5509 - accuracy: 0.7789 - val_loss: 0.5479 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 701us/step - loss: 0.5494 - accuracy: 0.7653 - val_loss: 0.5403 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.5483 - accuracy: 0.7687 - val_loss: 0.5380 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5432 - accuracy: 0.7755 - val_loss: 0.5368 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5414 - accuracy: 0.7721 - val_loss: 0.5312 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.5399 - accuracy: 0.7755 - val_loss: 0.5294 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.5376 - accuracy: 0.7687 - val_loss: 0.5299 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5358 - accuracy: 0.7755 - val_loss: 0.5370 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 0.5346 - accuracy: 0.7755 - val_loss: 0.5269 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5323 - accuracy: 0.7721 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.5293 - accuracy: 0.7721 - val_loss: 0.5275 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5278 - accuracy: 0.7789 - val_loss: 0.5258 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5251 - accuracy: 0.7721 - val_loss: 0.5299 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.5240 - accuracy: 0.7721 - val_loss: 0.5252 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5223 - accuracy: 0.7755 - val_loss: 0.5282 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.5213 - accuracy: 0.7857 - val_loss: 0.5258 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5192 - accuracy: 0.7755 - val_loss: 0.5288 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5200 - accuracy: 0.7823 - val_loss: 0.5204 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.5176 - accuracy: 0.7755 - val_loss: 0.5223 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5145 - accuracy: 0.7789 - val_loss: 0.5208 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.5140 - accuracy: 0.7789 - val_loss: 0.5184 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5134 - accuracy: 0.7823 - val_loss: 0.5255 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.5107 - accuracy: 0.7891 - val_loss: 0.5133 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.5094 - accuracy: 0.7857 - val_loss: 0.5180 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5079 - accuracy: 0.7857 - val_loss: 0.5217 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5083 - accuracy: 0.7755 - val_loss: 0.5324 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 650us/step - loss: 0.5048 - accuracy: 0.7789 - val_loss: 0.5221 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5039 - accuracy: 0.7857 - val_loss: 0.5189 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.5027 - accuracy: 0.7857 - val_loss: 0.5200 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5016 - accuracy: 0.7755 - val_loss: 0.5183 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5011 - accuracy: 0.7823 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4986 - accuracy: 0.7891 - val_loss: 0.5238 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4983 - accuracy: 0.7857 - val_loss: 0.5168 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 96us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.7210 - accuracy: 0.2279 - val_loss: 1.5820 - val_accuracy: 0.1346\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 1.5741 - accuracy: 0.2551 - val_loss: 1.4631 - val_accuracy: 0.2308\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 1.4532 - accuracy: 0.3027 - val_loss: 1.3669 - val_accuracy: 0.2885\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 1.3487 - accuracy: 0.3571 - val_loss: 1.2816 - val_accuracy: 0.3846\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 373us/step - loss: 1.2637 - accuracy: 0.3912 - val_loss: 1.2134 - val_accuracy: 0.4808\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 1.1839 - accuracy: 0.4558 - val_loss: 1.1444 - val_accuracy: 0.5192\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 1.1163 - accuracy: 0.5578 - val_loss: 1.0865 - val_accuracy: 0.5577\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 1.0580 - accuracy: 0.5884 - val_loss: 1.0397 - val_accuracy: 0.6346\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 1.0038 - accuracy: 0.6599 - val_loss: 0.9926 - val_accuracy: 0.6923\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.9570 - accuracy: 0.7041 - val_loss: 0.9524 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.9147 - accuracy: 0.7143 - val_loss: 0.9117 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.8769 - accuracy: 0.7279 - val_loss: 0.8716 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.8423 - accuracy: 0.7211 - val_loss: 0.8422 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.8131 - accuracy: 0.7279 - val_loss: 0.8136 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.7844 - accuracy: 0.7211 - val_loss: 0.7843 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.7591 - accuracy: 0.7143 - val_loss: 0.7541 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.7377 - accuracy: 0.7313 - val_loss: 0.7324 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.7190 - accuracy: 0.7347 - val_loss: 0.7093 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.7033 - accuracy: 0.7517 - val_loss: 0.6961 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.6889 - accuracy: 0.7619 - val_loss: 0.6814 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.6769 - accuracy: 0.7721 - val_loss: 0.6717 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.6655 - accuracy: 0.7585 - val_loss: 0.6615 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.6557 - accuracy: 0.7483 - val_loss: 0.6494 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.6454 - accuracy: 0.7653 - val_loss: 0.6398 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.6371 - accuracy: 0.7653 - val_loss: 0.6314 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.6285 - accuracy: 0.7721 - val_loss: 0.6294 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.6213 - accuracy: 0.7687 - val_loss: 0.6191 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.6153 - accuracy: 0.7755 - val_loss: 0.6158 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.6089 - accuracy: 0.7721 - val_loss: 0.6120 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.6029 - accuracy: 0.7687 - val_loss: 0.6047 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5967 - accuracy: 0.7789 - val_loss: 0.6059 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5934 - accuracy: 0.7687 - val_loss: 0.6063 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5870 - accuracy: 0.7789 - val_loss: 0.5915 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5806 - accuracy: 0.7789 - val_loss: 0.5896 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.5769 - accuracy: 0.7823 - val_loss: 0.5902 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5734 - accuracy: 0.7755 - val_loss: 0.5881 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.5681 - accuracy: 0.7823 - val_loss: 0.5778 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5631 - accuracy: 0.7857 - val_loss: 0.5805 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5604 - accuracy: 0.7823 - val_loss: 0.5772 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 731us/step - loss: 0.5581 - accuracy: 0.7721 - val_loss: 0.5770 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 684us/step - loss: 0.5538 - accuracy: 0.7857 - val_loss: 0.5721 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.5500 - accuracy: 0.7823 - val_loss: 0.5722 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.5469 - accuracy: 0.7857 - val_loss: 0.5736 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.5445 - accuracy: 0.7789 - val_loss: 0.5743 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5441 - accuracy: 0.7823 - val_loss: 0.5612 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5375 - accuracy: 0.7823 - val_loss: 0.5663 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.5369 - accuracy: 0.7721 - val_loss: 0.5715 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5333 - accuracy: 0.7789 - val_loss: 0.5600 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5316 - accuracy: 0.7789 - val_loss: 0.5554 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.5290 - accuracy: 0.7789 - val_loss: 0.5532 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5259 - accuracy: 0.7823 - val_loss: 0.5563 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5237 - accuracy: 0.7789 - val_loss: 0.5608 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5238 - accuracy: 0.7789 - val_loss: 0.5618 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5189 - accuracy: 0.7755 - val_loss: 0.5493 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.5181 - accuracy: 0.7857 - val_loss: 0.5506 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5162 - accuracy: 0.7823 - val_loss: 0.5546 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.5154 - accuracy: 0.7823 - val_loss: 0.5530 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5122 - accuracy: 0.7823 - val_loss: 0.5540 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5108 - accuracy: 0.7823 - val_loss: 0.5568 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5078 - accuracy: 0.7823 - val_loss: 0.5484 - val_accuracy: 0.8654\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 316us/step - loss: 0.5067 - accuracy: 0.7789 - val_loss: 0.5439 - val_accuracy: 0.8654\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5050 - accuracy: 0.7789 - val_loss: 0.5487 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5033 - accuracy: 0.7857 - val_loss: 0.5489 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5017 - accuracy: 0.7857 - val_loss: 0.5546 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5008 - accuracy: 0.7755 - val_loss: 0.5474 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4988 - accuracy: 0.7823 - val_loss: 0.5468 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.4974 - accuracy: 0.7857 - val_loss: 0.5401 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4964 - accuracy: 0.7823 - val_loss: 0.5448 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4946 - accuracy: 0.7823 - val_loss: 0.5421 - val_accuracy: 0.8654\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.4939 - accuracy: 0.7789 - val_loss: 0.5425 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.4919 - accuracy: 0.7857 - val_loss: 0.5407 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4913 - accuracy: 0.7857 - val_loss: 0.5486 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4892 - accuracy: 0.7823 - val_loss: 0.5493 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4885 - accuracy: 0.7891 - val_loss: 0.5450 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4867 - accuracy: 0.7789 - val_loss: 0.5453 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.4860 - accuracy: 0.7891 - val_loss: 0.5366 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.4837 - accuracy: 0.7925 - val_loss: 0.5430 - val_accuracy: 0.8654\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.4840 - accuracy: 0.7891 - val_loss: 0.5454 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4823 - accuracy: 0.7993 - val_loss: 0.5361 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.4815 - accuracy: 0.7823 - val_loss: 0.5447 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.4804 - accuracy: 0.7959 - val_loss: 0.5347 - val_accuracy: 0.8654\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.4776 - accuracy: 0.7993 - val_loss: 0.5363 - val_accuracy: 0.8654\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4776 - accuracy: 0.7925 - val_loss: 0.5455 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.4767 - accuracy: 0.7993 - val_loss: 0.5340 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4738 - accuracy: 0.7993 - val_loss: 0.5409 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4754 - accuracy: 0.7959 - val_loss: 0.5441 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.4732 - accuracy: 0.7993 - val_loss: 0.5373 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4726 - accuracy: 0.8027 - val_loss: 0.5391 - val_accuracy: 0.8654\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4702 - accuracy: 0.8061 - val_loss: 0.5434 - val_accuracy: 0.8654\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.4707 - accuracy: 0.8027 - val_loss: 0.5447 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4679 - accuracy: 0.7993 - val_loss: 0.5393 - val_accuracy: 0.8654\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.4689 - accuracy: 0.8027 - val_loss: 0.5368 - val_accuracy: 0.8654\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4668 - accuracy: 0.7993 - val_loss: 0.5426 - val_accuracy: 0.8654\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 511us/step - loss: 0.4650 - accuracy: 0.7993 - val_loss: 0.5407 - val_accuracy: 0.8654\n",
      "116/116 [==============================] - 0s 130us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4297 - accuracy: 0.3571 - val_loss: 1.4017 - val_accuracy: 0.3654\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 511us/step - loss: 1.2696 - accuracy: 0.4320 - val_loss: 1.2708 - val_accuracy: 0.4423\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 1.1699 - accuracy: 0.4932 - val_loss: 1.1707 - val_accuracy: 0.5577\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 1.0909 - accuracy: 0.5884 - val_loss: 1.0937 - val_accuracy: 0.5962\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 1.0265 - accuracy: 0.6293 - val_loss: 1.0292 - val_accuracy: 0.6731\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.9707 - accuracy: 0.6633 - val_loss: 0.9721 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.9239 - accuracy: 0.6701 - val_loss: 0.9282 - val_accuracy: 0.6923\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 690us/step - loss: 0.8834 - accuracy: 0.6803 - val_loss: 0.8890 - val_accuracy: 0.6923\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.8488 - accuracy: 0.6973 - val_loss: 0.8520 - val_accuracy: 0.7115\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.8187 - accuracy: 0.7109 - val_loss: 0.8273 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.7924 - accuracy: 0.7245 - val_loss: 0.8019 - val_accuracy: 0.7308\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.7678 - accuracy: 0.7381 - val_loss: 0.7784 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.7462 - accuracy: 0.7449 - val_loss: 0.7568 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.7271 - accuracy: 0.7517 - val_loss: 0.7375 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.7095 - accuracy: 0.7551 - val_loss: 0.7190 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.6937 - accuracy: 0.7551 - val_loss: 0.7028 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.6798 - accuracy: 0.7619 - val_loss: 0.6880 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.6684 - accuracy: 0.7585 - val_loss: 0.6806 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.6570 - accuracy: 0.7585 - val_loss: 0.6649 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.6468 - accuracy: 0.7585 - val_loss: 0.6559 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.6381 - accuracy: 0.7551 - val_loss: 0.6484 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 275us/step - loss: 0.6310 - accuracy: 0.7619 - val_loss: 0.6369 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6228 - accuracy: 0.7619 - val_loss: 0.6311 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.6163 - accuracy: 0.7619 - val_loss: 0.6248 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.6117 - accuracy: 0.7653 - val_loss: 0.6155 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.6043 - accuracy: 0.7687 - val_loss: 0.6123 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5998 - accuracy: 0.7653 - val_loss: 0.6011 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5941 - accuracy: 0.7653 - val_loss: 0.6015 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5884 - accuracy: 0.7653 - val_loss: 0.5917 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.5842 - accuracy: 0.7755 - val_loss: 0.5850 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.5801 - accuracy: 0.7653 - val_loss: 0.5809 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.5749 - accuracy: 0.7687 - val_loss: 0.5755 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 640us/step - loss: 0.5719 - accuracy: 0.7721 - val_loss: 0.5756 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.5686 - accuracy: 0.7755 - val_loss: 0.5706 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.5641 - accuracy: 0.7721 - val_loss: 0.5678 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.5633 - accuracy: 0.7687 - val_loss: 0.5588 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5578 - accuracy: 0.7789 - val_loss: 0.5625 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5551 - accuracy: 0.7755 - val_loss: 0.5566 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5511 - accuracy: 0.7823 - val_loss: 0.5507 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5521 - accuracy: 0.78 - 0s 361us/step - loss: 0.5481 - accuracy: 0.7755 - val_loss: 0.5468 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.5452 - accuracy: 0.7755 - val_loss: 0.5374 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5430 - accuracy: 0.7755 - val_loss: 0.5409 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5408 - accuracy: 0.7755 - val_loss: 0.5345 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5367 - accuracy: 0.7823 - val_loss: 0.5393 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5355 - accuracy: 0.7789 - val_loss: 0.5330 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.5322 - accuracy: 0.7755 - val_loss: 0.5333 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5301 - accuracy: 0.7789 - val_loss: 0.5290 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5281 - accuracy: 0.7789 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5252 - accuracy: 0.7789 - val_loss: 0.5268 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5236 - accuracy: 0.7755 - val_loss: 0.5250 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5218 - accuracy: 0.7789 - val_loss: 0.5218 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5204 - accuracy: 0.7789 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5187 - accuracy: 0.7823 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.5160 - accuracy: 0.7789 - val_loss: 0.5154 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5144 - accuracy: 0.7789 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.5114 - accuracy: 0.7789 - val_loss: 0.5127 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.5103 - accuracy: 0.7789 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5090 - accuracy: 0.7789 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5068 - accuracy: 0.7823 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.5049 - accuracy: 0.7823 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5055 - accuracy: 0.7857 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5027 - accuracy: 0.7823 - val_loss: 0.5117 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5007 - accuracy: 0.7925 - val_loss: 0.5106 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4985 - accuracy: 0.7857 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.4981 - accuracy: 0.7823 - val_loss: 0.5065 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.4960 - accuracy: 0.7857 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.4938 - accuracy: 0.7857 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.4936 - accuracy: 0.7959 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.4931 - accuracy: 0.7925 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4916 - accuracy: 0.7823 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4898 - accuracy: 0.7959 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.4876 - accuracy: 0.7959 - val_loss: 0.5043 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4868 - accuracy: 0.7925 - val_loss: 0.5011 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.4856 - accuracy: 0.7925 - val_loss: 0.5077 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4838 - accuracy: 0.7959 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.4831 - accuracy: 0.7959 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4827 - accuracy: 0.8027 - val_loss: 0.5040 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.4806 - accuracy: 0.7993 - val_loss: 0.5057 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4805 - accuracy: 0.7993 - val_loss: 0.5033 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4786 - accuracy: 0.8027 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4794 - accuracy: 0.8027 - val_loss: 0.5116 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4757 - accuracy: 0.8027 - val_loss: 0.4976 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4751 - accuracy: 0.7993 - val_loss: 0.4965 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.4754 - accuracy: 0.7993 - val_loss: 0.5014 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 253us/step - loss: 0.4740 - accuracy: 0.7959 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.4721 - accuracy: 0.7993 - val_loss: 0.4952 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.4719 - accuracy: 0.8027 - val_loss: 0.4983 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4704 - accuracy: 0.8027 - val_loss: 0.5025 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4689 - accuracy: 0.7993 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.4675 - accuracy: 0.7993 - val_loss: 0.5010 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.4672 - accuracy: 0.8061 - val_loss: 0.4990 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4677 - accuracy: 0.7993 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4661 - accuracy: 0.8061 - val_loss: 0.4996 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4650 - accuracy: 0.7959 - val_loss: 0.5025 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.4635 - accuracy: 0.8027 - val_loss: 0.4967 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4638 - accuracy: 0.7993 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 94us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5444 - accuracy: 0.2653 - val_loss: 1.4609 - val_accuracy: 0.2308\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 1.3594 - accuracy: 0.3129 - val_loss: 1.3228 - val_accuracy: 0.3269\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 1.2585 - accuracy: 0.3946 - val_loss: 1.2233 - val_accuracy: 0.4231\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 1.1838 - accuracy: 0.4830 - val_loss: 1.1515 - val_accuracy: 0.5385\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 1.1200 - accuracy: 0.5578 - val_loss: 1.0855 - val_accuracy: 0.6154\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 1.0596 - accuracy: 0.6088 - val_loss: 1.0242 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 1.0032 - accuracy: 0.6463 - val_loss: 0.9656 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.9517 - accuracy: 0.6803 - val_loss: 0.9160 - val_accuracy: 0.6731\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.9075 - accuracy: 0.7075 - val_loss: 0.8677 - val_accuracy: 0.7308\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.8659 - accuracy: 0.7313 - val_loss: 0.8302 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.8304 - accuracy: 0.7381 - val_loss: 0.7935 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.8011 - accuracy: 0.7347 - val_loss: 0.7597 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.7749 - accuracy: 0.7483 - val_loss: 0.7345 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.7515 - accuracy: 0.7449 - val_loss: 0.7170 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.7313 - accuracy: 0.7449 - val_loss: 0.6935 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.7144 - accuracy: 0.7517 - val_loss: 0.6742 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.6983 - accuracy: 0.7585 - val_loss: 0.6594 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.6848 - accuracy: 0.7551 - val_loss: 0.6483 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.6719 - accuracy: 0.7585 - val_loss: 0.6346 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.6595 - accuracy: 0.7619 - val_loss: 0.6248 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.6489 - accuracy: 0.7585 - val_loss: 0.6140 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.6410 - accuracy: 0.7687 - val_loss: 0.6000 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.6303 - accuracy: 0.7619 - val_loss: 0.5990 - val_accuracy: 0.7692\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.6228 - accuracy: 0.7585 - val_loss: 0.5883 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.6162 - accuracy: 0.7687 - val_loss: 0.5801 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.6087 - accuracy: 0.7551 - val_loss: 0.5850 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 0.6016 - accuracy: 0.7619 - val_loss: 0.5710 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5955 - accuracy: 0.7619 - val_loss: 0.5683 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5915 - accuracy: 0.7721 - val_loss: 0.5552 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5845 - accuracy: 0.7687 - val_loss: 0.5586 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5792 - accuracy: 0.7687 - val_loss: 0.5523 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5749 - accuracy: 0.7585 - val_loss: 0.5519 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5708 - accuracy: 0.7585 - val_loss: 0.5445 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.5662 - accuracy: 0.7653 - val_loss: 0.5436 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5628 - accuracy: 0.7653 - val_loss: 0.5360 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5591 - accuracy: 0.7721 - val_loss: 0.5336 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 453us/step - loss: 0.5559 - accuracy: 0.7653 - val_loss: 0.5361 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5515 - accuracy: 0.7653 - val_loss: 0.5328 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5488 - accuracy: 0.7721 - val_loss: 0.5281 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.5459 - accuracy: 0.7721 - val_loss: 0.5252 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.5452 - accuracy: 0.7687 - val_loss: 0.5241 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5400 - accuracy: 0.7687 - val_loss: 0.5224 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5372 - accuracy: 0.7687 - val_loss: 0.5198 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.5343 - accuracy: 0.7721 - val_loss: 0.5151 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5311 - accuracy: 0.7687 - val_loss: 0.5173 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5306 - accuracy: 0.7755 - val_loss: 0.5041 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5278 - accuracy: 0.7653 - val_loss: 0.5164 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.5246 - accuracy: 0.7755 - val_loss: 0.5091 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5218 - accuracy: 0.7721 - val_loss: 0.5066 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.5198 - accuracy: 0.7721 - val_loss: 0.5116 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 0.5178 - accuracy: 0.7721 - val_loss: 0.5012 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5146 - accuracy: 0.7755 - val_loss: 0.5090 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5135 - accuracy: 0.7721 - val_loss: 0.5024 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5111 - accuracy: 0.7755 - val_loss: 0.4994 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.5098 - accuracy: 0.7755 - val_loss: 0.4976 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.5075 - accuracy: 0.7755 - val_loss: 0.4989 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5065 - accuracy: 0.7755 - val_loss: 0.4978 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5042 - accuracy: 0.7789 - val_loss: 0.4964 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5026 - accuracy: 0.7789 - val_loss: 0.4896 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.5007 - accuracy: 0.7755 - val_loss: 0.4994 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.4986 - accuracy: 0.7789 - val_loss: 0.4961 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.4969 - accuracy: 0.7823 - val_loss: 0.4873 - val_accuracy: 0.8654\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4946 - accuracy: 0.7789 - val_loss: 0.4897 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4931 - accuracy: 0.7789 - val_loss: 0.4893 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4913 - accuracy: 0.7857 - val_loss: 0.4874 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.4903 - accuracy: 0.7857 - val_loss: 0.4907 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.4890 - accuracy: 0.7925 - val_loss: 0.4919 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.4870 - accuracy: 0.7959 - val_loss: 0.4876 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.4862 - accuracy: 0.7823 - val_loss: 0.4947 - val_accuracy: 0.8654\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4850 - accuracy: 0.7891 - val_loss: 0.4808 - val_accuracy: 0.8654\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4827 - accuracy: 0.7959 - val_loss: 0.4814 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.4827 - accuracy: 0.7959 - val_loss: 0.4884 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4805 - accuracy: 0.7959 - val_loss: 0.4893 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.4787 - accuracy: 0.7993 - val_loss: 0.4842 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4787 - accuracy: 0.7925 - val_loss: 0.4803 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4777 - accuracy: 0.8027 - val_loss: 0.4851 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4754 - accuracy: 0.7993 - val_loss: 0.4849 - val_accuracy: 0.8654\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4729 - accuracy: 0.7993 - val_loss: 0.4838 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.4725 - accuracy: 0.7993 - val_loss: 0.4854 - val_accuracy: 0.8846\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.4706 - accuracy: 0.8027 - val_loss: 0.4879 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4710 - accuracy: 0.8061 - val_loss: 0.4748 - val_accuracy: 0.8846\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4715 - accuracy: 0.7993 - val_loss: 0.4880 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4666 - accuracy: 0.8027 - val_loss: 0.4764 - val_accuracy: 0.8846\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4661 - accuracy: 0.8061 - val_loss: 0.4770 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4649 - accuracy: 0.8061 - val_loss: 0.4803 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.4642 - accuracy: 0.8027 - val_loss: 0.4779 - val_accuracy: 0.8654\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.4632 - accuracy: 0.8129 - val_loss: 0.4754 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.4616 - accuracy: 0.8129 - val_loss: 0.4832 - val_accuracy: 0.8654\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.4604 - accuracy: 0.8061 - val_loss: 0.4849 - val_accuracy: 0.8654\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.4603 - accuracy: 0.8095 - val_loss: 0.4848 - val_accuracy: 0.8654\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.4582 - accuracy: 0.8129 - val_loss: 0.4804 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 224us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4011 - accuracy: 0.2415 - val_loss: 1.2744 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 1.2815 - accuracy: 0.3980 - val_loss: 1.1820 - val_accuracy: 0.5769\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 1.1891 - accuracy: 0.5272 - val_loss: 1.1056 - val_accuracy: 0.6346\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 1.1120 - accuracy: 0.6259 - val_loss: 1.0438 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 1.0469 - accuracy: 0.6837 - val_loss: 0.9760 - val_accuracy: 0.7308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.9910 - accuracy: 0.6973 - val_loss: 0.9220 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 742us/step - loss: 0.9417 - accuracy: 0.7075 - val_loss: 0.8750 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.8988 - accuracy: 0.7177 - val_loss: 0.8361 - val_accuracy: 0.7500\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 635us/step - loss: 0.8637 - accuracy: 0.7279 - val_loss: 0.7963 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.8331 - accuracy: 0.7313 - val_loss: 0.7654 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 662us/step - loss: 0.8068 - accuracy: 0.7415 - val_loss: 0.7470 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.7799 - accuracy: 0.7483 - val_loss: 0.7167 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.7587 - accuracy: 0.7517 - val_loss: 0.6977 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.7374 - accuracy: 0.7585 - val_loss: 0.6796 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.7185 - accuracy: 0.7687 - val_loss: 0.6597 - val_accuracy: 0.7692\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.7029 - accuracy: 0.7619 - val_loss: 0.6455 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.6843 - accuracy: 0.7721 - val_loss: 0.6279 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.6695 - accuracy: 0.7721 - val_loss: 0.6199 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.6563 - accuracy: 0.7687 - val_loss: 0.6077 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.6446 - accuracy: 0.7653 - val_loss: 0.5949 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.6342 - accuracy: 0.7721 - val_loss: 0.5887 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.6258 - accuracy: 0.7789 - val_loss: 0.5722 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.6179 - accuracy: 0.7789 - val_loss: 0.5725 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.6109 - accuracy: 0.7687 - val_loss: 0.5746 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.6031 - accuracy: 0.7653 - val_loss: 0.5644 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.5965 - accuracy: 0.7755 - val_loss: 0.5632 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5905 - accuracy: 0.7653 - val_loss: 0.5609 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5844 - accuracy: 0.7823 - val_loss: 0.5551 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5782 - accuracy: 0.7721 - val_loss: 0.5553 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 236us/step - loss: 0.5737 - accuracy: 0.7755 - val_loss: 0.5454 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.5695 - accuracy: 0.7789 - val_loss: 0.5477 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5659 - accuracy: 0.7721 - val_loss: 0.5429 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5608 - accuracy: 0.7721 - val_loss: 0.5439 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.5571 - accuracy: 0.7755 - val_loss: 0.5381 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5519 - accuracy: 0.7755 - val_loss: 0.5348 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5478 - accuracy: 0.7721 - val_loss: 0.5325 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5442 - accuracy: 0.7653 - val_loss: 0.5345 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5407 - accuracy: 0.7721 - val_loss: 0.5329 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5381 - accuracy: 0.7721 - val_loss: 0.5328 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5348 - accuracy: 0.7755 - val_loss: 0.5301 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5326 - accuracy: 0.7755 - val_loss: 0.5353 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5302 - accuracy: 0.7755 - val_loss: 0.5336 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 0.5295 - accuracy: 0.7823 - val_loss: 0.5191 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 699us/step - loss: 0.5249 - accuracy: 0.7789 - val_loss: 0.5296 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5230 - accuracy: 0.7823 - val_loss: 0.5276 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.5212 - accuracy: 0.7755 - val_loss: 0.5289 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5182 - accuracy: 0.7789 - val_loss: 0.5233 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5176 - accuracy: 0.7857 - val_loss: 0.5244 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5154 - accuracy: 0.7857 - val_loss: 0.5252 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5117 - accuracy: 0.7823 - val_loss: 0.5169 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5119 - accuracy: 0.7925 - val_loss: 0.5121 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5086 - accuracy: 0.7857 - val_loss: 0.5206 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5076 - accuracy: 0.7891 - val_loss: 0.5213 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.5054 - accuracy: 0.7857 - val_loss: 0.5144 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5045 - accuracy: 0.7891 - val_loss: 0.5208 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5019 - accuracy: 0.7959 - val_loss: 0.5148 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 414us/step - loss: 0.5016 - accuracy: 0.7959 - val_loss: 0.5151 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4999 - accuracy: 0.7925 - val_loss: 0.5191 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4972 - accuracy: 0.7959 - val_loss: 0.5175 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.4974 - accuracy: 0.7959 - val_loss: 0.5140 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4948 - accuracy: 0.7925 - val_loss: 0.5158 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 125us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.2680 - accuracy: 0.3571 - val_loss: 1.2358 - val_accuracy: 0.4038\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 1.1685 - accuracy: 0.4660 - val_loss: 1.1395 - val_accuracy: 0.4615\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 1.0897 - accuracy: 0.5544 - val_loss: 1.0641 - val_accuracy: 0.5385\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 1.0271 - accuracy: 0.5986 - val_loss: 1.0004 - val_accuracy: 0.5962\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.9754 - accuracy: 0.6327 - val_loss: 0.9514 - val_accuracy: 0.6346\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.9302 - accuracy: 0.6565 - val_loss: 0.8983 - val_accuracy: 0.6154\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.8910 - accuracy: 0.6905 - val_loss: 0.8613 - val_accuracy: 0.6923\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.8553 - accuracy: 0.7143 - val_loss: 0.8281 - val_accuracy: 0.7115\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.8262 - accuracy: 0.7313 - val_loss: 0.7984 - val_accuracy: 0.7308\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.7988 - accuracy: 0.7313 - val_loss: 0.7691 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.7754 - accuracy: 0.7279 - val_loss: 0.7485 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.7531 - accuracy: 0.7381 - val_loss: 0.7337 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.7354 - accuracy: 0.7347 - val_loss: 0.7117 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.7170 - accuracy: 0.7347 - val_loss: 0.6999 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.7011 - accuracy: 0.7415 - val_loss: 0.6833 - val_accuracy: 0.7692\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.6861 - accuracy: 0.7381 - val_loss: 0.6672 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6729 - accuracy: 0.7347 - val_loss: 0.6527 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 741us/step - loss: 0.6622 - accuracy: 0.7347 - val_loss: 0.6437 - val_accuracy: 0.7692\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 710us/step - loss: 0.6499 - accuracy: 0.7381 - val_loss: 0.6351 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 669us/step - loss: 0.6392 - accuracy: 0.7483 - val_loss: 0.6242 - val_accuracy: 0.7692\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.6300 - accuracy: 0.7483 - val_loss: 0.6088 - val_accuracy: 0.7692\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.6204 - accuracy: 0.7517 - val_loss: 0.6053 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.6125 - accuracy: 0.7585 - val_loss: 0.5954 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.6050 - accuracy: 0.7551 - val_loss: 0.5901 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5996 - accuracy: 0.7551 - val_loss: 0.5773 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5910 - accuracy: 0.7619 - val_loss: 0.5758 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5872 - accuracy: 0.7619 - val_loss: 0.5682 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.5806 - accuracy: 0.7585 - val_loss: 0.5675 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5756 - accuracy: 0.7653 - val_loss: 0.5624 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5729 - accuracy: 0.7585 - val_loss: 0.5574 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5674 - accuracy: 0.7551 - val_loss: 0.5493 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5618 - accuracy: 0.7619 - val_loss: 0.5466 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5589 - accuracy: 0.7585 - val_loss: 0.5457 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5549 - accuracy: 0.7619 - val_loss: 0.5408 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5511 - accuracy: 0.7653 - val_loss: 0.5403 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5506 - accuracy: 0.7619 - val_loss: 0.5362 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5440 - accuracy: 0.7687 - val_loss: 0.5359 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5424 - accuracy: 0.7721 - val_loss: 0.5329 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5395 - accuracy: 0.7721 - val_loss: 0.5331 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5361 - accuracy: 0.7721 - val_loss: 0.5251 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5329 - accuracy: 0.7687 - val_loss: 0.5288 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5319 - accuracy: 0.7687 - val_loss: 0.5298 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5281 - accuracy: 0.7721 - val_loss: 0.5185 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5262 - accuracy: 0.7789 - val_loss: 0.5227 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5254 - accuracy: 0.7755 - val_loss: 0.5104 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5229 - accuracy: 0.7789 - val_loss: 0.5200 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5192 - accuracy: 0.7789 - val_loss: 0.5215 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5180 - accuracy: 0.7823 - val_loss: 0.5184 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.5158 - accuracy: 0.7789 - val_loss: 0.5180 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5132 - accuracy: 0.7789 - val_loss: 0.5153 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 416us/step - loss: 0.5122 - accuracy: 0.7789 - val_loss: 0.5167 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5100 - accuracy: 0.7823 - val_loss: 0.5212 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5080 - accuracy: 0.7857 - val_loss: 0.5142 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.5058 - accuracy: 0.7789 - val_loss: 0.5122 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5048 - accuracy: 0.7823 - val_loss: 0.5072 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5035 - accuracy: 0.7857 - val_loss: 0.5176 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5012 - accuracy: 0.7891 - val_loss: 0.5094 - val_accuracy: 0.7885\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4999 - accuracy: 0.7755 - val_loss: 0.5132 - val_accuracy: 0.7885\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4973 - accuracy: 0.7823 - val_loss: 0.5081 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.4961 - accuracy: 0.7823 - val_loss: 0.5153 - val_accuracy: 0.8077\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4968 - accuracy: 0.7857 - val_loss: 0.5127 - val_accuracy: 0.7885\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.4936 - accuracy: 0.7891 - val_loss: 0.5078 - val_accuracy: 0.8077\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 0.4920 - accuracy: 0.7857 - val_loss: 0.5098 - val_accuracy: 0.7885\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4914 - accuracy: 0.7891 - val_loss: 0.5045 - val_accuracy: 0.8077\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4902 - accuracy: 0.7925 - val_loss: 0.5117 - val_accuracy: 0.8077\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4882 - accuracy: 0.7789 - val_loss: 0.5064 - val_accuracy: 0.7885\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.4870 - accuracy: 0.7925 - val_loss: 0.5051 - val_accuracy: 0.7885\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4852 - accuracy: 0.7857 - val_loss: 0.5098 - val_accuracy: 0.7885\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4834 - accuracy: 0.7823 - val_loss: 0.5167 - val_accuracy: 0.7885\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.4831 - accuracy: 0.7925 - val_loss: 0.5094 - val_accuracy: 0.7885\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.4822 - accuracy: 0.7925 - val_loss: 0.5152 - val_accuracy: 0.7885\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.4814 - accuracy: 0.7891 - val_loss: 0.5075 - val_accuracy: 0.8077\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4792 - accuracy: 0.8027 - val_loss: 0.5038 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.4777 - accuracy: 0.8027 - val_loss: 0.5035 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4776 - accuracy: 0.7925 - val_loss: 0.5051 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.4771 - accuracy: 0.8027 - val_loss: 0.5030 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4760 - accuracy: 0.7993 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4747 - accuracy: 0.8027 - val_loss: 0.5127 - val_accuracy: 0.7885\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.4733 - accuracy: 0.7993 - val_loss: 0.5012 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 654us/step - loss: 0.4726 - accuracy: 0.8061 - val_loss: 0.5107 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4737 - accuracy: 0.8061 - val_loss: 0.5032 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4695 - accuracy: 0.8095 - val_loss: 0.5091 - val_accuracy: 0.8077\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4701 - accuracy: 0.8061 - val_loss: 0.5022 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4680 - accuracy: 0.8163 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4685 - accuracy: 0.8129 - val_loss: 0.5105 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4674 - accuracy: 0.8061 - val_loss: 0.4977 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4646 - accuracy: 0.8163 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4663 - accuracy: 0.8095 - val_loss: 0.5034 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.4631 - accuracy: 0.8163 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.4625 - accuracy: 0.8061 - val_loss: 0.5061 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4615 - accuracy: 0.8095 - val_loss: 0.4965 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4621 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.4595 - accuracy: 0.8231 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4601 - accuracy: 0.8197 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4579 - accuracy: 0.8197 - val_loss: 0.4993 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.4584 - accuracy: 0.8197 - val_loss: 0.4992 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4562 - accuracy: 0.8197 - val_loss: 0.4999 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.4561 - accuracy: 0.8231 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.4552 - accuracy: 0.8231 - val_loss: 0.4987 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4540 - accuracy: 0.8231 - val_loss: 0.4985 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.4529 - accuracy: 0.8163 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4519 - accuracy: 0.8231 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.4511 - accuracy: 0.8163 - val_loss: 0.5003 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 225us/step - loss: 0.4504 - accuracy: 0.8231 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 232us/step - loss: 0.4489 - accuracy: 0.8265 - val_loss: 0.4953 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 189us/step - loss: 0.4486 - accuracy: 0.8299 - val_loss: 0.4949 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 187us/step - loss: 0.4473 - accuracy: 0.8265 - val_loss: 0.4964 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 186us/step - loss: 0.4479 - accuracy: 0.8265 - val_loss: 0.4947 - val_accuracy: 0.8077\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4463 - accuracy: 0.8197 - val_loss: 0.4943 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.4450 - accuracy: 0.8265 - val_loss: 0.5079 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4447 - accuracy: 0.8197 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.4437 - accuracy: 0.8231 - val_loss: 0.5027 - val_accuracy: 0.8077\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4432 - accuracy: 0.8299 - val_loss: 0.4878 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.4420 - accuracy: 0.8265 - val_loss: 0.5004 - val_accuracy: 0.8077\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.4416 - accuracy: 0.8231 - val_loss: 0.4990 - val_accuracy: 0.8077\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 0.4402 - accuracy: 0.8197 - val_loss: 0.4944 - val_accuracy: 0.8077\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.4392 - accuracy: 0.8265 - val_loss: 0.4999 - val_accuracy: 0.8077\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4401 - accuracy: 0.8231 - val_loss: 0.4943 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.4375 - accuracy: 0.8333 - val_loss: 0.4955 - val_accuracy: 0.8077\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.4369 - accuracy: 0.8299 - val_loss: 0.4934 - val_accuracy: 0.8077\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.4365 - accuracy: 0.8231 - val_loss: 0.4990 - val_accuracy: 0.8077\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.4355 - accuracy: 0.8265 - val_loss: 0.4967 - val_accuracy: 0.8077\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 597us/step - loss: 0.4351 - accuracy: 0.8231 - val_loss: 0.4946 - val_accuracy: 0.8077\n",
      "116/116 [==============================] - 0s 148us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.6892 - accuracy: 0.2721 - val_loss: 1.4984 - val_accuracy: 0.3654\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 1.4516 - accuracy: 0.3469 - val_loss: 1.3507 - val_accuracy: 0.3654\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 1.3169 - accuracy: 0.3946 - val_loss: 1.2516 - val_accuracy: 0.5192\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 1.2304 - accuracy: 0.5034 - val_loss: 1.1789 - val_accuracy: 0.5577\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 1.1626 - accuracy: 0.5578 - val_loss: 1.1181 - val_accuracy: 0.5962\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 1.1029 - accuracy: 0.6259 - val_loss: 1.0554 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 1.0480 - accuracy: 0.6667 - val_loss: 0.9989 - val_accuracy: 0.6538\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.9988 - accuracy: 0.6871 - val_loss: 0.9533 - val_accuracy: 0.6346\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.9487 - accuracy: 0.7041 - val_loss: 0.8977 - val_accuracy: 0.6731\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.9095 - accuracy: 0.7177 - val_loss: 0.8532 - val_accuracy: 0.6923\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.8667 - accuracy: 0.7381 - val_loss: 0.8134 - val_accuracy: 0.6923\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.8300 - accuracy: 0.7381 - val_loss: 0.7823 - val_accuracy: 0.7308\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.7988 - accuracy: 0.7415 - val_loss: 0.7575 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.7676 - accuracy: 0.7517 - val_loss: 0.7251 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.7430 - accuracy: 0.7551 - val_loss: 0.7012 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.7211 - accuracy: 0.7619 - val_loss: 0.6755 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.7012 - accuracy: 0.7653 - val_loss: 0.6620 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.6848 - accuracy: 0.7585 - val_loss: 0.6475 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.6706 - accuracy: 0.7721 - val_loss: 0.6389 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.6577 - accuracy: 0.7653 - val_loss: 0.6222 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.6470 - accuracy: 0.7619 - val_loss: 0.6068 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.6375 - accuracy: 0.7721 - val_loss: 0.6104 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6293 - accuracy: 0.7687 - val_loss: 0.5939 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.6187 - accuracy: 0.7755 - val_loss: 0.5916 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.6108 - accuracy: 0.7755 - val_loss: 0.5906 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.6049 - accuracy: 0.7755 - val_loss: 0.5799 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.6003 - accuracy: 0.7653 - val_loss: 0.5807 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.5925 - accuracy: 0.7789 - val_loss: 0.5731 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5870 - accuracy: 0.7755 - val_loss: 0.5661 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5830 - accuracy: 0.7789 - val_loss: 0.5645 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5782 - accuracy: 0.7789 - val_loss: 0.5566 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 629us/step - loss: 0.5735 - accuracy: 0.7755 - val_loss: 0.5567 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5687 - accuracy: 0.7789 - val_loss: 0.5547 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5674 - accuracy: 0.7721 - val_loss: 0.5511 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.5613 - accuracy: 0.7789 - val_loss: 0.5546 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 625us/step - loss: 0.5592 - accuracy: 0.7823 - val_loss: 0.5549 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.5558 - accuracy: 0.7789 - val_loss: 0.5469 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5526 - accuracy: 0.7823 - val_loss: 0.5407 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 825us/step - loss: 0.5497 - accuracy: 0.7857 - val_loss: 0.5443 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.5463 - accuracy: 0.7789 - val_loss: 0.5398 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5434 - accuracy: 0.7823 - val_loss: 0.5405 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 816us/step - loss: 0.5414 - accuracy: 0.7823 - val_loss: 0.5433 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.5400 - accuracy: 0.7789 - val_loss: 0.5412 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 739us/step - loss: 0.5360 - accuracy: 0.7823 - val_loss: 0.5333 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.5344 - accuracy: 0.7823 - val_loss: 0.5329 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5313 - accuracy: 0.7823 - val_loss: 0.5325 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5296 - accuracy: 0.7823 - val_loss: 0.5314 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 469us/step - loss: 0.5269 - accuracy: 0.7823 - val_loss: 0.5292 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.5257 - accuracy: 0.7857 - val_loss: 0.5325 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5248 - accuracy: 0.7789 - val_loss: 0.5318 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.5231 - accuracy: 0.7823 - val_loss: 0.5289 - val_accuracy: 0.8654\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.5217 - accuracy: 0.7857 - val_loss: 0.5364 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 0.5190 - accuracy: 0.7823 - val_loss: 0.5293 - val_accuracy: 0.8654\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.5158 - accuracy: 0.7857 - val_loss: 0.5246 - val_accuracy: 0.8654\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.5139 - accuracy: 0.7823 - val_loss: 0.5221 - val_accuracy: 0.8654\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5132 - accuracy: 0.7823 - val_loss: 0.5277 - val_accuracy: 0.8654\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5110 - accuracy: 0.7857 - val_loss: 0.5216 - val_accuracy: 0.8654\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5113 - accuracy: 0.7823 - val_loss: 0.5174 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.5109 - accuracy: 0.7823 - val_loss: 0.5289 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5068 - accuracy: 0.7823 - val_loss: 0.5241 - val_accuracy: 0.8654\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5062 - accuracy: 0.7823 - val_loss: 0.5296 - val_accuracy: 0.8654\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 692us/step - loss: 0.5035 - accuracy: 0.7857 - val_loss: 0.5148 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5032 - accuracy: 0.7823 - val_loss: 0.5184 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5013 - accuracy: 0.7823 - val_loss: 0.5186 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5004 - accuracy: 0.7891 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4984 - accuracy: 0.7823 - val_loss: 0.5181 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.5006 - accuracy: 0.7823 - val_loss: 0.5153 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4954 - accuracy: 0.7857 - val_loss: 0.5210 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.4964 - accuracy: 0.7823 - val_loss: 0.5207 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.4928 - accuracy: 0.7823 - val_loss: 0.5181 - val_accuracy: 0.8654\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4935 - accuracy: 0.7823 - val_loss: 0.5133 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4928 - accuracy: 0.7823 - val_loss: 0.5118 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4897 - accuracy: 0.7857 - val_loss: 0.5102 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4878 - accuracy: 0.7857 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4867 - accuracy: 0.7823 - val_loss: 0.5151 - val_accuracy: 0.8654\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 602us/step - loss: 0.4864 - accuracy: 0.7857 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.4854 - accuracy: 0.7857 - val_loss: 0.5112 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4843 - accuracy: 0.7823 - val_loss: 0.5142 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.4841 - accuracy: 0.7925 - val_loss: 0.5004 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.4806 - accuracy: 0.7891 - val_loss: 0.5050 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4803 - accuracy: 0.7857 - val_loss: 0.5002 - val_accuracy: 0.8654\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.4797 - accuracy: 0.7891 - val_loss: 0.5044 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.4793 - accuracy: 0.7823 - val_loss: 0.5048 - val_accuracy: 0.8654\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4774 - accuracy: 0.7891 - val_loss: 0.5041 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4756 - accuracy: 0.7959 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4761 - accuracy: 0.7891 - val_loss: 0.5027 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.4761 - accuracy: 0.7925 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.4729 - accuracy: 0.7925 - val_loss: 0.5031 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4736 - accuracy: 0.7993 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4709 - accuracy: 0.8061 - val_loss: 0.5017 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.4694 - accuracy: 0.7959 - val_loss: 0.5038 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.4692 - accuracy: 0.8027 - val_loss: 0.5013 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4679 - accuracy: 0.8027 - val_loss: 0.5008 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.4688 - accuracy: 0.7959 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 328us/step - loss: 0.4670 - accuracy: 0.8061 - val_loss: 0.4956 - val_accuracy: 0.8077\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.4658 - accuracy: 0.8061 - val_loss: 0.4979 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4650 - accuracy: 0.8061 - val_loss: 0.5021 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.4643 - accuracy: 0.8061 - val_loss: 0.4960 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4634 - accuracy: 0.7993 - val_loss: 0.5020 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.4630 - accuracy: 0.8061 - val_loss: 0.4956 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.4617 - accuracy: 0.8061 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.4604 - accuracy: 0.7993 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.4609 - accuracy: 0.7959 - val_loss: 0.5043 - val_accuracy: 0.8269\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4586 - accuracy: 0.8027 - val_loss: 0.4971 - val_accuracy: 0.8077\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.4583 - accuracy: 0.8061 - val_loss: 0.4997 - val_accuracy: 0.8077\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.4571 - accuracy: 0.7993 - val_loss: 0.5056 - val_accuracy: 0.8269\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.4573 - accuracy: 0.7993 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4569 - accuracy: 0.8061 - val_loss: 0.5006 - val_accuracy: 0.8077\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4561 - accuracy: 0.8027 - val_loss: 0.5046 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.4540 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 91us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.6268 - accuracy: 0.2653 - val_loss: 1.5090 - val_accuracy: 0.2885\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 1.3991 - accuracy: 0.2959 - val_loss: 1.3394 - val_accuracy: 0.2885\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 1.2720 - accuracy: 0.4082 - val_loss: 1.2250 - val_accuracy: 0.4615\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 1.1791 - accuracy: 0.4422 - val_loss: 1.1300 - val_accuracy: 0.5385\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 1.0985 - accuracy: 0.5476 - val_loss: 1.0583 - val_accuracy: 0.5769\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 586us/step - loss: 1.0311 - accuracy: 0.6327 - val_loss: 0.9909 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.9722 - accuracy: 0.7007 - val_loss: 0.9349 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.9185 - accuracy: 0.7075 - val_loss: 0.8922 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.8746 - accuracy: 0.7177 - val_loss: 0.8401 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.8376 - accuracy: 0.7211 - val_loss: 0.8030 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.8042 - accuracy: 0.7381 - val_loss: 0.7718 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.7787 - accuracy: 0.7551 - val_loss: 0.7411 - val_accuracy: 0.8269\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.7502 - accuracy: 0.7483 - val_loss: 0.7194 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 692us/step - loss: 0.7297 - accuracy: 0.7517 - val_loss: 0.7014 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 774us/step - loss: 0.7114 - accuracy: 0.7551 - val_loss: 0.6790 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.6950 - accuracy: 0.7517 - val_loss: 0.6605 - val_accuracy: 0.8462\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.6782 - accuracy: 0.7551 - val_loss: 0.6545 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.6666 - accuracy: 0.7551 - val_loss: 0.6364 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.6561 - accuracy: 0.7517 - val_loss: 0.6282 - val_accuracy: 0.8462\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.6476 - accuracy: 0.7517 - val_loss: 0.6232 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.6350 - accuracy: 0.7619 - val_loss: 0.6102 - val_accuracy: 0.8462\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.6278 - accuracy: 0.7551 - val_loss: 0.6077 - val_accuracy: 0.8462\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.6202 - accuracy: 0.7551 - val_loss: 0.6007 - val_accuracy: 0.8462\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.6128 - accuracy: 0.7517 - val_loss: 0.5920 - val_accuracy: 0.8462\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 701us/step - loss: 0.6054 - accuracy: 0.7619 - val_loss: 0.5887 - val_accuracy: 0.8462\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5997 - accuracy: 0.7653 - val_loss: 0.5771 - val_accuracy: 0.8462\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5941 - accuracy: 0.7551 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5883 - accuracy: 0.7653 - val_loss: 0.5746 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5885 - accuracy: 0.7585 - val_loss: 0.5728 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5814 - accuracy: 0.7687 - val_loss: 0.5667 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5752 - accuracy: 0.7585 - val_loss: 0.5693 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5704 - accuracy: 0.7619 - val_loss: 0.5628 - val_accuracy: 0.8462\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5675 - accuracy: 0.7687 - val_loss: 0.5610 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5648 - accuracy: 0.7687 - val_loss: 0.5590 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5608 - accuracy: 0.7585 - val_loss: 0.5644 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5556 - accuracy: 0.7653 - val_loss: 0.5538 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5553 - accuracy: 0.7687 - val_loss: 0.5553 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5533 - accuracy: 0.7585 - val_loss: 0.5475 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5477 - accuracy: 0.7755 - val_loss: 0.5498 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 301us/step - loss: 0.5479 - accuracy: 0.7687 - val_loss: 0.5566 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.5443 - accuracy: 0.7789 - val_loss: 0.5433 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5420 - accuracy: 0.7823 - val_loss: 0.5501 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5391 - accuracy: 0.7653 - val_loss: 0.5462 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.5359 - accuracy: 0.7755 - val_loss: 0.5421 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5347 - accuracy: 0.7857 - val_loss: 0.5417 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5324 - accuracy: 0.7755 - val_loss: 0.5438 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.5289 - accuracy: 0.7721 - val_loss: 0.5402 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5278 - accuracy: 0.7823 - val_loss: 0.5402 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5258 - accuracy: 0.7755 - val_loss: 0.5413 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5240 - accuracy: 0.7755 - val_loss: 0.5399 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5211 - accuracy: 0.7857 - val_loss: 0.5403 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5213 - accuracy: 0.7789 - val_loss: 0.5376 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5188 - accuracy: 0.7857 - val_loss: 0.5318 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5175 - accuracy: 0.7857 - val_loss: 0.5307 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5154 - accuracy: 0.7823 - val_loss: 0.5338 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5159 - accuracy: 0.7789 - val_loss: 0.5370 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5118 - accuracy: 0.7891 - val_loss: 0.5279 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.5118 - accuracy: 0.7891 - val_loss: 0.5296 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5093 - accuracy: 0.7925 - val_loss: 0.5284 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5078 - accuracy: 0.7925 - val_loss: 0.5338 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5065 - accuracy: 0.7925 - val_loss: 0.5334 - val_accuracy: 0.8077\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5049 - accuracy: 0.7891 - val_loss: 0.5329 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.5059 - accuracy: 0.7857 - val_loss: 0.5339 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5028 - accuracy: 0.7891 - val_loss: 0.5285 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5007 - accuracy: 0.8027 - val_loss: 0.5308 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.5010 - accuracy: 0.7993 - val_loss: 0.5226 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.4986 - accuracy: 0.7993 - val_loss: 0.5323 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.4989 - accuracy: 0.7993 - val_loss: 0.5225 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4954 - accuracy: 0.7993 - val_loss: 0.5309 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4957 - accuracy: 0.8027 - val_loss: 0.5322 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4941 - accuracy: 0.7993 - val_loss: 0.5299 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.4920 - accuracy: 0.7993 - val_loss: 0.5229 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.4912 - accuracy: 0.8027 - val_loss: 0.5249 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4898 - accuracy: 0.8061 - val_loss: 0.5226 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.4887 - accuracy: 0.8061 - val_loss: 0.5266 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4872 - accuracy: 0.8095 - val_loss: 0.5250 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.4873 - accuracy: 0.8129 - val_loss: 0.5259 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4851 - accuracy: 0.8129 - val_loss: 0.5263 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 230us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.8173 - accuracy: 0.2347 - val_loss: 1.6646 - val_accuracy: 0.2115\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 1.5300 - accuracy: 0.2653 - val_loss: 1.4626 - val_accuracy: 0.2692\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 1.3767 - accuracy: 0.3027 - val_loss: 1.3478 - val_accuracy: 0.3269\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 1.2847 - accuracy: 0.4014 - val_loss: 1.2691 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 1.2176 - accuracy: 0.5068 - val_loss: 1.1928 - val_accuracy: 0.5962\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 1.1565 - accuracy: 0.5986 - val_loss: 1.1396 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 1.0967 - accuracy: 0.6667 - val_loss: 1.0773 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 1.0394 - accuracy: 0.7075 - val_loss: 1.0177 - val_accuracy: 0.7500\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.9843 - accuracy: 0.7313 - val_loss: 0.9700 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.9336 - accuracy: 0.7449 - val_loss: 0.9223 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.8879 - accuracy: 0.7483 - val_loss: 0.8817 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.8472 - accuracy: 0.7449 - val_loss: 0.8372 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.8114 - accuracy: 0.7381 - val_loss: 0.7983 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.7804 - accuracy: 0.7415 - val_loss: 0.7695 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.7532 - accuracy: 0.7415 - val_loss: 0.7473 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.7307 - accuracy: 0.7517 - val_loss: 0.7217 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 342us/step - loss: 0.7103 - accuracy: 0.7517 - val_loss: 0.7050 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.6934 - accuracy: 0.7449 - val_loss: 0.6798 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 861us/step - loss: 0.6775 - accuracy: 0.7483 - val_loss: 0.6693 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.6637 - accuracy: 0.7517 - val_loss: 0.6508 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.6517 - accuracy: 0.7483 - val_loss: 0.6455 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.6395 - accuracy: 0.7585 - val_loss: 0.6331 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.6316 - accuracy: 0.7517 - val_loss: 0.6203 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.6226 - accuracy: 0.7619 - val_loss: 0.6089 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.6134 - accuracy: 0.7653 - val_loss: 0.6040 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.6067 - accuracy: 0.7619 - val_loss: 0.5936 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.6013 - accuracy: 0.7653 - val_loss: 0.5919 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5956 - accuracy: 0.7585 - val_loss: 0.5832 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5900 - accuracy: 0.7585 - val_loss: 0.5848 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5858 - accuracy: 0.7619 - val_loss: 0.5812 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5823 - accuracy: 0.7585 - val_loss: 0.5726 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5760 - accuracy: 0.7619 - val_loss: 0.5708 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.5736 - accuracy: 0.7585 - val_loss: 0.5658 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.5679 - accuracy: 0.7585 - val_loss: 0.5622 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.5659 - accuracy: 0.7619 - val_loss: 0.5627 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.5624 - accuracy: 0.7619 - val_loss: 0.5545 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5595 - accuracy: 0.7585 - val_loss: 0.5531 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5550 - accuracy: 0.7551 - val_loss: 0.5498 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 618us/step - loss: 0.5529 - accuracy: 0.7517 - val_loss: 0.5481 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5513 - accuracy: 0.7619 - val_loss: 0.5459 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5494 - accuracy: 0.7687 - val_loss: 0.5406 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5457 - accuracy: 0.7619 - val_loss: 0.5392 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.5444 - accuracy: 0.7653 - val_loss: 0.5347 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5416 - accuracy: 0.7721 - val_loss: 0.5409 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5382 - accuracy: 0.7687 - val_loss: 0.5452 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.5348 - accuracy: 0.7585 - val_loss: 0.5338 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5354 - accuracy: 0.7619 - val_loss: 0.5345 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.5322 - accuracy: 0.7585 - val_loss: 0.5389 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 704us/step - loss: 0.5322 - accuracy: 0.7619 - val_loss: 0.5319 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5274 - accuracy: 0.7687 - val_loss: 0.5362 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.5279 - accuracy: 0.7721 - val_loss: 0.5269 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 751us/step - loss: 0.5255 - accuracy: 0.7687 - val_loss: 0.5248 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 973us/step - loss: 0.5220 - accuracy: 0.7653 - val_loss: 0.5274 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5206 - accuracy: 0.7687 - val_loss: 0.5277 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 0.5187 - accuracy: 0.7687 - val_loss: 0.5298 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 603us/step - loss: 0.5173 - accuracy: 0.7789 - val_loss: 0.5233 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 895us/step - loss: 0.5147 - accuracy: 0.7755 - val_loss: 0.5265 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.5139 - accuracy: 0.7823 - val_loss: 0.5207 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5124 - accuracy: 0.7755 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5107 - accuracy: 0.7857 - val_loss: 0.5263 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5098 - accuracy: 0.7755 - val_loss: 0.5292 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5093 - accuracy: 0.7823 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5057 - accuracy: 0.7823 - val_loss: 0.5217 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5052 - accuracy: 0.7857 - val_loss: 0.5228 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5045 - accuracy: 0.7959 - val_loss: 0.5222 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.5015 - accuracy: 0.7925 - val_loss: 0.5227 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5007 - accuracy: 0.7823 - val_loss: 0.5208 - val_accuracy: 0.8654\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4998 - accuracy: 0.7925 - val_loss: 0.5226 - val_accuracy: 0.8654\n",
      "116/116 [==============================] - 0s 117us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5341 - accuracy: 0.2721 - val_loss: 1.3620 - val_accuracy: 0.4038\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 1.3719 - accuracy: 0.3163 - val_loss: 1.2451 - val_accuracy: 0.4231\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 1.2737 - accuracy: 0.3810 - val_loss: 1.1528 - val_accuracy: 0.5962\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 286us/step - loss: 1.1933 - accuracy: 0.4728 - val_loss: 1.0917 - val_accuracy: 0.6538\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 1.1253 - accuracy: 0.5986 - val_loss: 1.0257 - val_accuracy: 0.7308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 1.0648 - accuracy: 0.6803 - val_loss: 0.9717 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 1.0077 - accuracy: 0.6973 - val_loss: 0.9098 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.9524 - accuracy: 0.7007 - val_loss: 0.8645 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.9033 - accuracy: 0.6939 - val_loss: 0.8146 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 0.8589 - accuracy: 0.7075 - val_loss: 0.7797 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.8201 - accuracy: 0.7245 - val_loss: 0.7416 - val_accuracy: 0.7500\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.7898 - accuracy: 0.7109 - val_loss: 0.7148 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.7626 - accuracy: 0.7211 - val_loss: 0.6939 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 879us/step - loss: 0.7390 - accuracy: 0.7279 - val_loss: 0.6819 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.7187 - accuracy: 0.7381 - val_loss: 0.6619 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.7004 - accuracy: 0.7279 - val_loss: 0.6418 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.6866 - accuracy: 0.7313 - val_loss: 0.6315 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.6732 - accuracy: 0.7347 - val_loss: 0.6205 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.6628 - accuracy: 0.7381 - val_loss: 0.6154 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 643us/step - loss: 0.6496 - accuracy: 0.7517 - val_loss: 0.6010 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.6439 - accuracy: 0.7313 - val_loss: 0.5841 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.6338 - accuracy: 0.7517 - val_loss: 0.5917 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.6255 - accuracy: 0.7483 - val_loss: 0.5785 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 793us/step - loss: 0.6181 - accuracy: 0.7483 - val_loss: 0.5811 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.6122 - accuracy: 0.7517 - val_loss: 0.5714 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.6055 - accuracy: 0.7483 - val_loss: 0.5648 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 754us/step - loss: 0.5993 - accuracy: 0.7517 - val_loss: 0.5540 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.5948 - accuracy: 0.7551 - val_loss: 0.5511 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.5910 - accuracy: 0.7619 - val_loss: 0.5492 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 703us/step - loss: 0.5882 - accuracy: 0.7551 - val_loss: 0.5401 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.5808 - accuracy: 0.7585 - val_loss: 0.5425 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.5756 - accuracy: 0.7653 - val_loss: 0.5410 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 663us/step - loss: 0.5719 - accuracy: 0.7687 - val_loss: 0.5416 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.5675 - accuracy: 0.7653 - val_loss: 0.5300 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5663 - accuracy: 0.7653 - val_loss: 0.5348 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5615 - accuracy: 0.7687 - val_loss: 0.5307 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5595 - accuracy: 0.7721 - val_loss: 0.5256 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5538 - accuracy: 0.7687 - val_loss: 0.5311 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.5516 - accuracy: 0.7755 - val_loss: 0.5226 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.5505 - accuracy: 0.7687 - val_loss: 0.5194 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.5461 - accuracy: 0.7823 - val_loss: 0.5182 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5455 - accuracy: 0.7789 - val_loss: 0.5191 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5411 - accuracy: 0.7721 - val_loss: 0.5127 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5386 - accuracy: 0.7755 - val_loss: 0.5105 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 710us/step - loss: 0.5371 - accuracy: 0.7891 - val_loss: 0.5159 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.5342 - accuracy: 0.7755 - val_loss: 0.5055 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5322 - accuracy: 0.7721 - val_loss: 0.5104 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 725us/step - loss: 0.5291 - accuracy: 0.7823 - val_loss: 0.5044 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5273 - accuracy: 0.7755 - val_loss: 0.5115 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 0.5246 - accuracy: 0.7755 - val_loss: 0.4986 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 646us/step - loss: 0.5224 - accuracy: 0.7891 - val_loss: 0.5055 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 815us/step - loss: 0.5197 - accuracy: 0.7755 - val_loss: 0.4995 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.5174 - accuracy: 0.7857 - val_loss: 0.4987 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.5166 - accuracy: 0.7755 - val_loss: 0.4971 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5137 - accuracy: 0.7823 - val_loss: 0.4947 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5129 - accuracy: 0.7857 - val_loss: 0.4978 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.5111 - accuracy: 0.7823 - val_loss: 0.4985 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 710us/step - loss: 0.5106 - accuracy: 0.7925 - val_loss: 0.4943 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.5093 - accuracy: 0.7823 - val_loss: 0.4985 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 420us/step - loss: 0.5053 - accuracy: 0.7823 - val_loss: 0.4918 - val_accuracy: 0.8077\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.5049 - accuracy: 0.7823 - val_loss: 0.4949 - val_accuracy: 0.8077\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.5036 - accuracy: 0.7925 - val_loss: 0.4880 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5022 - accuracy: 0.7925 - val_loss: 0.4941 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5007 - accuracy: 0.7823 - val_loss: 0.4993 - val_accuracy: 0.8077\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4987 - accuracy: 0.7857 - val_loss: 0.4900 - val_accuracy: 0.8077\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 816us/step - loss: 0.4963 - accuracy: 0.7891 - val_loss: 0.4882 - val_accuracy: 0.8077\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 863us/step - loss: 0.4984 - accuracy: 0.7823 - val_loss: 0.4863 - val_accuracy: 0.8077\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.79 - 0s 678us/step - loss: 0.4971 - accuracy: 0.7925 - val_loss: 0.4856 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 648us/step - loss: 0.4938 - accuracy: 0.7823 - val_loss: 0.4921 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.4908 - accuracy: 0.7891 - val_loss: 0.4877 - val_accuracy: 0.8077\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.4888 - accuracy: 0.7857 - val_loss: 0.4812 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.4884 - accuracy: 0.7925 - val_loss: 0.4905 - val_accuracy: 0.8077\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 620us/step - loss: 0.4875 - accuracy: 0.7857 - val_loss: 0.4851 - val_accuracy: 0.8077\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.4866 - accuracy: 0.7891 - val_loss: 0.4762 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 649us/step - loss: 0.4857 - accuracy: 0.7925 - val_loss: 0.4952 - val_accuracy: 0.8077\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.4823 - accuracy: 0.7891 - val_loss: 0.4806 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.4818 - accuracy: 0.7925 - val_loss: 0.4806 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.4805 - accuracy: 0.8027 - val_loss: 0.4830 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.4786 - accuracy: 0.7959 - val_loss: 0.4779 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4776 - accuracy: 0.7993 - val_loss: 0.4851 - val_accuracy: 0.8077\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.4777 - accuracy: 0.7925 - val_loss: 0.4815 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4750 - accuracy: 0.7959 - val_loss: 0.4846 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.4735 - accuracy: 0.7925 - val_loss: 0.4780 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4722 - accuracy: 0.7925 - val_loss: 0.4814 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 358us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4775 - accuracy: 0.2823 - val_loss: 1.4970 - val_accuracy: 0.2308\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 1.3018 - accuracy: 0.3776 - val_loss: 1.3177 - val_accuracy: 0.3269\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 1.1829 - accuracy: 0.4388 - val_loss: 1.1919 - val_accuracy: 0.4038\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 1.0934 - accuracy: 0.5612 - val_loss: 1.0965 - val_accuracy: 0.5000\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 1.0193 - accuracy: 0.6327 - val_loss: 1.0158 - val_accuracy: 0.5769\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 707us/step - loss: 0.9512 - accuracy: 0.6837 - val_loss: 0.9497 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.8902 - accuracy: 0.6871 - val_loss: 0.8849 - val_accuracy: 0.7115\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.8353 - accuracy: 0.7075 - val_loss: 0.8402 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.7906 - accuracy: 0.7177 - val_loss: 0.8001 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.7512 - accuracy: 0.7245 - val_loss: 0.7636 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.7196 - accuracy: 0.7211 - val_loss: 0.7432 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.6929 - accuracy: 0.7449 - val_loss: 0.7191 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.6736 - accuracy: 0.7415 - val_loss: 0.6877 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.6546 - accuracy: 0.7517 - val_loss: 0.6754 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6395 - accuracy: 0.7619 - val_loss: 0.6644 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6274 - accuracy: 0.7517 - val_loss: 0.6478 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.6167 - accuracy: 0.7585 - val_loss: 0.6392 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 254us/step - loss: 0.6076 - accuracy: 0.7619 - val_loss: 0.6242 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5985 - accuracy: 0.7585 - val_loss: 0.6177 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.5911 - accuracy: 0.7653 - val_loss: 0.6050 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.5834 - accuracy: 0.7687 - val_loss: 0.6019 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5796 - accuracy: 0.7687 - val_loss: 0.5925 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5729 - accuracy: 0.7789 - val_loss: 0.5887 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 593us/step - loss: 0.5669 - accuracy: 0.7687 - val_loss: 0.5837 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 798us/step - loss: 0.5612 - accuracy: 0.7755 - val_loss: 0.5744 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 856us/step - loss: 0.5567 - accuracy: 0.7721 - val_loss: 0.5758 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.5544 - accuracy: 0.7755 - val_loss: 0.5724 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 743us/step - loss: 0.5497 - accuracy: 0.7721 - val_loss: 0.5618 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 694us/step - loss: 0.5465 - accuracy: 0.7721 - val_loss: 0.5638 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.5427 - accuracy: 0.7755 - val_loss: 0.5537 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 641us/step - loss: 0.5410 - accuracy: 0.7687 - val_loss: 0.5509 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5373 - accuracy: 0.7721 - val_loss: 0.5446 - val_accuracy: 0.8462\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5365 - accuracy: 0.7789 - val_loss: 0.5468 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5351 - accuracy: 0.7789 - val_loss: 0.5411 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.5280 - accuracy: 0.7789 - val_loss: 0.5433 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.5256 - accuracy: 0.7755 - val_loss: 0.5352 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5236 - accuracy: 0.7721 - val_loss: 0.5322 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5220 - accuracy: 0.7755 - val_loss: 0.5290 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5199 - accuracy: 0.7823 - val_loss: 0.5327 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5186 - accuracy: 0.7721 - val_loss: 0.5280 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5166 - accuracy: 0.7755 - val_loss: 0.5294 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5156 - accuracy: 0.7857 - val_loss: 0.5297 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5142 - accuracy: 0.7789 - val_loss: 0.5325 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5112 - accuracy: 0.7755 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5097 - accuracy: 0.7857 - val_loss: 0.5206 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5081 - accuracy: 0.7721 - val_loss: 0.5244 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 814us/step - loss: 0.5048 - accuracy: 0.7857 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.5045 - accuracy: 0.7891 - val_loss: 0.5206 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5034 - accuracy: 0.7857 - val_loss: 0.5205 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5017 - accuracy: 0.7823 - val_loss: 0.5154 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5001 - accuracy: 0.7891 - val_loss: 0.5203 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.4977 - accuracy: 0.7823 - val_loss: 0.5158 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 255us/step - loss: 0.4989 - accuracy: 0.7823 - val_loss: 0.5157 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 0.4950 - accuracy: 0.7823 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4964 - accuracy: 0.7891 - val_loss: 0.5192 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4917 - accuracy: 0.7959 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4919 - accuracy: 0.7857 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 0.4915 - accuracy: 0.7959 - val_loss: 0.5085 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.4896 - accuracy: 0.7925 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 791us/step - loss: 0.4877 - accuracy: 0.7857 - val_loss: 0.5201 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 696us/step - loss: 0.4876 - accuracy: 0.7857 - val_loss: 0.5206 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 600us/step - loss: 0.4858 - accuracy: 0.7993 - val_loss: 0.5044 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.4852 - accuracy: 0.7959 - val_loss: 0.5043 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.4861 - accuracy: 0.7891 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4835 - accuracy: 0.7959 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.4819 - accuracy: 0.7925 - val_loss: 0.5119 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4806 - accuracy: 0.7959 - val_loss: 0.5124 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 691us/step - loss: 0.4798 - accuracy: 0.7959 - val_loss: 0.5093 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.4777 - accuracy: 0.8027 - val_loss: 0.5078 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4778 - accuracy: 0.7993 - val_loss: 0.5058 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.4772 - accuracy: 0.7993 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4750 - accuracy: 0.7959 - val_loss: 0.5093 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.4724 - accuracy: 0.8061 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.4738 - accuracy: 0.8027 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4703 - accuracy: 0.8027 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 104us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.7120 - accuracy: 0.2381 - val_loss: 1.5401 - val_accuracy: 0.1538\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 1.3928 - accuracy: 0.2551 - val_loss: 1.3112 - val_accuracy: 0.4038\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 628us/step - loss: 1.2686 - accuracy: 0.3810 - val_loss: 1.2030 - val_accuracy: 0.4231\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 1.1797 - accuracy: 0.4660 - val_loss: 1.1242 - val_accuracy: 0.4615\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 1.1057 - accuracy: 0.5340 - val_loss: 1.0538 - val_accuracy: 0.5385\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 1.0455 - accuracy: 0.5816 - val_loss: 0.9979 - val_accuracy: 0.5769\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.9879 - accuracy: 0.6395 - val_loss: 0.9477 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.9418 - accuracy: 0.6667 - val_loss: 0.9062 - val_accuracy: 0.6731\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.8992 - accuracy: 0.6803 - val_loss: 0.8717 - val_accuracy: 0.6923\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.8612 - accuracy: 0.6939 - val_loss: 0.8377 - val_accuracy: 0.7115\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 337us/step - loss: 0.8281 - accuracy: 0.7007 - val_loss: 0.8077 - val_accuracy: 0.7115\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.7988 - accuracy: 0.6939 - val_loss: 0.7780 - val_accuracy: 0.7115\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.7734 - accuracy: 0.7109 - val_loss: 0.7587 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.7499 - accuracy: 0.7177 - val_loss: 0.7397 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.7292 - accuracy: 0.7279 - val_loss: 0.7212 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.7116 - accuracy: 0.7483 - val_loss: 0.7014 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.6941 - accuracy: 0.7313 - val_loss: 0.6821 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.6749 - accuracy: 0.7585 - val_loss: 0.6717 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6595 - accuracy: 0.7687 - val_loss: 0.6527 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.6463 - accuracy: 0.7653 - val_loss: 0.6473 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.6368 - accuracy: 0.7721 - val_loss: 0.6384 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.6262 - accuracy: 0.7585 - val_loss: 0.6262 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.6189 - accuracy: 0.7653 - val_loss: 0.6178 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.6119 - accuracy: 0.7687 - val_loss: 0.6135 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.6047 - accuracy: 0.7653 - val_loss: 0.6092 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.6000 - accuracy: 0.7653 - val_loss: 0.6066 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5932 - accuracy: 0.7755 - val_loss: 0.6080 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.5881 - accuracy: 0.7619 - val_loss: 0.5914 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5837 - accuracy: 0.7687 - val_loss: 0.5905 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5779 - accuracy: 0.7789 - val_loss: 0.5916 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.5739 - accuracy: 0.7755 - val_loss: 0.5885 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5699 - accuracy: 0.7653 - val_loss: 0.5802 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5661 - accuracy: 0.7755 - val_loss: 0.5904 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5644 - accuracy: 0.7755 - val_loss: 0.5853 - val_accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5585 - accuracy: 0.7755 - val_loss: 0.5820 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5556 - accuracy: 0.7721 - val_loss: 0.5726 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5550 - accuracy: 0.7721 - val_loss: 0.5721 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.5509 - accuracy: 0.7687 - val_loss: 0.5676 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5481 - accuracy: 0.7721 - val_loss: 0.5608 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 250us/step - loss: 0.5446 - accuracy: 0.7755 - val_loss: 0.5685 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5412 - accuracy: 0.7721 - val_loss: 0.5638 - val_accuracy: 0.7885\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5390 - accuracy: 0.7721 - val_loss: 0.5647 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.5373 - accuracy: 0.7721 - val_loss: 0.5631 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5356 - accuracy: 0.7755 - val_loss: 0.5554 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5312 - accuracy: 0.7789 - val_loss: 0.5648 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5303 - accuracy: 0.7789 - val_loss: 0.5571 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5281 - accuracy: 0.7755 - val_loss: 0.5589 - val_accuracy: 0.7885\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5253 - accuracy: 0.7789 - val_loss: 0.5577 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5236 - accuracy: 0.7823 - val_loss: 0.5512 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5227 - accuracy: 0.7687 - val_loss: 0.5466 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5213 - accuracy: 0.7823 - val_loss: 0.5508 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5181 - accuracy: 0.7823 - val_loss: 0.5463 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5186 - accuracy: 0.7823 - val_loss: 0.5495 - val_accuracy: 0.7885\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5147 - accuracy: 0.7789 - val_loss: 0.5394 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5124 - accuracy: 0.7823 - val_loss: 0.5468 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 194us/step - loss: 0.5115 - accuracy: 0.7823 - val_loss: 0.5477 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5102 - accuracy: 0.7755 - val_loss: 0.5428 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.5092 - accuracy: 0.7857 - val_loss: 0.5457 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.5083 - accuracy: 0.7823 - val_loss: 0.5306 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.5036 - accuracy: 0.7857 - val_loss: 0.5443 - val_accuracy: 0.8077\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5057 - accuracy: 0.7721 - val_loss: 0.5388 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5013 - accuracy: 0.7755 - val_loss: 0.5365 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5010 - accuracy: 0.7891 - val_loss: 0.5408 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 0.5002 - accuracy: 0.7857 - val_loss: 0.5310 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.4969 - accuracy: 0.7891 - val_loss: 0.5405 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 207us/step - loss: 0.4957 - accuracy: 0.7891 - val_loss: 0.5307 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 300us/step - loss: 0.4950 - accuracy: 0.7823 - val_loss: 0.5341 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4935 - accuracy: 0.7823 - val_loss: 0.5273 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4933 - accuracy: 0.7891 - val_loss: 0.5184 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.4932 - accuracy: 0.7993 - val_loss: 0.5246 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4900 - accuracy: 0.7959 - val_loss: 0.5303 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4875 - accuracy: 0.7891 - val_loss: 0.5203 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4867 - accuracy: 0.7925 - val_loss: 0.5106 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4863 - accuracy: 0.7925 - val_loss: 0.5204 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4859 - accuracy: 0.7891 - val_loss: 0.5130 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4851 - accuracy: 0.7857 - val_loss: 0.5205 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4809 - accuracy: 0.7891 - val_loss: 0.5149 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4827 - accuracy: 0.7823 - val_loss: 0.5119 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4793 - accuracy: 0.7959 - val_loss: 0.5129 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4799 - accuracy: 0.7925 - val_loss: 0.5176 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4772 - accuracy: 0.8027 - val_loss: 0.5175 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4775 - accuracy: 0.7925 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4755 - accuracy: 0.7959 - val_loss: 0.5096 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4739 - accuracy: 0.7891 - val_loss: 0.5091 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.4720 - accuracy: 0.7959 - val_loss: 0.5049 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4743 - accuracy: 0.7993 - val_loss: 0.5136 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4717 - accuracy: 0.7823 - val_loss: 0.5081 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.4709 - accuracy: 0.7891 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4693 - accuracy: 0.7925 - val_loss: 0.5061 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.4666 - accuracy: 0.7925 - val_loss: 0.5093 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4669 - accuracy: 0.7891 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4664 - accuracy: 0.7925 - val_loss: 0.5063 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4653 - accuracy: 0.7891 - val_loss: 0.4994 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4641 - accuracy: 0.7891 - val_loss: 0.5037 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.4622 - accuracy: 0.7857 - val_loss: 0.5053 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4605 - accuracy: 0.7925 - val_loss: 0.5060 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.4604 - accuracy: 0.7891 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4584 - accuracy: 0.7993 - val_loss: 0.4974 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4584 - accuracy: 0.7993 - val_loss: 0.5082 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4565 - accuracy: 0.7925 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4566 - accuracy: 0.7891 - val_loss: 0.4978 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4544 - accuracy: 0.8027 - val_loss: 0.4928 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4533 - accuracy: 0.7959 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4523 - accuracy: 0.7925 - val_loss: 0.5040 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4535 - accuracy: 0.7993 - val_loss: 0.4979 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4513 - accuracy: 0.7993 - val_loss: 0.4874 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4490 - accuracy: 0.7959 - val_loss: 0.4986 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4488 - accuracy: 0.7959 - val_loss: 0.4912 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.4476 - accuracy: 0.7891 - val_loss: 0.4920 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4471 - accuracy: 0.7925 - val_loss: 0.4989 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4449 - accuracy: 0.8061 - val_loss: 0.4935 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4437 - accuracy: 0.7959 - val_loss: 0.4869 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.4430 - accuracy: 0.7993 - val_loss: 0.4821 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4430 - accuracy: 0.8027 - val_loss: 0.4884 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4429 - accuracy: 0.7925 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4387 - accuracy: 0.8027 - val_loss: 0.4907 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.4396 - accuracy: 0.7993 - val_loss: 0.4891 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4393 - accuracy: 0.7959 - val_loss: 0.4855 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4370 - accuracy: 0.7959 - val_loss: 0.4831 - val_accuracy: 0.8462\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4399 - accuracy: 0.7959 - val_loss: 0.4938 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4379 - accuracy: 0.8095 - val_loss: 0.4855 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.4346 - accuracy: 0.7993 - val_loss: 0.4904 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 275us/step - loss: 0.4353 - accuracy: 0.8027 - val_loss: 0.4762 - val_accuracy: 0.8462\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4322 - accuracy: 0.7925 - val_loss: 0.4853 - val_accuracy: 0.8462\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4322 - accuracy: 0.8095 - val_loss: 0.4856 - val_accuracy: 0.8462\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.4307 - accuracy: 0.8027 - val_loss: 0.4793 - val_accuracy: 0.8462\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4317 - accuracy: 0.7993 - val_loss: 0.4870 - val_accuracy: 0.8462\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4289 - accuracy: 0.8061 - val_loss: 0.4781 - val_accuracy: 0.8462\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4307 - accuracy: 0.8061 - val_loss: 0.4729 - val_accuracy: 0.8462\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4260 - accuracy: 0.7993 - val_loss: 0.4844 - val_accuracy: 0.8462\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4278 - accuracy: 0.7993 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.4243 - accuracy: 0.8027 - val_loss: 0.4793 - val_accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.4255 - accuracy: 0.8061 - val_loss: 0.4740 - val_accuracy: 0.8462\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4238 - accuracy: 0.7993 - val_loss: 0.4780 - val_accuracy: 0.8462\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.4236 - accuracy: 0.8027 - val_loss: 0.4702 - val_accuracy: 0.8462\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4228 - accuracy: 0.8129 - val_loss: 0.4855 - val_accuracy: 0.8462\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 712us/step - loss: 0.4226 - accuracy: 0.8197 - val_loss: 0.4716 - val_accuracy: 0.8462\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4197 - accuracy: 0.8163 - val_loss: 0.4832 - val_accuracy: 0.8462\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.4201 - accuracy: 0.8163 - val_loss: 0.4763 - val_accuracy: 0.8462\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4198 - accuracy: 0.8027 - val_loss: 0.4750 - val_accuracy: 0.8462\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.4183 - accuracy: 0.8197 - val_loss: 0.4847 - val_accuracy: 0.8462\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4171 - accuracy: 0.8163 - val_loss: 0.4693 - val_accuracy: 0.8462\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.4164 - accuracy: 0.8163 - val_loss: 0.4760 - val_accuracy: 0.8462\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4149 - accuracy: 0.8163 - val_loss: 0.4760 - val_accuracy: 0.8462\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4147 - accuracy: 0.8197 - val_loss: 0.4784 - val_accuracy: 0.8462\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4136 - accuracy: 0.8197 - val_loss: 0.4693 - val_accuracy: 0.8462\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4122 - accuracy: 0.8299 - val_loss: 0.4691 - val_accuracy: 0.8462\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4121 - accuracy: 0.8299 - val_loss: 0.4765 - val_accuracy: 0.8462\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4137 - accuracy: 0.8333 - val_loss: 0.4675 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4111 - accuracy: 0.8197 - val_loss: 0.4785 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 181us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3531 - accuracy: 0.3129 - val_loss: 1.2870 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 1.2117 - accuracy: 0.4864 - val_loss: 1.1848 - val_accuracy: 0.4808\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 1.1130 - accuracy: 0.6122 - val_loss: 1.0914 - val_accuracy: 0.5385\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 1.0233 - accuracy: 0.6633 - val_loss: 1.0106 - val_accuracy: 0.6154\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.9527 - accuracy: 0.7075 - val_loss: 0.9274 - val_accuracy: 0.6346\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.8921 - accuracy: 0.7075 - val_loss: 0.8719 - val_accuracy: 0.7308\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.8432 - accuracy: 0.7041 - val_loss: 0.8310 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.8026 - accuracy: 0.7279 - val_loss: 0.7889 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.7680 - accuracy: 0.7279 - val_loss: 0.7588 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.7396 - accuracy: 0.7415 - val_loss: 0.7342 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.7160 - accuracy: 0.7381 - val_loss: 0.7001 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.6948 - accuracy: 0.7449 - val_loss: 0.6855 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.6770 - accuracy: 0.7449 - val_loss: 0.6710 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 603us/step - loss: 0.6625 - accuracy: 0.7517 - val_loss: 0.6588 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.6512 - accuracy: 0.7381 - val_loss: 0.6536 - val_accuracy: 0.7692\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.6389 - accuracy: 0.7619 - val_loss: 0.6292 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.6280 - accuracy: 0.7551 - val_loss: 0.6244 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.6200 - accuracy: 0.7619 - val_loss: 0.6150 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.6133 - accuracy: 0.7619 - val_loss: 0.5983 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.6050 - accuracy: 0.7551 - val_loss: 0.6042 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5981 - accuracy: 0.7517 - val_loss: 0.5915 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 623us/step - loss: 0.5916 - accuracy: 0.7619 - val_loss: 0.5846 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.5899 - accuracy: 0.7619 - val_loss: 0.5880 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5806 - accuracy: 0.7551 - val_loss: 0.5737 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5780 - accuracy: 0.7619 - val_loss: 0.5760 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5739 - accuracy: 0.7619 - val_loss: 0.5600 - val_accuracy: 0.7692\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5671 - accuracy: 0.7619 - val_loss: 0.5752 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 313us/step - loss: 0.5668 - accuracy: 0.7687 - val_loss: 0.5719 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5604 - accuracy: 0.7687 - val_loss: 0.5535 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5559 - accuracy: 0.7721 - val_loss: 0.5613 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5540 - accuracy: 0.7721 - val_loss: 0.5554 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5521 - accuracy: 0.7687 - val_loss: 0.5517 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5458 - accuracy: 0.7721 - val_loss: 0.5450 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.5441 - accuracy: 0.7687 - val_loss: 0.5474 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5409 - accuracy: 0.7721 - val_loss: 0.5441 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5385 - accuracy: 0.7687 - val_loss: 0.5408 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5355 - accuracy: 0.7721 - val_loss: 0.5302 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5331 - accuracy: 0.7721 - val_loss: 0.5375 - val_accuracy: 0.7885\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5322 - accuracy: 0.7687 - val_loss: 0.5344 - val_accuracy: 0.7885\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.5293 - accuracy: 0.7755 - val_loss: 0.5424 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.5303 - accuracy: 0.7653 - val_loss: 0.5310 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5244 - accuracy: 0.7721 - val_loss: 0.5286 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5225 - accuracy: 0.7755 - val_loss: 0.5244 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 653us/step - loss: 0.5230 - accuracy: 0.7755 - val_loss: 0.5264 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 658us/step - loss: 0.5189 - accuracy: 0.7755 - val_loss: 0.5257 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5187 - accuracy: 0.7789 - val_loss: 0.5191 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.5164 - accuracy: 0.7721 - val_loss: 0.5184 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.5138 - accuracy: 0.7721 - val_loss: 0.5213 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.5111 - accuracy: 0.7721 - val_loss: 0.5165 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.5120 - accuracy: 0.7755 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5090 - accuracy: 0.7755 - val_loss: 0.5122 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.5075 - accuracy: 0.7755 - val_loss: 0.5173 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 0.5084 - accuracy: 0.7755 - val_loss: 0.5076 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.5045 - accuracy: 0.7755 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.5031 - accuracy: 0.7721 - val_loss: 0.5073 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.5002 - accuracy: 0.7755 - val_loss: 0.5107 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5022 - accuracy: 0.7789 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 787us/step - loss: 0.5000 - accuracy: 0.7857 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 622us/step - loss: 0.4980 - accuracy: 0.7721 - val_loss: 0.5130 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.4967 - accuracy: 0.7755 - val_loss: 0.5153 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4955 - accuracy: 0.7823 - val_loss: 0.5071 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.4960 - accuracy: 0.7857 - val_loss: 0.5078 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4955 - accuracy: 0.7755 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.4934 - accuracy: 0.7891 - val_loss: 0.5137 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4944 - accuracy: 0.7857 - val_loss: 0.4938 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 834us/step - loss: 0.4911 - accuracy: 0.7721 - val_loss: 0.5076 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.4889 - accuracy: 0.7925 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4893 - accuracy: 0.7789 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.4862 - accuracy: 0.7891 - val_loss: 0.5046 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4855 - accuracy: 0.7959 - val_loss: 0.5021 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4840 - accuracy: 0.7925 - val_loss: 0.4903 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.4828 - accuracy: 0.7959 - val_loss: 0.5005 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.4826 - accuracy: 0.7925 - val_loss: 0.4984 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4802 - accuracy: 0.7925 - val_loss: 0.4916 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.4787 - accuracy: 0.7925 - val_loss: 0.4996 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.4777 - accuracy: 0.7959 - val_loss: 0.4931 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.4768 - accuracy: 0.7891 - val_loss: 0.4984 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.4750 - accuracy: 0.7857 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4749 - accuracy: 0.7993 - val_loss: 0.4975 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4734 - accuracy: 0.7993 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.4738 - accuracy: 0.7993 - val_loss: 0.4960 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 89us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3258 - accuracy: 0.4014 - val_loss: 1.1964 - val_accuracy: 0.4808\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 637us/step - loss: 1.1587 - accuracy: 0.5782 - val_loss: 1.0624 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 613us/step - loss: 1.0594 - accuracy: 0.6361 - val_loss: 0.9730 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.9836 - accuracy: 0.6633 - val_loss: 0.8975 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.9196 - accuracy: 0.6769 - val_loss: 0.8485 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.8659 - accuracy: 0.6973 - val_loss: 0.7950 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.8228 - accuracy: 0.7075 - val_loss: 0.7568 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.7853 - accuracy: 0.7279 - val_loss: 0.7189 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.7543 - accuracy: 0.7415 - val_loss: 0.7003 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.7276 - accuracy: 0.7449 - val_loss: 0.6752 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.7005 - accuracy: 0.7449 - val_loss: 0.6409 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.6817 - accuracy: 0.7517 - val_loss: 0.6292 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.6658 - accuracy: 0.7517 - val_loss: 0.6224 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.6494 - accuracy: 0.7517 - val_loss: 0.6009 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.6383 - accuracy: 0.7585 - val_loss: 0.5904 - val_accuracy: 0.8462\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.6266 - accuracy: 0.7585 - val_loss: 0.5781 - val_accuracy: 0.8462\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.6172 - accuracy: 0.7551 - val_loss: 0.5690 - val_accuracy: 0.8462\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.6091 - accuracy: 0.7619 - val_loss: 0.5691 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.6054 - accuracy: 0.7619 - val_loss: 0.5595 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5924 - accuracy: 0.7687 - val_loss: 0.5528 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5883 - accuracy: 0.7517 - val_loss: 0.5513 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.5823 - accuracy: 0.7551 - val_loss: 0.5382 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.5762 - accuracy: 0.7619 - val_loss: 0.5349 - val_accuracy: 0.8462\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5727 - accuracy: 0.7619 - val_loss: 0.5380 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.5670 - accuracy: 0.7687 - val_loss: 0.5315 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.5631 - accuracy: 0.7687 - val_loss: 0.5261 - val_accuracy: 0.8654\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5587 - accuracy: 0.7653 - val_loss: 0.5254 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.5554 - accuracy: 0.7721 - val_loss: 0.5249 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.5501 - accuracy: 0.7721 - val_loss: 0.5224 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5490 - accuracy: 0.7721 - val_loss: 0.5235 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5467 - accuracy: 0.7687 - val_loss: 0.5117 - val_accuracy: 0.8654\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.5429 - accuracy: 0.7721 - val_loss: 0.5146 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 0.5384 - accuracy: 0.7755 - val_loss: 0.5107 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.5378 - accuracy: 0.7721 - val_loss: 0.5089 - val_accuracy: 0.8654\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5335 - accuracy: 0.7721 - val_loss: 0.5157 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.5323 - accuracy: 0.7721 - val_loss: 0.5021 - val_accuracy: 0.8654\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.5284 - accuracy: 0.7755 - val_loss: 0.5071 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5244 - accuracy: 0.7721 - val_loss: 0.5029 - val_accuracy: 0.8654\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5221 - accuracy: 0.7755 - val_loss: 0.5032 - val_accuracy: 0.8654\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.5202 - accuracy: 0.7789 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.5196 - accuracy: 0.7789 - val_loss: 0.4937 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 696us/step - loss: 0.5211 - accuracy: 0.7721 - val_loss: 0.5138 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5158 - accuracy: 0.7687 - val_loss: 0.4938 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5114 - accuracy: 0.7789 - val_loss: 0.5029 - val_accuracy: 0.8654\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.5112 - accuracy: 0.7789 - val_loss: 0.4940 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5087 - accuracy: 0.7789 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5097 - accuracy: 0.7857 - val_loss: 0.4875 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5044 - accuracy: 0.7823 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.5031 - accuracy: 0.7891 - val_loss: 0.4896 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 675us/step - loss: 0.5014 - accuracy: 0.7857 - val_loss: 0.4881 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 649us/step - loss: 0.5008 - accuracy: 0.7789 - val_loss: 0.4898 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 640us/step - loss: 0.4981 - accuracy: 0.7857 - val_loss: 0.4773 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.4965 - accuracy: 0.7891 - val_loss: 0.4865 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 673us/step - loss: 0.4960 - accuracy: 0.7857 - val_loss: 0.4909 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 705us/step - loss: 0.4929 - accuracy: 0.7823 - val_loss: 0.4816 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 912us/step - loss: 0.4915 - accuracy: 0.7891 - val_loss: 0.4822 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.4902 - accuracy: 0.7857 - val_loss: 0.4882 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 630us/step - loss: 0.4898 - accuracy: 0.7857 - val_loss: 0.4864 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 986us/step - loss: 0.4868 - accuracy: 0.7857 - val_loss: 0.4841 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 698us/step - loss: 0.4860 - accuracy: 0.7891 - val_loss: 0.4798 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4842 - accuracy: 0.7891 - val_loss: 0.4773 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4837 - accuracy: 0.7959 - val_loss: 0.4757 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.4836 - accuracy: 0.7891 - val_loss: 0.4767 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 511us/step - loss: 0.4803 - accuracy: 0.7891 - val_loss: 0.4779 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.4811 - accuracy: 0.7925 - val_loss: 0.4819 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 681us/step - loss: 0.4799 - accuracy: 0.7959 - val_loss: 0.4758 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.4770 - accuracy: 0.7891 - val_loss: 0.4738 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4763 - accuracy: 0.7959 - val_loss: 0.4710 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.4733 - accuracy: 0.7891 - val_loss: 0.4734 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 0.4739 - accuracy: 0.7891 - val_loss: 0.4668 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4750 - accuracy: 0.7959 - val_loss: 0.4723 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.4720 - accuracy: 0.7891 - val_loss: 0.4691 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4695 - accuracy: 0.7891 - val_loss: 0.4704 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 207us/step - loss: 0.4694 - accuracy: 0.7925 - val_loss: 0.4667 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4668 - accuracy: 0.7959 - val_loss: 0.4724 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4325 - accuracy: 0.81 - 0s 321us/step - loss: 0.4679 - accuracy: 0.7993 - val_loss: 0.4699 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.4651 - accuracy: 0.7925 - val_loss: 0.4701 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4634 - accuracy: 0.7891 - val_loss: 0.4681 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4626 - accuracy: 0.7891 - val_loss: 0.4687 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.4612 - accuracy: 0.7959 - val_loss: 0.4649 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.4606 - accuracy: 0.8061 - val_loss: 0.4563 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4597 - accuracy: 0.7959 - val_loss: 0.4646 - val_accuracy: 0.8654\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.4574 - accuracy: 0.8027 - val_loss: 0.4699 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4587 - accuracy: 0.7993 - val_loss: 0.4635 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.4561 - accuracy: 0.7993 - val_loss: 0.4620 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4548 - accuracy: 0.7993 - val_loss: 0.4657 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.4549 - accuracy: 0.7993 - val_loss: 0.4721 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.4507 - accuracy: 0.8061 - val_loss: 0.4587 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.4529 - accuracy: 0.8027 - val_loss: 0.4571 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.4518 - accuracy: 0.8027 - val_loss: 0.4614 - val_accuracy: 0.8654\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.4509 - accuracy: 0.7959 - val_loss: 0.4627 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 117us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.4566 - accuracy: 0.3741 - val_loss: 1.3078 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 1.2506 - accuracy: 0.4762 - val_loss: 1.1996 - val_accuracy: 0.5192\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 1.1384 - accuracy: 0.5714 - val_loss: 1.1191 - val_accuracy: 0.5192\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 1.0567 - accuracy: 0.6327 - val_loss: 1.0439 - val_accuracy: 0.5962\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.9884 - accuracy: 0.6837 - val_loss: 0.9811 - val_accuracy: 0.6538\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.9300 - accuracy: 0.7041 - val_loss: 0.9235 - val_accuracy: 0.6346\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.8798 - accuracy: 0.7109 - val_loss: 0.8679 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.8342 - accuracy: 0.7279 - val_loss: 0.8357 - val_accuracy: 0.7115\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.7951 - accuracy: 0.7279 - val_loss: 0.7931 - val_accuracy: 0.7308\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 887us/step - loss: 0.7626 - accuracy: 0.7381 - val_loss: 0.7620 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.7331 - accuracy: 0.7381 - val_loss: 0.7345 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.7074 - accuracy: 0.7483 - val_loss: 0.7158 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.6840 - accuracy: 0.7551 - val_loss: 0.6914 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.6647 - accuracy: 0.7619 - val_loss: 0.6712 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.6494 - accuracy: 0.7551 - val_loss: 0.6550 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6332 - accuracy: 0.7619 - val_loss: 0.6527 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.6214 - accuracy: 0.7551 - val_loss: 0.6349 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.6100 - accuracy: 0.7619 - val_loss: 0.6270 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.6004 - accuracy: 0.7619 - val_loss: 0.6121 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5925 - accuracy: 0.7619 - val_loss: 0.6019 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5842 - accuracy: 0.7755 - val_loss: 0.6033 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 451us/step - loss: 0.5800 - accuracy: 0.7721 - val_loss: 0.5968 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5708 - accuracy: 0.7721 - val_loss: 0.5914 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.5674 - accuracy: 0.7687 - val_loss: 0.5823 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 880us/step - loss: 0.5607 - accuracy: 0.7721 - val_loss: 0.5780 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 891us/step - loss: 0.5561 - accuracy: 0.7755 - val_loss: 0.5788 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.5515 - accuracy: 0.7755 - val_loss: 0.5792 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5483 - accuracy: 0.7789 - val_loss: 0.5692 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.5433 - accuracy: 0.7755 - val_loss: 0.5698 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5405 - accuracy: 0.7789 - val_loss: 0.5627 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5381 - accuracy: 0.7721 - val_loss: 0.5638 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5355 - accuracy: 0.7789 - val_loss: 0.5539 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5342 - accuracy: 0.7823 - val_loss: 0.5572 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 711us/step - loss: 0.5294 - accuracy: 0.7789 - val_loss: 0.5548 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5263 - accuracy: 0.7789 - val_loss: 0.5528 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5229 - accuracy: 0.7823 - val_loss: 0.5502 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.5230 - accuracy: 0.7755 - val_loss: 0.5518 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5174 - accuracy: 0.7823 - val_loss: 0.5450 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5147 - accuracy: 0.7857 - val_loss: 0.5442 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5140 - accuracy: 0.7789 - val_loss: 0.5450 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 865us/step - loss: 0.5132 - accuracy: 0.7857 - val_loss: 0.5423 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5097 - accuracy: 0.7857 - val_loss: 0.5415 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 705us/step - loss: 0.5088 - accuracy: 0.7891 - val_loss: 0.5403 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5050 - accuracy: 0.7959 - val_loss: 0.5460 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5052 - accuracy: 0.7857 - val_loss: 0.5411 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.5022 - accuracy: 0.7891 - val_loss: 0.5416 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.5006 - accuracy: 0.7891 - val_loss: 0.5375 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 633us/step - loss: 0.4998 - accuracy: 0.7925 - val_loss: 0.5386 - val_accuracy: 0.8654\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 878us/step - loss: 0.5008 - accuracy: 0.7925 - val_loss: 0.5342 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 646us/step - loss: 0.4951 - accuracy: 0.7891 - val_loss: 0.5393 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4923 - accuracy: 0.7993 - val_loss: 0.5352 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.4908 - accuracy: 0.7925 - val_loss: 0.5336 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4894 - accuracy: 0.7891 - val_loss: 0.5315 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4882 - accuracy: 0.7993 - val_loss: 0.5307 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4869 - accuracy: 0.8027 - val_loss: 0.5242 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.4851 - accuracy: 0.8061 - val_loss: 0.5339 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.4851 - accuracy: 0.7993 - val_loss: 0.5344 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 0.4834 - accuracy: 0.7993 - val_loss: 0.5310 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.4818 - accuracy: 0.8095 - val_loss: 0.5327 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.4791 - accuracy: 0.8129 - val_loss: 0.5288 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4777 - accuracy: 0.8163 - val_loss: 0.5241 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4785 - accuracy: 0.8027 - val_loss: 0.5358 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.4753 - accuracy: 0.8129 - val_loss: 0.5296 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4747 - accuracy: 0.8197 - val_loss: 0.5314 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.4739 - accuracy: 0.8095 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.4717 - accuracy: 0.8095 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.4726 - accuracy: 0.8061 - val_loss: 0.5283 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4676 - accuracy: 0.8095 - val_loss: 0.5205 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4694 - accuracy: 0.8027 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4677 - accuracy: 0.8163 - val_loss: 0.5186 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4656 - accuracy: 0.8095 - val_loss: 0.5213 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.4646 - accuracy: 0.8197 - val_loss: 0.5228 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4628 - accuracy: 0.8197 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.4624 - accuracy: 0.8197 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.4613 - accuracy: 0.8197 - val_loss: 0.5152 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.4597 - accuracy: 0.8231 - val_loss: 0.5224 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4598 - accuracy: 0.8231 - val_loss: 0.5201 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 394us/step - loss: 0.4576 - accuracy: 0.8197 - val_loss: 0.5185 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4571 - accuracy: 0.8231 - val_loss: 0.5171 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4561 - accuracy: 0.8197 - val_loss: 0.5119 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.4527 - accuracy: 0.8197 - val_loss: 0.5188 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4521 - accuracy: 0.8231 - val_loss: 0.5198 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4510 - accuracy: 0.8231 - val_loss: 0.5128 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4496 - accuracy: 0.8231 - val_loss: 0.5103 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4486 - accuracy: 0.8231 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.4487 - accuracy: 0.8231 - val_loss: 0.5142 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.4469 - accuracy: 0.8299 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4486 - accuracy: 0.8265 - val_loss: 0.5185 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.4466 - accuracy: 0.8197 - val_loss: 0.5046 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.4443 - accuracy: 0.8299 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4437 - accuracy: 0.8299 - val_loss: 0.5198 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.4451 - accuracy: 0.8265 - val_loss: 0.5087 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 608us/step - loss: 0.4426 - accuracy: 0.8231 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4399 - accuracy: 0.8265 - val_loss: 0.5135 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.4389 - accuracy: 0.8333 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.4384 - accuracy: 0.8231 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.4384 - accuracy: 0.8333 - val_loss: 0.5139 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 753us/step - loss: 0.4358 - accuracy: 0.8299 - val_loss: 0.5050 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4357 - accuracy: 0.8265 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4354 - accuracy: 0.8333 - val_loss: 0.5024 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4362 - accuracy: 0.8231 - val_loss: 0.5131 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4333 - accuracy: 0.8367 - val_loss: 0.4996 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4326 - accuracy: 0.8265 - val_loss: 0.5133 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4332 - accuracy: 0.8299 - val_loss: 0.5012 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.4300 - accuracy: 0.8367 - val_loss: 0.5025 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4284 - accuracy: 0.8367 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.4282 - accuracy: 0.8333 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4272 - accuracy: 0.8231 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4976 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4276 - accuracy: 0.8333 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4245 - accuracy: 0.8333 - val_loss: 0.4986 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.4232 - accuracy: 0.8333 - val_loss: 0.5089 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.5066 - val_accuracy: 0.8269\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.4213 - accuracy: 0.8333 - val_loss: 0.5035 - val_accuracy: 0.8269\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.4241 - accuracy: 0.8231 - val_loss: 0.4969 - val_accuracy: 0.8654\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.4236 - accuracy: 0.8265 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4207 - accuracy: 0.8333 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.4189 - accuracy: 0.8299 - val_loss: 0.5041 - val_accuracy: 0.8269\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4170 - accuracy: 0.8367 - val_loss: 0.4993 - val_accuracy: 0.8269\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.4147 - accuracy: 0.8333 - val_loss: 0.5031 - val_accuracy: 0.8269\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.4153 - accuracy: 0.8367 - val_loss: 0.4964 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4149 - accuracy: 0.8299 - val_loss: 0.4960 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4166 - accuracy: 0.8401 - val_loss: 0.5019 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.4130 - accuracy: 0.8299 - val_loss: 0.4989 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4120 - accuracy: 0.8299 - val_loss: 0.5007 - val_accuracy: 0.8269\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4105 - accuracy: 0.8367 - val_loss: 0.4992 - val_accuracy: 0.8269\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.4099 - accuracy: 0.8265 - val_loss: 0.5019 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 174us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4834 - accuracy: 0.2517 - val_loss: 1.4207 - val_accuracy: 0.2885\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 633us/step - loss: 1.3209 - accuracy: 0.3912 - val_loss: 1.2444 - val_accuracy: 0.3846\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 1.1998 - accuracy: 0.5204 - val_loss: 1.1275 - val_accuracy: 0.6923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 1.1056 - accuracy: 0.6497 - val_loss: 1.0211 - val_accuracy: 0.8077\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 1.0151 - accuracy: 0.7211 - val_loss: 0.9302 - val_accuracy: 0.8077\n",
      "Epoch 6/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 299us/step - loss: 0.9375 - accuracy: 0.7347 - val_loss: 0.8447 - val_accuracy: 0.8654\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.8722 - accuracy: 0.7415 - val_loss: 0.7869 - val_accuracy: 0.8269\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.8201 - accuracy: 0.7483 - val_loss: 0.7351 - val_accuracy: 0.8269\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.7763 - accuracy: 0.7347 - val_loss: 0.7043 - val_accuracy: 0.8269\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.7436 - accuracy: 0.7449 - val_loss: 0.6732 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.7156 - accuracy: 0.7517 - val_loss: 0.6525 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.6938 - accuracy: 0.7483 - val_loss: 0.6316 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6738 - accuracy: 0.7551 - val_loss: 0.6144 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.6600 - accuracy: 0.7585 - val_loss: 0.6018 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6452 - accuracy: 0.7585 - val_loss: 0.5938 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.6329 - accuracy: 0.7585 - val_loss: 0.5890 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6255 - accuracy: 0.7551 - val_loss: 0.5802 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.6164 - accuracy: 0.7619 - val_loss: 0.5652 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.6080 - accuracy: 0.7653 - val_loss: 0.5639 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5987 - accuracy: 0.7721 - val_loss: 0.5619 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5915 - accuracy: 0.7653 - val_loss: 0.5511 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5858 - accuracy: 0.7619 - val_loss: 0.5415 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5774 - accuracy: 0.7687 - val_loss: 0.5382 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.5736 - accuracy: 0.7687 - val_loss: 0.5346 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5654 - accuracy: 0.7789 - val_loss: 0.5407 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5627 - accuracy: 0.7755 - val_loss: 0.5358 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5590 - accuracy: 0.7721 - val_loss: 0.5322 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5515 - accuracy: 0.7891 - val_loss: 0.5343 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5476 - accuracy: 0.7789 - val_loss: 0.5267 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5436 - accuracy: 0.7857 - val_loss: 0.5264 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5446 - accuracy: 0.7687 - val_loss: 0.5208 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.5376 - accuracy: 0.7823 - val_loss: 0.5222 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5338 - accuracy: 0.7857 - val_loss: 0.5236 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.5311 - accuracy: 0.7823 - val_loss: 0.5191 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5267 - accuracy: 0.7789 - val_loss: 0.5206 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5280 - accuracy: 0.7857 - val_loss: 0.5234 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.5207 - accuracy: 0.7823 - val_loss: 0.5106 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5188 - accuracy: 0.7823 - val_loss: 0.5105 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5156 - accuracy: 0.7823 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5147 - accuracy: 0.7823 - val_loss: 0.5198 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5119 - accuracy: 0.7789 - val_loss: 0.5093 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5100 - accuracy: 0.7823 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5061 - accuracy: 0.7823 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5048 - accuracy: 0.7891 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5016 - accuracy: 0.7891 - val_loss: 0.5033 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.4999 - accuracy: 0.7891 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4984 - accuracy: 0.7857 - val_loss: 0.5101 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4969 - accuracy: 0.7891 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.4943 - accuracy: 0.7925 - val_loss: 0.5035 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4922 - accuracy: 0.7925 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4916 - accuracy: 0.7925 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4901 - accuracy: 0.7891 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4880 - accuracy: 0.7993 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.4874 - accuracy: 0.7993 - val_loss: 0.4968 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4837 - accuracy: 0.7993 - val_loss: 0.5073 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4861 - accuracy: 0.7925 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.4832 - accuracy: 0.7959 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4804 - accuracy: 0.7925 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4785 - accuracy: 0.8061 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.4762 - accuracy: 0.7993 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4751 - accuracy: 0.8061 - val_loss: 0.4978 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 274us/step - loss: 0.4753 - accuracy: 0.7993 - val_loss: 0.4984 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4734 - accuracy: 0.7891 - val_loss: 0.4994 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4730 - accuracy: 0.8061 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4708 - accuracy: 0.7993 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4694 - accuracy: 0.7959 - val_loss: 0.4923 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 98us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4591 - accuracy: 0.2653 - val_loss: 1.3597 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 1.2531 - accuracy: 0.4014 - val_loss: 1.2145 - val_accuracy: 0.4038\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 1.1398 - accuracy: 0.5918 - val_loss: 1.1035 - val_accuracy: 0.5962\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 1.0449 - accuracy: 0.6531 - val_loss: 1.0217 - val_accuracy: 0.6346\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.9679 - accuracy: 0.6531 - val_loss: 0.9587 - val_accuracy: 0.6731\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.9032 - accuracy: 0.6769 - val_loss: 0.8925 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.8506 - accuracy: 0.6939 - val_loss: 0.8445 - val_accuracy: 0.7115\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.8099 - accuracy: 0.6905 - val_loss: 0.8124 - val_accuracy: 0.7115\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.7710 - accuracy: 0.7007 - val_loss: 0.7775 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.7414 - accuracy: 0.7075 - val_loss: 0.7474 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.7156 - accuracy: 0.7211 - val_loss: 0.7305 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.6967 - accuracy: 0.7109 - val_loss: 0.7045 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.6783 - accuracy: 0.7279 - val_loss: 0.6902 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.6609 - accuracy: 0.7245 - val_loss: 0.6752 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.6479 - accuracy: 0.7211 - val_loss: 0.6547 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.6359 - accuracy: 0.7211 - val_loss: 0.6566 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.6270 - accuracy: 0.7245 - val_loss: 0.6433 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.6170 - accuracy: 0.7313 - val_loss: 0.6235 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.6078 - accuracy: 0.7279 - val_loss: 0.6198 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.6013 - accuracy: 0.7279 - val_loss: 0.6132 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5942 - accuracy: 0.7381 - val_loss: 0.6021 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5874 - accuracy: 0.7415 - val_loss: 0.5992 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.5807 - accuracy: 0.7415 - val_loss: 0.5962 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5758 - accuracy: 0.7415 - val_loss: 0.5844 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5711 - accuracy: 0.7449 - val_loss: 0.5812 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5666 - accuracy: 0.7449 - val_loss: 0.5664 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5639 - accuracy: 0.7517 - val_loss: 0.5673 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5581 - accuracy: 0.7551 - val_loss: 0.5666 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.77 - 0s 336us/step - loss: 0.5548 - accuracy: 0.7483 - val_loss: 0.5676 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5507 - accuracy: 0.7585 - val_loss: 0.5602 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 700us/step - loss: 0.5490 - accuracy: 0.7619 - val_loss: 0.5622 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5447 - accuracy: 0.7619 - val_loss: 0.5420 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5413 - accuracy: 0.7619 - val_loss: 0.5445 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5369 - accuracy: 0.7585 - val_loss: 0.5542 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.5364 - accuracy: 0.7653 - val_loss: 0.5459 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.5337 - accuracy: 0.7687 - val_loss: 0.5469 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5284 - accuracy: 0.7755 - val_loss: 0.5341 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5268 - accuracy: 0.7653 - val_loss: 0.5315 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5243 - accuracy: 0.7755 - val_loss: 0.5377 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5233 - accuracy: 0.7687 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 0.5210 - accuracy: 0.7789 - val_loss: 0.5327 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5169 - accuracy: 0.7789 - val_loss: 0.5220 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5156 - accuracy: 0.7823 - val_loss: 0.5251 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5175 - accuracy: 0.7789 - val_loss: 0.5183 - val_accuracy: 0.8654\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5120 - accuracy: 0.7721 - val_loss: 0.5318 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.5113 - accuracy: 0.7789 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5068 - accuracy: 0.7721 - val_loss: 0.5244 - val_accuracy: 0.8654\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5073 - accuracy: 0.7755 - val_loss: 0.5169 - val_accuracy: 0.8654\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5042 - accuracy: 0.7755 - val_loss: 0.5232 - val_accuracy: 0.8654\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5035 - accuracy: 0.7823 - val_loss: 0.5180 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 361us/step - loss: 0.5024 - accuracy: 0.7755 - val_loss: 0.5170 - val_accuracy: 0.8654\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.4989 - accuracy: 0.7789 - val_loss: 0.5105 - val_accuracy: 0.8654\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4980 - accuracy: 0.7857 - val_loss: 0.5158 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4982 - accuracy: 0.7925 - val_loss: 0.5057 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.4984 - accuracy: 0.7891 - val_loss: 0.5073 - val_accuracy: 0.8654\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4937 - accuracy: 0.7993 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4922 - accuracy: 0.7959 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4905 - accuracy: 0.7959 - val_loss: 0.5099 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4889 - accuracy: 0.7993 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.4875 - accuracy: 0.7993 - val_loss: 0.5038 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4858 - accuracy: 0.7959 - val_loss: 0.5056 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4852 - accuracy: 0.8027 - val_loss: 0.5079 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4850 - accuracy: 0.8027 - val_loss: 0.4945 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4825 - accuracy: 0.8027 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.4812 - accuracy: 0.8061 - val_loss: 0.4959 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4814 - accuracy: 0.7993 - val_loss: 0.4969 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4788 - accuracy: 0.8027 - val_loss: 0.5033 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4803 - accuracy: 0.7993 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 625us/step - loss: 0.4788 - accuracy: 0.7925 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 730us/step - loss: 0.4756 - accuracy: 0.8027 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4750 - accuracy: 0.7993 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4740 - accuracy: 0.7925 - val_loss: 0.5095 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.4721 - accuracy: 0.8027 - val_loss: 0.4981 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 147us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.7964 - accuracy: 0.3061 - val_loss: 1.6809 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 1.4571 - accuracy: 0.4150 - val_loss: 1.4134 - val_accuracy: 0.4038\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 1.2786 - accuracy: 0.5102 - val_loss: 1.2351 - val_accuracy: 0.4808\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 1.1586 - accuracy: 0.5952 - val_loss: 1.1080 - val_accuracy: 0.5577\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 1.0572 - accuracy: 0.6565 - val_loss: 1.0109 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.9745 - accuracy: 0.7109 - val_loss: 0.9275 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.9089 - accuracy: 0.7279 - val_loss: 0.8584 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.8550 - accuracy: 0.7347 - val_loss: 0.8233 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.8121 - accuracy: 0.7517 - val_loss: 0.7781 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.7764 - accuracy: 0.7517 - val_loss: 0.7469 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.7460 - accuracy: 0.7585 - val_loss: 0.7187 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.7213 - accuracy: 0.7551 - val_loss: 0.6994 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6991 - accuracy: 0.7585 - val_loss: 0.6856 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.6819 - accuracy: 0.7551 - val_loss: 0.6708 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.6660 - accuracy: 0.7585 - val_loss: 0.6543 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6530 - accuracy: 0.7551 - val_loss: 0.6503 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6411 - accuracy: 0.7585 - val_loss: 0.6410 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.6290 - accuracy: 0.7653 - val_loss: 0.6271 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.6206 - accuracy: 0.7653 - val_loss: 0.6205 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.6111 - accuracy: 0.7653 - val_loss: 0.6167 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6034 - accuracy: 0.7619 - val_loss: 0.6102 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5959 - accuracy: 0.7619 - val_loss: 0.6046 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5907 - accuracy: 0.7585 - val_loss: 0.5989 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5827 - accuracy: 0.7653 - val_loss: 0.5950 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5778 - accuracy: 0.7619 - val_loss: 0.5905 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.5740 - accuracy: 0.7755 - val_loss: 0.5951 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5701 - accuracy: 0.7653 - val_loss: 0.5789 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5665 - accuracy: 0.7687 - val_loss: 0.5836 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 600us/step - loss: 0.5595 - accuracy: 0.7755 - val_loss: 0.5780 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 722us/step - loss: 0.5580 - accuracy: 0.7619 - val_loss: 0.5793 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.5531 - accuracy: 0.7755 - val_loss: 0.5794 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5496 - accuracy: 0.7721 - val_loss: 0.5661 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 631us/step - loss: 0.5502 - accuracy: 0.7653 - val_loss: 0.5843 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 715us/step - loss: 0.5444 - accuracy: 0.7721 - val_loss: 0.5624 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.5401 - accuracy: 0.7789 - val_loss: 0.5606 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.5369 - accuracy: 0.7687 - val_loss: 0.5695 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.5371 - accuracy: 0.7755 - val_loss: 0.5602 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5315 - accuracy: 0.7789 - val_loss: 0.5660 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5308 - accuracy: 0.7755 - val_loss: 0.5599 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5275 - accuracy: 0.7653 - val_loss: 0.5554 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5260 - accuracy: 0.7721 - val_loss: 0.5551 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5223 - accuracy: 0.7721 - val_loss: 0.5607 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5202 - accuracy: 0.7721 - val_loss: 0.5512 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5176 - accuracy: 0.7687 - val_loss: 0.5511 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5167 - accuracy: 0.7721 - val_loss: 0.5555 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5142 - accuracy: 0.7687 - val_loss: 0.5512 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5118 - accuracy: 0.7653 - val_loss: 0.5495 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5104 - accuracy: 0.7687 - val_loss: 0.5407 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5097 - accuracy: 0.7687 - val_loss: 0.5514 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.5065 - accuracy: 0.7721 - val_loss: 0.5405 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5054 - accuracy: 0.7687 - val_loss: 0.5415 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.5060 - accuracy: 0.7755 - val_loss: 0.5499 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5015 - accuracy: 0.7721 - val_loss: 0.5417 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5001 - accuracy: 0.7755 - val_loss: 0.5422 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5013 - accuracy: 0.7721 - val_loss: 0.5436 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4980 - accuracy: 0.7755 - val_loss: 0.5370 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4956 - accuracy: 0.7755 - val_loss: 0.5337 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.4941 - accuracy: 0.7687 - val_loss: 0.5426 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.4954 - accuracy: 0.7653 - val_loss: 0.5397 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.4937 - accuracy: 0.7755 - val_loss: 0.5390 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 0.4898 - accuracy: 0.7721 - val_loss: 0.5367 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.4911 - accuracy: 0.7721 - val_loss: 0.5343 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 627us/step - loss: 0.4863 - accuracy: 0.7721 - val_loss: 0.5335 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.4871 - accuracy: 0.7823 - val_loss: 0.5325 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4856 - accuracy: 0.7721 - val_loss: 0.5379 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 713us/step - loss: 0.4823 - accuracy: 0.7687 - val_loss: 0.5327 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.4822 - accuracy: 0.7857 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.4802 - accuracy: 0.7755 - val_loss: 0.5398 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4803 - accuracy: 0.7755 - val_loss: 0.5324 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4784 - accuracy: 0.7789 - val_loss: 0.5355 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4807 - accuracy: 0.7857 - val_loss: 0.5265 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4749 - accuracy: 0.7925 - val_loss: 0.5370 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4734 - accuracy: 0.7755 - val_loss: 0.5382 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.78 - 0s 301us/step - loss: 0.4743 - accuracy: 0.7891 - val_loss: 0.5253 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4726 - accuracy: 0.7959 - val_loss: 0.5348 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.4703 - accuracy: 0.7823 - val_loss: 0.5329 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.4687 - accuracy: 0.7857 - val_loss: 0.5339 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 658us/step - loss: 0.4674 - accuracy: 0.7857 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.4654 - accuracy: 0.7857 - val_loss: 0.5271 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.4652 - accuracy: 0.7959 - val_loss: 0.5277 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4630 - accuracy: 0.7959 - val_loss: 0.5227 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.4629 - accuracy: 0.7993 - val_loss: 0.5339 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.4642 - accuracy: 0.7925 - val_loss: 0.5217 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.4603 - accuracy: 0.8027 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 167us/step - loss: 0.4580 - accuracy: 0.8061 - val_loss: 0.5258 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4577 - accuracy: 0.8095 - val_loss: 0.5248 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4573 - accuracy: 0.8061 - val_loss: 0.5299 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.4585 - accuracy: 0.7993 - val_loss: 0.5360 - val_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 307us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3243 - accuracy: 0.4558 - val_loss: 1.1253 - val_accuracy: 0.6154\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 1.1356 - accuracy: 0.5850 - val_loss: 1.0129 - val_accuracy: 0.7115\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 1.0262 - accuracy: 0.6905 - val_loss: 0.9295 - val_accuracy: 0.7692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.9479 - accuracy: 0.7075 - val_loss: 0.8611 - val_accuracy: 0.7885\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.8794 - accuracy: 0.7347 - val_loss: 0.8093 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.8268 - accuracy: 0.7449 - val_loss: 0.7628 - val_accuracy: 0.8077\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.7849 - accuracy: 0.7415 - val_loss: 0.7262 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.7506 - accuracy: 0.7517 - val_loss: 0.6959 - val_accuracy: 0.8077\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.7212 - accuracy: 0.7415 - val_loss: 0.6817 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.7004 - accuracy: 0.7517 - val_loss: 0.6554 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.6807 - accuracy: 0.7483 - val_loss: 0.6452 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.6620 - accuracy: 0.7381 - val_loss: 0.6198 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.6445 - accuracy: 0.7449 - val_loss: 0.6103 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.6313 - accuracy: 0.7517 - val_loss: 0.6004 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.6209 - accuracy: 0.7517 - val_loss: 0.5894 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.6100 - accuracy: 0.7551 - val_loss: 0.5940 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.6000 - accuracy: 0.7585 - val_loss: 0.5648 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.5921 - accuracy: 0.7517 - val_loss: 0.5706 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5855 - accuracy: 0.7619 - val_loss: 0.5682 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5768 - accuracy: 0.7619 - val_loss: 0.5495 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.5728 - accuracy: 0.7687 - val_loss: 0.5515 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5676 - accuracy: 0.7653 - val_loss: 0.5426 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.5636 - accuracy: 0.7653 - val_loss: 0.5453 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5571 - accuracy: 0.7551 - val_loss: 0.5388 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5537 - accuracy: 0.7619 - val_loss: 0.5354 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.5484 - accuracy: 0.7585 - val_loss: 0.5408 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.5448 - accuracy: 0.7687 - val_loss: 0.5383 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.5412 - accuracy: 0.7687 - val_loss: 0.5360 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5399 - accuracy: 0.7687 - val_loss: 0.5321 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5381 - accuracy: 0.7687 - val_loss: 0.5320 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5354 - accuracy: 0.7585 - val_loss: 0.5267 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5319 - accuracy: 0.7653 - val_loss: 0.5290 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.5257 - accuracy: 0.7687 - val_loss: 0.5181 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.5253 - accuracy: 0.7653 - val_loss: 0.5153 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5217 - accuracy: 0.7721 - val_loss: 0.5212 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5218 - accuracy: 0.7619 - val_loss: 0.5241 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5184 - accuracy: 0.7721 - val_loss: 0.5091 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5166 - accuracy: 0.7755 - val_loss: 0.5110 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.5133 - accuracy: 0.7721 - val_loss: 0.5109 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.5111 - accuracy: 0.7755 - val_loss: 0.5124 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 687us/step - loss: 0.5093 - accuracy: 0.7823 - val_loss: 0.5118 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.5062 - accuracy: 0.7789 - val_loss: 0.5172 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5074 - accuracy: 0.7687 - val_loss: 0.5100 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.5046 - accuracy: 0.7823 - val_loss: 0.5164 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.78 - 0s 509us/step - loss: 0.5022 - accuracy: 0.7721 - val_loss: 0.5115 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.5016 - accuracy: 0.7755 - val_loss: 0.5016 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4990 - accuracy: 0.7823 - val_loss: 0.5068 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 796us/step - loss: 0.4962 - accuracy: 0.7857 - val_loss: 0.5072 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 551us/step - loss: 0.4964 - accuracy: 0.7789 - val_loss: 0.5052 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.4934 - accuracy: 0.7959 - val_loss: 0.5099 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4944 - accuracy: 0.7823 - val_loss: 0.5007 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4898 - accuracy: 0.7891 - val_loss: 0.5059 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4886 - accuracy: 0.7891 - val_loss: 0.5021 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.4884 - accuracy: 0.7891 - val_loss: 0.5031 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4881 - accuracy: 0.7857 - val_loss: 0.4949 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 514us/step - loss: 0.4879 - accuracy: 0.7857 - val_loss: 0.4984 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.4852 - accuracy: 0.7857 - val_loss: 0.5051 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.4821 - accuracy: 0.7959 - val_loss: 0.5107 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.4822 - accuracy: 0.7993 - val_loss: 0.4968 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4810 - accuracy: 0.7959 - val_loss: 0.5003 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4776 - accuracy: 0.7959 - val_loss: 0.4926 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4756 - accuracy: 0.8061 - val_loss: 0.4966 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4756 - accuracy: 0.7925 - val_loss: 0.5009 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.4751 - accuracy: 0.8095 - val_loss: 0.4981 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4715 - accuracy: 0.8095 - val_loss: 0.5003 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4693 - accuracy: 0.7959 - val_loss: 0.4945 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4709 - accuracy: 0.7891 - val_loss: 0.5097 - val_accuracy: 0.8077\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4693 - accuracy: 0.7959 - val_loss: 0.4853 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4678 - accuracy: 0.8061 - val_loss: 0.4934 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4659 - accuracy: 0.7993 - val_loss: 0.4950 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 712us/step - loss: 0.4660 - accuracy: 0.8061 - val_loss: 0.4907 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4643 - accuracy: 0.8061 - val_loss: 0.4971 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4636 - accuracy: 0.7993 - val_loss: 0.4939 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4624 - accuracy: 0.7993 - val_loss: 0.4969 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4612 - accuracy: 0.8061 - val_loss: 0.4859 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4614 - accuracy: 0.8061 - val_loss: 0.4985 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.4600 - accuracy: 0.8163 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4581 - accuracy: 0.8129 - val_loss: 0.4904 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 144us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5680 - accuracy: 0.2585 - val_loss: 1.4053 - val_accuracy: 0.2500\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 1.3157 - accuracy: 0.3197 - val_loss: 1.2120 - val_accuracy: 0.4231\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 1.1905 - accuracy: 0.5136 - val_loss: 1.1091 - val_accuracy: 0.5385\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 760us/step - loss: 1.0973 - accuracy: 0.6088 - val_loss: 1.0190 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 1.0165 - accuracy: 0.6633 - val_loss: 0.9487 - val_accuracy: 0.6923\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.9518 - accuracy: 0.6871 - val_loss: 0.8856 - val_accuracy: 0.7308\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.8992 - accuracy: 0.7211 - val_loss: 0.8365 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.8512 - accuracy: 0.7211 - val_loss: 0.7959 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.8123 - accuracy: 0.7245 - val_loss: 0.7555 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.7751 - accuracy: 0.7381 - val_loss: 0.7267 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.7448 - accuracy: 0.7313 - val_loss: 0.7072 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.7213 - accuracy: 0.7313 - val_loss: 0.6769 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.6968 - accuracy: 0.7313 - val_loss: 0.6649 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.6821 - accuracy: 0.7381 - val_loss: 0.6496 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.6642 - accuracy: 0.7381 - val_loss: 0.6303 - val_accuracy: 0.7692\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.6509 - accuracy: 0.7381 - val_loss: 0.6227 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.6398 - accuracy: 0.7483 - val_loss: 0.6053 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.6305 - accuracy: 0.7449 - val_loss: 0.5936 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.6205 - accuracy: 0.7449 - val_loss: 0.5952 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.6125 - accuracy: 0.7449 - val_loss: 0.5782 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.6039 - accuracy: 0.7551 - val_loss: 0.5804 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 258us/step - loss: 0.5977 - accuracy: 0.7585 - val_loss: 0.5646 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5906 - accuracy: 0.7517 - val_loss: 0.5666 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.5832 - accuracy: 0.7551 - val_loss: 0.5678 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.5787 - accuracy: 0.7517 - val_loss: 0.5521 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.5735 - accuracy: 0.7585 - val_loss: 0.5485 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5677 - accuracy: 0.7619 - val_loss: 0.5514 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 469us/step - loss: 0.5662 - accuracy: 0.7585 - val_loss: 0.5485 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5587 - accuracy: 0.7551 - val_loss: 0.5357 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5553 - accuracy: 0.7619 - val_loss: 0.5379 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5512 - accuracy: 0.7585 - val_loss: 0.5388 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5477 - accuracy: 0.7619 - val_loss: 0.5297 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 455us/step - loss: 0.5460 - accuracy: 0.7483 - val_loss: 0.5268 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.5410 - accuracy: 0.7619 - val_loss: 0.5235 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.5394 - accuracy: 0.7619 - val_loss: 0.5202 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.5352 - accuracy: 0.7687 - val_loss: 0.5167 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5316 - accuracy: 0.7687 - val_loss: 0.5112 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5317 - accuracy: 0.7755 - val_loss: 0.5129 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5254 - accuracy: 0.7721 - val_loss: 0.5133 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5236 - accuracy: 0.7619 - val_loss: 0.5030 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.5214 - accuracy: 0.7755 - val_loss: 0.5063 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 876us/step - loss: 0.5222 - accuracy: 0.7619 - val_loss: 0.5025 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5148 - accuracy: 0.7721 - val_loss: 0.5083 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5178 - accuracy: 0.7721 - val_loss: 0.5085 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5143 - accuracy: 0.7619 - val_loss: 0.5000 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.5108 - accuracy: 0.7619 - val_loss: 0.5028 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5112 - accuracy: 0.7687 - val_loss: 0.5019 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5077 - accuracy: 0.7755 - val_loss: 0.4912 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 243us/step - loss: 0.5054 - accuracy: 0.7755 - val_loss: 0.5018 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5033 - accuracy: 0.7789 - val_loss: 0.4884 - val_accuracy: 0.8654\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4994 - accuracy: 0.7823 - val_loss: 0.4997 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4977 - accuracy: 0.7823 - val_loss: 0.4900 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.4970 - accuracy: 0.7823 - val_loss: 0.4979 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.4934 - accuracy: 0.7823 - val_loss: 0.4865 - val_accuracy: 0.8654\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.4940 - accuracy: 0.7755 - val_loss: 0.4952 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.4925 - accuracy: 0.7891 - val_loss: 0.4859 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 718us/step - loss: 0.4892 - accuracy: 0.7789 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4872 - accuracy: 0.7925 - val_loss: 0.4901 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.4878 - accuracy: 0.8027 - val_loss: 0.4827 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4875 - accuracy: 0.7789 - val_loss: 0.4909 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4838 - accuracy: 0.7721 - val_loss: 0.4932 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4822 - accuracy: 0.7857 - val_loss: 0.4837 - val_accuracy: 0.8654\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4826 - accuracy: 0.7721 - val_loss: 0.4864 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4809 - accuracy: 0.8027 - val_loss: 0.4816 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4779 - accuracy: 0.8061 - val_loss: 0.4830 - val_accuracy: 0.8654\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.4756 - accuracy: 0.7959 - val_loss: 0.4793 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.4769 - accuracy: 0.7993 - val_loss: 0.4892 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.4762 - accuracy: 0.7959 - val_loss: 0.4761 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4723 - accuracy: 0.7959 - val_loss: 0.4852 - val_accuracy: 0.8654\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4717 - accuracy: 0.7925 - val_loss: 0.4905 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.4701 - accuracy: 0.8027 - val_loss: 0.4819 - val_accuracy: 0.8654\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.4691 - accuracy: 0.8027 - val_loss: 0.4773 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.4689 - accuracy: 0.8061 - val_loss: 0.4842 - val_accuracy: 0.8654\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4673 - accuracy: 0.8027 - val_loss: 0.4800 - val_accuracy: 0.8654\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.4658 - accuracy: 0.8129 - val_loss: 0.4798 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4675 - accuracy: 0.8027 - val_loss: 0.4837 - val_accuracy: 0.8654\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4654 - accuracy: 0.8061 - val_loss: 0.4771 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4614 - accuracy: 0.8129 - val_loss: 0.4756 - val_accuracy: 0.8654\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.4603 - accuracy: 0.8027 - val_loss: 0.4861 - val_accuracy: 0.8654\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4584 - accuracy: 0.8027 - val_loss: 0.4732 - val_accuracy: 0.8654\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4586 - accuracy: 0.8095 - val_loss: 0.4724 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4587 - accuracy: 0.8129 - val_loss: 0.4716 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4555 - accuracy: 0.8265 - val_loss: 0.4737 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4563 - accuracy: 0.8095 - val_loss: 0.4817 - val_accuracy: 0.8654\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4544 - accuracy: 0.8061 - val_loss: 0.4686 - val_accuracy: 0.8654\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4547 - accuracy: 0.8095 - val_loss: 0.4759 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4517 - accuracy: 0.8095 - val_loss: 0.4768 - val_accuracy: 0.8654\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.4505 - accuracy: 0.8197 - val_loss: 0.4713 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 465us/step - loss: 0.4525 - accuracy: 0.8231 - val_loss: 0.4719 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4491 - accuracy: 0.8265 - val_loss: 0.4758 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.4486 - accuracy: 0.8265 - val_loss: 0.4721 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4470 - accuracy: 0.8163 - val_loss: 0.4707 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4455 - accuracy: 0.8299 - val_loss: 0.4754 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.4464 - accuracy: 0.8163 - val_loss: 0.4704 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4451 - accuracy: 0.8163 - val_loss: 0.4785 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 138us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 0s 2ms/step - loss: 1.2514 - accuracy: 0.4218 - val_loss: 1.1227 - val_accuracy: 0.6154\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 1.1080 - accuracy: 0.6190 - val_loss: 1.0158 - val_accuracy: 0.6538\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 1.0027 - accuracy: 0.6565 - val_loss: 0.9344 - val_accuracy: 0.6538\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.9148 - accuracy: 0.7007 - val_loss: 0.8492 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.8466 - accuracy: 0.7245 - val_loss: 0.7940 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.7886 - accuracy: 0.7347 - val_loss: 0.7425 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.7480 - accuracy: 0.7313 - val_loss: 0.7094 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.7145 - accuracy: 0.7381 - val_loss: 0.6772 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6866 - accuracy: 0.7449 - val_loss: 0.6559 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.6653 - accuracy: 0.7517 - val_loss: 0.6348 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6484 - accuracy: 0.7551 - val_loss: 0.6235 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6336 - accuracy: 0.7551 - val_loss: 0.6103 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.6244 - accuracy: 0.7585 - val_loss: 0.6051 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6101 - accuracy: 0.7551 - val_loss: 0.5889 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.6027 - accuracy: 0.7687 - val_loss: 0.5794 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5928 - accuracy: 0.7551 - val_loss: 0.5862 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5867 - accuracy: 0.7551 - val_loss: 0.5777 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.5826 - accuracy: 0.7687 - val_loss: 0.5668 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5754 - accuracy: 0.7653 - val_loss: 0.5683 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5681 - accuracy: 0.7755 - val_loss: 0.5544 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5664 - accuracy: 0.7653 - val_loss: 0.5643 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5604 - accuracy: 0.7721 - val_loss: 0.5546 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5548 - accuracy: 0.7755 - val_loss: 0.5530 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.77 - 0s 292us/step - loss: 0.5527 - accuracy: 0.7687 - val_loss: 0.5553 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5485 - accuracy: 0.7755 - val_loss: 0.5477 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5456 - accuracy: 0.7789 - val_loss: 0.5416 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.5420 - accuracy: 0.7789 - val_loss: 0.5536 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5386 - accuracy: 0.7687 - val_loss: 0.5485 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5359 - accuracy: 0.7721 - val_loss: 0.5462 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.5322 - accuracy: 0.7789 - val_loss: 0.5404 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5306 - accuracy: 0.7789 - val_loss: 0.5450 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5265 - accuracy: 0.7789 - val_loss: 0.5351 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.5258 - accuracy: 0.7789 - val_loss: 0.5431 - val_accuracy: 0.7885\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5227 - accuracy: 0.7755 - val_loss: 0.5378 - val_accuracy: 0.7885\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.5202 - accuracy: 0.7857 - val_loss: 0.5406 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.5168 - accuracy: 0.7857 - val_loss: 0.5337 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5207 - accuracy: 0.7789 - val_loss: 0.5417 - val_accuracy: 0.7885\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5181 - accuracy: 0.7823 - val_loss: 0.5420 - val_accuracy: 0.7885\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5125 - accuracy: 0.7823 - val_loss: 0.5380 - val_accuracy: 0.7885\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5096 - accuracy: 0.7755 - val_loss: 0.5424 - val_accuracy: 0.7885\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5066 - accuracy: 0.7755 - val_loss: 0.5322 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5047 - accuracy: 0.7891 - val_loss: 0.5383 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5040 - accuracy: 0.7857 - val_loss: 0.5344 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5018 - accuracy: 0.7823 - val_loss: 0.5312 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4981 - accuracy: 0.7857 - val_loss: 0.5331 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.4962 - accuracy: 0.7925 - val_loss: 0.5250 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4965 - accuracy: 0.7891 - val_loss: 0.5283 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4942 - accuracy: 0.7891 - val_loss: 0.5233 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 435us/step - loss: 0.4915 - accuracy: 0.7925 - val_loss: 0.5266 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.4923 - accuracy: 0.7925 - val_loss: 0.5286 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.4895 - accuracy: 0.7891 - val_loss: 0.5256 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4856 - accuracy: 0.7925 - val_loss: 0.5268 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.4846 - accuracy: 0.7925 - val_loss: 0.5261 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4830 - accuracy: 0.7993 - val_loss: 0.5300 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.4846 - accuracy: 0.8027 - val_loss: 0.5201 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4778 - accuracy: 0.7993 - val_loss: 0.5327 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.4790 - accuracy: 0.7959 - val_loss: 0.5286 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.4775 - accuracy: 0.7959 - val_loss: 0.5258 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4768 - accuracy: 0.7959 - val_loss: 0.5243 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4768 - accuracy: 0.7959 - val_loss: 0.5238 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4735 - accuracy: 0.8027 - val_loss: 0.5196 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4752 - accuracy: 0.7959 - val_loss: 0.5194 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4690 - accuracy: 0.8027 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4685 - accuracy: 0.8027 - val_loss: 0.5315 - val_accuracy: 0.8077\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4684 - accuracy: 0.8061 - val_loss: 0.5237 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.4656 - accuracy: 0.8027 - val_loss: 0.5166 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.4640 - accuracy: 0.8027 - val_loss: 0.5246 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.78 - 0s 335us/step - loss: 0.4630 - accuracy: 0.8095 - val_loss: 0.5211 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4634 - accuracy: 0.8129 - val_loss: 0.5275 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4608 - accuracy: 0.8027 - val_loss: 0.5232 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4590 - accuracy: 0.8095 - val_loss: 0.5217 - val_accuracy: 0.8077\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 211us/step - loss: 0.4571 - accuracy: 0.8163 - val_loss: 0.5142 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4547 - accuracy: 0.8061 - val_loss: 0.5181 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.4543 - accuracy: 0.8027 - val_loss: 0.5153 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.4518 - accuracy: 0.8061 - val_loss: 0.5189 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.4520 - accuracy: 0.7993 - val_loss: 0.5231 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4501 - accuracy: 0.8061 - val_loss: 0.5176 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.4491 - accuracy: 0.8163 - val_loss: 0.5310 - val_accuracy: 0.8077\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.4463 - accuracy: 0.8299 - val_loss: 0.5150 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.4476 - accuracy: 0.8129 - val_loss: 0.5158 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.4459 - accuracy: 0.8197 - val_loss: 0.5168 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.4447 - accuracy: 0.8061 - val_loss: 0.5259 - val_accuracy: 0.8077\n",
      "116/116 [==============================] - 0s 116us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5322 - accuracy: 0.3197 - val_loss: 1.4783 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 1.3080 - accuracy: 0.5034 - val_loss: 1.2470 - val_accuracy: 0.5192\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 1.1680 - accuracy: 0.5680 - val_loss: 1.1296 - val_accuracy: 0.5769\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 1.0626 - accuracy: 0.6122 - val_loss: 1.0218 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.9734 - accuracy: 0.6769 - val_loss: 0.9276 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.8998 - accuracy: 0.6973 - val_loss: 0.8663 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.8402 - accuracy: 0.7347 - val_loss: 0.8130 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 662us/step - loss: 0.7942 - accuracy: 0.7279 - val_loss: 0.7633 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 242us/step - loss: 0.7576 - accuracy: 0.7313 - val_loss: 0.7280 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.7306 - accuracy: 0.7517 - val_loss: 0.7021 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.7063 - accuracy: 0.7415 - val_loss: 0.6836 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.6845 - accuracy: 0.7551 - val_loss: 0.6544 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6690 - accuracy: 0.7653 - val_loss: 0.6426 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6566 - accuracy: 0.7653 - val_loss: 0.6224 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.6435 - accuracy: 0.7653 - val_loss: 0.6172 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6302 - accuracy: 0.7619 - val_loss: 0.6048 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 252us/step - loss: 0.6207 - accuracy: 0.7721 - val_loss: 0.6009 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.6117 - accuracy: 0.7687 - val_loss: 0.5876 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 0.6039 - accuracy: 0.7551 - val_loss: 0.5861 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 258us/step - loss: 0.5977 - accuracy: 0.7585 - val_loss: 0.5825 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 250us/step - loss: 0.5916 - accuracy: 0.7619 - val_loss: 0.5719 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 254us/step - loss: 0.5845 - accuracy: 0.7653 - val_loss: 0.5748 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.5813 - accuracy: 0.7619 - val_loss: 0.5701 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5762 - accuracy: 0.7517 - val_loss: 0.5575 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5692 - accuracy: 0.7619 - val_loss: 0.5563 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.5656 - accuracy: 0.7619 - val_loss: 0.5515 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.5603 - accuracy: 0.7619 - val_loss: 0.5568 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.5589 - accuracy: 0.7653 - val_loss: 0.5462 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 586us/step - loss: 0.5537 - accuracy: 0.7653 - val_loss: 0.5517 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5523 - accuracy: 0.7721 - val_loss: 0.5453 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5460 - accuracy: 0.7755 - val_loss: 0.5509 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5426 - accuracy: 0.7721 - val_loss: 0.5519 - val_accuracy: 0.7885\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5406 - accuracy: 0.7755 - val_loss: 0.5377 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 795us/step - loss: 0.5367 - accuracy: 0.7789 - val_loss: 0.5416 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.5349 - accuracy: 0.7653 - val_loss: 0.5361 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5324 - accuracy: 0.7687 - val_loss: 0.5386 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 848us/step - loss: 0.5305 - accuracy: 0.7619 - val_loss: 0.5350 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 773us/step - loss: 0.5253 - accuracy: 0.7721 - val_loss: 0.5293 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5234 - accuracy: 0.7687 - val_loss: 0.5335 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.5202 - accuracy: 0.7721 - val_loss: 0.5264 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5188 - accuracy: 0.7721 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.5164 - accuracy: 0.7857 - val_loss: 0.5397 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.5140 - accuracy: 0.7789 - val_loss: 0.5345 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.5139 - accuracy: 0.7721 - val_loss: 0.5347 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 710us/step - loss: 0.5094 - accuracy: 0.7789 - val_loss: 0.5240 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 715us/step - loss: 0.5076 - accuracy: 0.7755 - val_loss: 0.5306 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.5063 - accuracy: 0.7721 - val_loss: 0.5294 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5069 - accuracy: 0.7721 - val_loss: 0.5197 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5024 - accuracy: 0.7857 - val_loss: 0.5282 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5012 - accuracy: 0.7721 - val_loss: 0.5335 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5028 - accuracy: 0.7687 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 683us/step - loss: 0.4974 - accuracy: 0.7789 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4953 - accuracy: 0.7789 - val_loss: 0.5248 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.4963 - accuracy: 0.7789 - val_loss: 0.5223 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.4936 - accuracy: 0.7789 - val_loss: 0.5260 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.4929 - accuracy: 0.7857 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4925 - accuracy: 0.7789 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.4900 - accuracy: 0.7789 - val_loss: 0.5146 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.4914 - accuracy: 0.7721 - val_loss: 0.5313 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.4859 - accuracy: 0.7823 - val_loss: 0.5115 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.4840 - accuracy: 0.7823 - val_loss: 0.5166 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 0.4827 - accuracy: 0.7857 - val_loss: 0.5253 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.4823 - accuracy: 0.7925 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.4823 - accuracy: 0.7789 - val_loss: 0.5178 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.4803 - accuracy: 0.7891 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 567us/step - loss: 0.4802 - accuracy: 0.7789 - val_loss: 0.5224 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.4788 - accuracy: 0.7925 - val_loss: 0.5092 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.4766 - accuracy: 0.8061 - val_loss: 0.5277 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.4744 - accuracy: 0.7823 - val_loss: 0.5200 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.4732 - accuracy: 0.7823 - val_loss: 0.5130 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4720 - accuracy: 0.7925 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.4734 - accuracy: 0.8061 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4731 - accuracy: 0.7857 - val_loss: 0.5296 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.4703 - accuracy: 0.7959 - val_loss: 0.5083 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 536us/step - loss: 0.4688 - accuracy: 0.7891 - val_loss: 0.5191 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 567us/step - loss: 0.4686 - accuracy: 0.8061 - val_loss: 0.5142 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 927us/step - loss: 0.4653 - accuracy: 0.8027 - val_loss: 0.5201 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 436us/step - loss: 0.4640 - accuracy: 0.8061 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 662us/step - loss: 0.4657 - accuracy: 0.7959 - val_loss: 0.5136 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 624us/step - loss: 0.4636 - accuracy: 0.8095 - val_loss: 0.5110 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.4624 - accuracy: 0.8061 - val_loss: 0.5211 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.4610 - accuracy: 0.8095 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 279us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5099 - accuracy: 0.1429 - val_loss: 1.4013 - val_accuracy: 0.2692\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 1.3389 - accuracy: 0.2925 - val_loss: 1.2536 - val_accuracy: 0.4808\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 1.2081 - accuracy: 0.4286 - val_loss: 1.1323 - val_accuracy: 0.6346\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 1.0962 - accuracy: 0.5884 - val_loss: 1.0284 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 1.0025 - accuracy: 0.6735 - val_loss: 0.9435 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.9240 - accuracy: 0.7041 - val_loss: 0.8776 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.8616 - accuracy: 0.7177 - val_loss: 0.8189 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.8107 - accuracy: 0.7313 - val_loss: 0.7720 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.7739 - accuracy: 0.7347 - val_loss: 0.7375 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.7436 - accuracy: 0.7177 - val_loss: 0.7139 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.7153 - accuracy: 0.7313 - val_loss: 0.6844 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 690us/step - loss: 0.6922 - accuracy: 0.7279 - val_loss: 0.6693 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 939us/step - loss: 0.6758 - accuracy: 0.7415 - val_loss: 0.6568 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.6589 - accuracy: 0.7313 - val_loss: 0.6405 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 679us/step - loss: 0.6462 - accuracy: 0.7449 - val_loss: 0.6154 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 801us/step - loss: 0.6361 - accuracy: 0.7313 - val_loss: 0.6152 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.6219 - accuracy: 0.7415 - val_loss: 0.6039 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.6104 - accuracy: 0.7415 - val_loss: 0.6017 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 639us/step - loss: 0.6024 - accuracy: 0.7381 - val_loss: 0.5939 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 696us/step - loss: 0.5958 - accuracy: 0.7517 - val_loss: 0.5834 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.5883 - accuracy: 0.7483 - val_loss: 0.5836 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.5822 - accuracy: 0.7415 - val_loss: 0.5785 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.7449 - val_loss: 0.5721 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 686us/step - loss: 0.5697 - accuracy: 0.7551 - val_loss: 0.5747 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5652 - accuracy: 0.7517 - val_loss: 0.5610 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5602 - accuracy: 0.7653 - val_loss: 0.5644 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 0.5558 - accuracy: 0.7449 - val_loss: 0.5688 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 838us/step - loss: 0.5524 - accuracy: 0.7415 - val_loss: 0.5585 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.5499 - accuracy: 0.7551 - val_loss: 0.5461 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 848us/step - loss: 0.5454 - accuracy: 0.7517 - val_loss: 0.5630 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.5401 - accuracy: 0.7585 - val_loss: 0.5451 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5378 - accuracy: 0.7585 - val_loss: 0.5389 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 693us/step - loss: 0.5335 - accuracy: 0.7653 - val_loss: 0.5415 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 788us/step - loss: 0.5316 - accuracy: 0.7585 - val_loss: 0.5374 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 586us/step - loss: 0.5264 - accuracy: 0.7755 - val_loss: 0.5509 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 619us/step - loss: 0.5260 - accuracy: 0.7585 - val_loss: 0.5446 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 944us/step - loss: 0.5216 - accuracy: 0.7619 - val_loss: 0.5322 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 698us/step - loss: 0.5211 - accuracy: 0.7619 - val_loss: 0.5355 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.5196 - accuracy: 0.7687 - val_loss: 0.5321 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 817us/step - loss: 0.5158 - accuracy: 0.7619 - val_loss: 0.5380 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7687 - val_loss: 0.5250 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 758us/step - loss: 0.5099 - accuracy: 0.7721 - val_loss: 0.5333 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5092 - accuracy: 0.7755 - val_loss: 0.5252 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 599us/step - loss: 0.5069 - accuracy: 0.7721 - val_loss: 0.5216 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 604us/step - loss: 0.5042 - accuracy: 0.7755 - val_loss: 0.5307 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5011 - accuracy: 0.7721 - val_loss: 0.5223 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.4998 - accuracy: 0.7755 - val_loss: 0.5194 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5009 - accuracy: 0.7721 - val_loss: 0.5204 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4961 - accuracy: 0.7755 - val_loss: 0.5201 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4960 - accuracy: 0.7857 - val_loss: 0.5192 - val_accuracy: 0.8077\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 473us/step - loss: 0.4936 - accuracy: 0.7687 - val_loss: 0.5193 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.4919 - accuracy: 0.7789 - val_loss: 0.5176 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.4908 - accuracy: 0.7857 - val_loss: 0.5297 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4873 - accuracy: 0.7857 - val_loss: 0.5123 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.4859 - accuracy: 0.7891 - val_loss: 0.5194 - val_accuracy: 0.8077\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.4848 - accuracy: 0.7925 - val_loss: 0.5201 - val_accuracy: 0.8077\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.4830 - accuracy: 0.7925 - val_loss: 0.5169 - val_accuracy: 0.8077\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.4874 - accuracy: 0.7925 - val_loss: 0.5122 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4821 - accuracy: 0.7891 - val_loss: 0.5116 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.4791 - accuracy: 0.7891 - val_loss: 0.5167 - val_accuracy: 0.8077\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4791 - accuracy: 0.7959 - val_loss: 0.5170 - val_accuracy: 0.8077\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.4752 - accuracy: 0.7959 - val_loss: 0.5207 - val_accuracy: 0.8077\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.4766 - accuracy: 0.7993 - val_loss: 0.5150 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4745 - accuracy: 0.7993 - val_loss: 0.5060 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4718 - accuracy: 0.7993 - val_loss: 0.5086 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.4704 - accuracy: 0.8027 - val_loss: 0.5142 - val_accuracy: 0.8077\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4709 - accuracy: 0.7925 - val_loss: 0.5071 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.4682 - accuracy: 0.7993 - val_loss: 0.5123 - val_accuracy: 0.8077\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4676 - accuracy: 0.8027 - val_loss: 0.5148 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.4657 - accuracy: 0.8095 - val_loss: 0.5099 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.4631 - accuracy: 0.8027 - val_loss: 0.5038 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.4629 - accuracy: 0.8061 - val_loss: 0.5067 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4618 - accuracy: 0.8061 - val_loss: 0.4994 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.4627 - accuracy: 0.8061 - val_loss: 0.5061 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4595 - accuracy: 0.8061 - val_loss: 0.5058 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.4582 - accuracy: 0.8129 - val_loss: 0.4952 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.4570 - accuracy: 0.8061 - val_loss: 0.5055 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.4565 - accuracy: 0.8095 - val_loss: 0.5058 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.4565 - accuracy: 0.8061 - val_loss: 0.5075 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.4555 - accuracy: 0.8027 - val_loss: 0.4974 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.4532 - accuracy: 0.8095 - val_loss: 0.5063 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 444us/step - loss: 0.4556 - accuracy: 0.8027 - val_loss: 0.5068 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.4513 - accuracy: 0.8163 - val_loss: 0.4926 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.4528 - accuracy: 0.8027 - val_loss: 0.5070 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.4500 - accuracy: 0.8197 - val_loss: 0.4916 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.4495 - accuracy: 0.8061 - val_loss: 0.5014 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.4483 - accuracy: 0.8061 - val_loss: 0.5039 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 598us/step - loss: 0.4491 - accuracy: 0.8095 - val_loss: 0.4933 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.4445 - accuracy: 0.8129 - val_loss: 0.5054 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.4461 - accuracy: 0.8265 - val_loss: 0.5062 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4433 - accuracy: 0.8129 - val_loss: 0.5025 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.4431 - accuracy: 0.8197 - val_loss: 0.4984 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.4406 - accuracy: 0.8129 - val_loss: 0.4934 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.4410 - accuracy: 0.8163 - val_loss: 0.4940 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.4391 - accuracy: 0.8163 - val_loss: 0.4990 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 243us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4552 - accuracy: 0.2245 - val_loss: 1.3448 - val_accuracy: 0.2885\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 1.2670 - accuracy: 0.4218 - val_loss: 1.1853 - val_accuracy: 0.5192\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 1.1504 - accuracy: 0.6088 - val_loss: 1.0610 - val_accuracy: 0.6923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 1.0464 - accuracy: 0.6871 - val_loss: 0.9668 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.9591 - accuracy: 0.7007 - val_loss: 0.8722 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.8818 - accuracy: 0.7177 - val_loss: 0.8046 - val_accuracy: 0.8077\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.8204 - accuracy: 0.7245 - val_loss: 0.7519 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.7706 - accuracy: 0.7279 - val_loss: 0.7075 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.7321 - accuracy: 0.7245 - val_loss: 0.6734 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 688us/step - loss: 0.6992 - accuracy: 0.7313 - val_loss: 0.6432 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 437us/step - loss: 0.6752 - accuracy: 0.7279 - val_loss: 0.6258 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.6562 - accuracy: 0.7415 - val_loss: 0.6048 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.6415 - accuracy: 0.7381 - val_loss: 0.6016 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.6277 - accuracy: 0.7415 - val_loss: 0.5960 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.6185 - accuracy: 0.7517 - val_loss: 0.5768 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.6090 - accuracy: 0.7483 - val_loss: 0.5827 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.5985 - accuracy: 0.7653 - val_loss: 0.5658 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 0.5919 - accuracy: 0.7585 - val_loss: 0.5637 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.5849 - accuracy: 0.7653 - val_loss: 0.5608 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5805 - accuracy: 0.7551 - val_loss: 0.5644 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5743 - accuracy: 0.7585 - val_loss: 0.5485 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5686 - accuracy: 0.7585 - val_loss: 0.5474 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5652 - accuracy: 0.7585 - val_loss: 0.5514 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.5595 - accuracy: 0.7687 - val_loss: 0.5433 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5564 - accuracy: 0.7653 - val_loss: 0.5490 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 0.5511 - accuracy: 0.7619 - val_loss: 0.5392 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.5515 - accuracy: 0.7619 - val_loss: 0.5365 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.5464 - accuracy: 0.7687 - val_loss: 0.5422 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.5430 - accuracy: 0.7687 - val_loss: 0.5313 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.5392 - accuracy: 0.7687 - val_loss: 0.5425 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5363 - accuracy: 0.7687 - val_loss: 0.5285 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.5342 - accuracy: 0.7653 - val_loss: 0.5300 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 668us/step - loss: 0.5290 - accuracy: 0.7687 - val_loss: 0.5324 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5264 - accuracy: 0.7687 - val_loss: 0.5314 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5244 - accuracy: 0.7687 - val_loss: 0.5286 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.5213 - accuracy: 0.7687 - val_loss: 0.5185 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5197 - accuracy: 0.7687 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.5182 - accuracy: 0.7687 - val_loss: 0.5191 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5119 - accuracy: 0.7755 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5118 - accuracy: 0.7789 - val_loss: 0.5101 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.5107 - accuracy: 0.7721 - val_loss: 0.5082 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5075 - accuracy: 0.7789 - val_loss: 0.5035 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.5086 - accuracy: 0.7789 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.5045 - accuracy: 0.7755 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.5005 - accuracy: 0.7789 - val_loss: 0.5057 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.5011 - accuracy: 0.7789 - val_loss: 0.5226 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.4973 - accuracy: 0.7721 - val_loss: 0.5176 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4960 - accuracy: 0.7823 - val_loss: 0.5045 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.4944 - accuracy: 0.7857 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.4924 - accuracy: 0.7925 - val_loss: 0.5150 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4896 - accuracy: 0.7891 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.4887 - accuracy: 0.7891 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4904 - accuracy: 0.7789 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.4865 - accuracy: 0.7857 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.4870 - accuracy: 0.7925 - val_loss: 0.5069 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.4811 - accuracy: 0.7925 - val_loss: 0.5041 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.4811 - accuracy: 0.7857 - val_loss: 0.4973 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.4790 - accuracy: 0.7823 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.4798 - accuracy: 0.7789 - val_loss: 0.4971 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.4780 - accuracy: 0.7993 - val_loss: 0.5051 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4755 - accuracy: 0.7891 - val_loss: 0.4963 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.4741 - accuracy: 0.7891 - val_loss: 0.5099 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4745 - accuracy: 0.7823 - val_loss: 0.5035 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.4702 - accuracy: 0.7891 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4715 - accuracy: 0.7959 - val_loss: 0.4982 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.4673 - accuracy: 0.7959 - val_loss: 0.4964 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 535us/step - loss: 0.4659 - accuracy: 0.7925 - val_loss: 0.4999 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4639 - accuracy: 0.8027 - val_loss: 0.4973 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.4619 - accuracy: 0.7925 - val_loss: 0.4884 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4633 - accuracy: 0.7925 - val_loss: 0.4956 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4599 - accuracy: 0.8027 - val_loss: 0.4848 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.4582 - accuracy: 0.7959 - val_loss: 0.4918 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4599 - accuracy: 0.7993 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4598 - accuracy: 0.7993 - val_loss: 0.4910 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 731us/step - loss: 0.4575 - accuracy: 0.7993 - val_loss: 0.4925 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.4539 - accuracy: 0.7993 - val_loss: 0.4872 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4554 - accuracy: 0.8095 - val_loss: 0.4924 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.4511 - accuracy: 0.8027 - val_loss: 0.4903 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4503 - accuracy: 0.8095 - val_loss: 0.4886 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.4529 - accuracy: 0.8027 - val_loss: 0.4795 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 783us/step - loss: 0.4485 - accuracy: 0.7993 - val_loss: 0.5019 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.4471 - accuracy: 0.7993 - val_loss: 0.4956 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.4457 - accuracy: 0.8027 - val_loss: 0.4894 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.4442 - accuracy: 0.8095 - val_loss: 0.4880 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.4437 - accuracy: 0.8095 - val_loss: 0.4898 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 645us/step - loss: 0.4440 - accuracy: 0.8027 - val_loss: 0.4788 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.4395 - accuracy: 0.8095 - val_loss: 0.4910 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 608us/step - loss: 0.4399 - accuracy: 0.8095 - val_loss: 0.4833 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.4378 - accuracy: 0.8095 - val_loss: 0.4890 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 727us/step - loss: 0.4375 - accuracy: 0.8095 - val_loss: 0.4855 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4399 - accuracy: 0.8027 - val_loss: 0.4856 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.4372 - accuracy: 0.7993 - val_loss: 0.4908 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4327 - accuracy: 0.8095 - val_loss: 0.4776 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.4352 - accuracy: 0.8027 - val_loss: 0.4822 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.4312 - accuracy: 0.8163 - val_loss: 0.4944 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.4300 - accuracy: 0.8197 - val_loss: 0.4886 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 648us/step - loss: 0.4310 - accuracy: 0.8129 - val_loss: 0.4869 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.4275 - accuracy: 0.8129 - val_loss: 0.4784 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.4272 - accuracy: 0.8163 - val_loss: 0.4852 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.4271 - accuracy: 0.8197 - val_loss: 0.4867 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.4250 - accuracy: 0.8265 - val_loss: 0.4770 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.4236 - accuracy: 0.8197 - val_loss: 0.4821 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.4228 - accuracy: 0.8129 - val_loss: 0.4732 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4206 - accuracy: 0.8231 - val_loss: 0.4870 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.4199 - accuracy: 0.8231 - val_loss: 0.4845 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.4184 - accuracy: 0.8197 - val_loss: 0.4800 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4181 - accuracy: 0.8299 - val_loss: 0.4771 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4185 - accuracy: 0.8163 - val_loss: 0.4683 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4157 - accuracy: 0.8129 - val_loss: 0.4853 - val_accuracy: 0.8269\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.4148 - accuracy: 0.8367 - val_loss: 0.4741 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.4163 - accuracy: 0.8231 - val_loss: 0.4785 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4127 - accuracy: 0.8299 - val_loss: 0.4751 - val_accuracy: 0.8269\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.4110 - accuracy: 0.8503 - val_loss: 0.4742 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.4135 - accuracy: 0.8231 - val_loss: 0.4793 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4117 - accuracy: 0.8333 - val_loss: 0.4613 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4087 - accuracy: 0.8299 - val_loss: 0.4876 - val_accuracy: 0.8269\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.4077 - accuracy: 0.8401 - val_loss: 0.4694 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4052 - accuracy: 0.8401 - val_loss: 0.4786 - val_accuracy: 0.8269\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.4089 - accuracy: 0.8299 - val_loss: 0.4809 - val_accuracy: 0.8269\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4052 - accuracy: 0.8299 - val_loss: 0.4908 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.4027 - accuracy: 0.8401 - val_loss: 0.4732 - val_accuracy: 0.8269\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4014 - accuracy: 0.8503 - val_loss: 0.4693 - val_accuracy: 0.8269\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 401us/step - loss: 0.4000 - accuracy: 0.8435 - val_loss: 0.4765 - val_accuracy: 0.8269\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.3980 - accuracy: 0.8469 - val_loss: 0.4707 - val_accuracy: 0.8269\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.3987 - accuracy: 0.8435 - val_loss: 0.4699 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 81us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5812 - accuracy: 0.2755 - val_loss: 1.4758 - val_accuracy: 0.2115\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 1.2821 - accuracy: 0.3810 - val_loss: 1.2745 - val_accuracy: 0.4423\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 1.1524 - accuracy: 0.5510 - val_loss: 1.1455 - val_accuracy: 0.5192\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 1.0519 - accuracy: 0.5918 - val_loss: 1.0469 - val_accuracy: 0.5769\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.9662 - accuracy: 0.6395 - val_loss: 0.9536 - val_accuracy: 0.5962\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.9004 - accuracy: 0.6633 - val_loss: 0.8927 - val_accuracy: 0.6346\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.8448 - accuracy: 0.6871 - val_loss: 0.8291 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.7993 - accuracy: 0.6905 - val_loss: 0.7801 - val_accuracy: 0.7115\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.7605 - accuracy: 0.6973 - val_loss: 0.7529 - val_accuracy: 0.7308\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.7317 - accuracy: 0.7177 - val_loss: 0.7103 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.7058 - accuracy: 0.7279 - val_loss: 0.6828 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.6843 - accuracy: 0.7279 - val_loss: 0.6698 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.6647 - accuracy: 0.7449 - val_loss: 0.6453 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.6524 - accuracy: 0.7347 - val_loss: 0.6373 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.6379 - accuracy: 0.7449 - val_loss: 0.6154 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.6262 - accuracy: 0.7517 - val_loss: 0.6037 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.6161 - accuracy: 0.7449 - val_loss: 0.5941 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.6060 - accuracy: 0.7517 - val_loss: 0.5885 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5986 - accuracy: 0.7585 - val_loss: 0.5785 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.5937 - accuracy: 0.7551 - val_loss: 0.5665 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.5865 - accuracy: 0.7449 - val_loss: 0.5673 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.5811 - accuracy: 0.7619 - val_loss: 0.5641 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.5755 - accuracy: 0.7619 - val_loss: 0.5483 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.5703 - accuracy: 0.7585 - val_loss: 0.5559 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5658 - accuracy: 0.7585 - val_loss: 0.5414 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.5634 - accuracy: 0.7619 - val_loss: 0.5397 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5562 - accuracy: 0.7585 - val_loss: 0.5540 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.5532 - accuracy: 0.7585 - val_loss: 0.5366 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5511 - accuracy: 0.7551 - val_loss: 0.5388 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5452 - accuracy: 0.7551 - val_loss: 0.5294 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.5419 - accuracy: 0.7551 - val_loss: 0.5290 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.5420 - accuracy: 0.7687 - val_loss: 0.5263 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 0.5356 - accuracy: 0.7653 - val_loss: 0.5378 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5340 - accuracy: 0.7551 - val_loss: 0.5294 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.5295 - accuracy: 0.7687 - val_loss: 0.5240 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5294 - accuracy: 0.7653 - val_loss: 0.5165 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5279 - accuracy: 0.7721 - val_loss: 0.5296 - val_accuracy: 0.7885\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5229 - accuracy: 0.7687 - val_loss: 0.5148 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.76 - 0s 513us/step - loss: 0.5188 - accuracy: 0.7687 - val_loss: 0.5178 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 571us/step - loss: 0.5171 - accuracy: 0.7789 - val_loss: 0.5113 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.5166 - accuracy: 0.7721 - val_loss: 0.5175 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.5139 - accuracy: 0.7755 - val_loss: 0.5167 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.5105 - accuracy: 0.7721 - val_loss: 0.5126 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.5104 - accuracy: 0.7823 - val_loss: 0.5000 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5085 - accuracy: 0.7823 - val_loss: 0.5173 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.5105 - accuracy: 0.7755 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5023 - accuracy: 0.7789 - val_loss: 0.5178 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5024 - accuracy: 0.7755 - val_loss: 0.5134 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4993 - accuracy: 0.7755 - val_loss: 0.4994 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 687us/step - loss: 0.4985 - accuracy: 0.7823 - val_loss: 0.5023 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.4978 - accuracy: 0.7857 - val_loss: 0.5068 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.4935 - accuracy: 0.7823 - val_loss: 0.5116 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 512us/step - loss: 0.4921 - accuracy: 0.7891 - val_loss: 0.5024 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4933 - accuracy: 0.7925 - val_loss: 0.5001 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4888 - accuracy: 0.7891 - val_loss: 0.5089 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4884 - accuracy: 0.7857 - val_loss: 0.5090 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4861 - accuracy: 0.7857 - val_loss: 0.5061 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.4841 - accuracy: 0.7891 - val_loss: 0.4985 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4873 - accuracy: 0.7857 - val_loss: 0.4997 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.4814 - accuracy: 0.7993 - val_loss: 0.4949 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4817 - accuracy: 0.7959 - val_loss: 0.4997 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.4814 - accuracy: 0.7891 - val_loss: 0.5047 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 0.4779 - accuracy: 0.7959 - val_loss: 0.5010 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4783 - accuracy: 0.7891 - val_loss: 0.4927 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4732 - accuracy: 0.7993 - val_loss: 0.4960 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4766 - accuracy: 0.7959 - val_loss: 0.4975 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4762 - accuracy: 0.7925 - val_loss: 0.4950 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.4716 - accuracy: 0.7925 - val_loss: 0.5042 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4723 - accuracy: 0.7823 - val_loss: 0.5077 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.4686 - accuracy: 0.8061 - val_loss: 0.4926 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4654 - accuracy: 0.8027 - val_loss: 0.4941 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.4647 - accuracy: 0.7959 - val_loss: 0.4925 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4642 - accuracy: 0.7993 - val_loss: 0.4897 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4635 - accuracy: 0.7959 - val_loss: 0.5022 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4608 - accuracy: 0.7925 - val_loss: 0.4900 - val_accuracy: 0.8269\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4595 - accuracy: 0.8095 - val_loss: 0.4876 - val_accuracy: 0.8269\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.4574 - accuracy: 0.8027 - val_loss: 0.4959 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4574 - accuracy: 0.7959 - val_loss: 0.4990 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4578 - accuracy: 0.8027 - val_loss: 0.4917 - val_accuracy: 0.8269\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4545 - accuracy: 0.8027 - val_loss: 0.4912 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.4534 - accuracy: 0.8061 - val_loss: 0.4998 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4532 - accuracy: 0.8095 - val_loss: 0.4910 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4511 - accuracy: 0.8027 - val_loss: 0.5028 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.4487 - accuracy: 0.8129 - val_loss: 0.4947 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.4499 - accuracy: 0.8095 - val_loss: 0.4990 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4472 - accuracy: 0.8095 - val_loss: 0.4857 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.4448 - accuracy: 0.8095 - val_loss: 0.4979 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4472 - accuracy: 0.8231 - val_loss: 0.5006 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4454 - accuracy: 0.8163 - val_loss: 0.4971 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4432 - accuracy: 0.8197 - val_loss: 0.4821 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 739us/step - loss: 0.4420 - accuracy: 0.8129 - val_loss: 0.4935 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.4407 - accuracy: 0.8197 - val_loss: 0.4876 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 571us/step - loss: 0.4408 - accuracy: 0.8129 - val_loss: 0.4919 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 627us/step - loss: 0.4414 - accuracy: 0.8197 - val_loss: 0.4906 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.4379 - accuracy: 0.8163 - val_loss: 0.4948 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.4376 - accuracy: 0.8197 - val_loss: 0.5033 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.4380 - accuracy: 0.8129 - val_loss: 0.4936 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 728us/step - loss: 0.4367 - accuracy: 0.8231 - val_loss: 0.4829 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.4367 - accuracy: 0.8231 - val_loss: 0.5030 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4323 - accuracy: 0.8231 - val_loss: 0.4917 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 229us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.3606 - accuracy: 0.2993 - val_loss: 1.2790 - val_accuracy: 0.4231\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 1.2035 - accuracy: 0.5170 - val_loss: 1.1450 - val_accuracy: 0.5769\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 552us/step - loss: 1.0893 - accuracy: 0.5850 - val_loss: 1.0136 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 659us/step - loss: 0.9882 - accuracy: 0.6701 - val_loss: 0.9198 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 911us/step - loss: 0.9112 - accuracy: 0.7075 - val_loss: 0.8389 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.8429 - accuracy: 0.7245 - val_loss: 0.7703 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.7877 - accuracy: 0.7449 - val_loss: 0.7206 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 367us/step - loss: 0.7501 - accuracy: 0.7381 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.7129 - accuracy: 0.7517 - val_loss: 0.6620 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 690us/step - loss: 0.6880 - accuracy: 0.7517 - val_loss: 0.6363 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.6697 - accuracy: 0.7517 - val_loss: 0.6170 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 240us/step - loss: 0.6488 - accuracy: 0.7517 - val_loss: 0.6065 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.6368 - accuracy: 0.7517 - val_loss: 0.5947 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.6230 - accuracy: 0.7483 - val_loss: 0.5773 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.6152 - accuracy: 0.7585 - val_loss: 0.5688 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 258us/step - loss: 0.6006 - accuracy: 0.7551 - val_loss: 0.5676 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.5946 - accuracy: 0.7551 - val_loss: 0.5644 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 626us/step - loss: 0.5878 - accuracy: 0.7449 - val_loss: 0.5590 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 834us/step - loss: 0.5787 - accuracy: 0.7585 - val_loss: 0.5626 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5706 - accuracy: 0.7653 - val_loss: 0.5482 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5643 - accuracy: 0.7653 - val_loss: 0.5539 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.5613 - accuracy: 0.7585 - val_loss: 0.5427 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5533 - accuracy: 0.7687 - val_loss: 0.5489 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.5542 - accuracy: 0.7687 - val_loss: 0.5420 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5448 - accuracy: 0.7755 - val_loss: 0.5384 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.5413 - accuracy: 0.7687 - val_loss: 0.5326 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.5379 - accuracy: 0.7687 - val_loss: 0.5376 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.5364 - accuracy: 0.7687 - val_loss: 0.5270 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.5339 - accuracy: 0.7755 - val_loss: 0.5266 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5270 - accuracy: 0.7755 - val_loss: 0.5307 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.5239 - accuracy: 0.7721 - val_loss: 0.5242 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5220 - accuracy: 0.7687 - val_loss: 0.5234 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5208 - accuracy: 0.7755 - val_loss: 0.5325 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5199 - accuracy: 0.7755 - val_loss: 0.5275 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5163 - accuracy: 0.7653 - val_loss: 0.5287 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5136 - accuracy: 0.7789 - val_loss: 0.5354 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.5103 - accuracy: 0.7721 - val_loss: 0.5109 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5095 - accuracy: 0.7755 - val_loss: 0.5241 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5073 - accuracy: 0.7857 - val_loss: 0.5277 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5067 - accuracy: 0.7755 - val_loss: 0.5253 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 243us/step - loss: 0.5026 - accuracy: 0.7823 - val_loss: 0.5138 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 194us/step - loss: 0.5026 - accuracy: 0.7891 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.4975 - accuracy: 0.7925 - val_loss: 0.5125 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.4978 - accuracy: 0.7857 - val_loss: 0.5206 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4937 - accuracy: 0.7925 - val_loss: 0.5177 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 403us/step - loss: 0.4936 - accuracy: 0.7755 - val_loss: 0.5148 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4902 - accuracy: 0.7959 - val_loss: 0.5201 - val_accuracy: 0.8077\n",
      "116/116 [==============================] - 0s 101us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3168 - accuracy: 0.4116 - val_loss: 1.2362 - val_accuracy: 0.4423\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 511us/step - loss: 1.0980 - accuracy: 0.5952 - val_loss: 1.0939 - val_accuracy: 0.6346\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.9870 - accuracy: 0.6939 - val_loss: 0.9849 - val_accuracy: 0.6538\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.9017 - accuracy: 0.7347 - val_loss: 0.8958 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.8301 - accuracy: 0.7279 - val_loss: 0.8400 - val_accuracy: 0.6923\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.7822 - accuracy: 0.7415 - val_loss: 0.7873 - val_accuracy: 0.7308\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.7463 - accuracy: 0.7381 - val_loss: 0.7418 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.7086 - accuracy: 0.7347 - val_loss: 0.7014 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.6854 - accuracy: 0.7381 - val_loss: 0.6861 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.6612 - accuracy: 0.7449 - val_loss: 0.6575 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.6482 - accuracy: 0.7517 - val_loss: 0.6355 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.6336 - accuracy: 0.7483 - val_loss: 0.6345 - val_accuracy: 0.8269\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6241 - accuracy: 0.7415 - val_loss: 0.6189 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.6105 - accuracy: 0.7415 - val_loss: 0.6123 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.6049 - accuracy: 0.7415 - val_loss: 0.5981 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 295us/step - loss: 0.5954 - accuracy: 0.7449 - val_loss: 0.5904 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.5899 - accuracy: 0.7483 - val_loss: 0.5838 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.5830 - accuracy: 0.7517 - val_loss: 0.5807 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.5770 - accuracy: 0.7483 - val_loss: 0.5704 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5715 - accuracy: 0.7517 - val_loss: 0.5717 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.5679 - accuracy: 0.7585 - val_loss: 0.5753 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.5611 - accuracy: 0.7381 - val_loss: 0.5626 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.5563 - accuracy: 0.7551 - val_loss: 0.5611 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.5547 - accuracy: 0.7483 - val_loss: 0.5584 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5510 - accuracy: 0.7551 - val_loss: 0.5571 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.5469 - accuracy: 0.7585 - val_loss: 0.5422 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5408 - accuracy: 0.7687 - val_loss: 0.5554 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.5387 - accuracy: 0.7755 - val_loss: 0.5440 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.5370 - accuracy: 0.7619 - val_loss: 0.5337 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5346 - accuracy: 0.7619 - val_loss: 0.5468 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5297 - accuracy: 0.7517 - val_loss: 0.5475 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.5292 - accuracy: 0.7721 - val_loss: 0.5469 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.5249 - accuracy: 0.7619 - val_loss: 0.5258 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5199 - accuracy: 0.7653 - val_loss: 0.5364 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5186 - accuracy: 0.7687 - val_loss: 0.5345 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5151 - accuracy: 0.7653 - val_loss: 0.5279 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.5119 - accuracy: 0.7653 - val_loss: 0.5318 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.5131 - accuracy: 0.7755 - val_loss: 0.5342 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 771us/step - loss: 0.5102 - accuracy: 0.7687 - val_loss: 0.5256 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 657us/step - loss: 0.5050 - accuracy: 0.7857 - val_loss: 0.5148 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.5077 - accuracy: 0.7789 - val_loss: 0.5189 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.5049 - accuracy: 0.7687 - val_loss: 0.5201 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.5017 - accuracy: 0.7721 - val_loss: 0.5228 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4983 - accuracy: 0.7721 - val_loss: 0.5152 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4967 - accuracy: 0.7857 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4992 - accuracy: 0.7755 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 632us/step - loss: 0.4961 - accuracy: 0.7789 - val_loss: 0.5328 - val_accuracy: 0.8077\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4904 - accuracy: 0.7789 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4881 - accuracy: 0.7789 - val_loss: 0.5194 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4907 - accuracy: 0.7925 - val_loss: 0.5175 - val_accuracy: 0.8654\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4894 - accuracy: 0.7721 - val_loss: 0.5143 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.4869 - accuracy: 0.7789 - val_loss: 0.5188 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4827 - accuracy: 0.7891 - val_loss: 0.5086 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4816 - accuracy: 0.7857 - val_loss: 0.5123 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.4802 - accuracy: 0.7891 - val_loss: 0.5103 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4817 - accuracy: 0.8027 - val_loss: 0.5050 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4766 - accuracy: 0.7959 - val_loss: 0.5151 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.4751 - accuracy: 0.7959 - val_loss: 0.5077 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4723 - accuracy: 0.7959 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4728 - accuracy: 0.7925 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.4696 - accuracy: 0.7993 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4691 - accuracy: 0.8061 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.4672 - accuracy: 0.7959 - val_loss: 0.5103 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4674 - accuracy: 0.7959 - val_loss: 0.5097 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.4666 - accuracy: 0.7959 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4647 - accuracy: 0.7993 - val_loss: 0.5096 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4621 - accuracy: 0.8095 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4625 - accuracy: 0.8061 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4603 - accuracy: 0.7993 - val_loss: 0.5134 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4604 - accuracy: 0.8027 - val_loss: 0.5032 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4578 - accuracy: 0.7993 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 279us/step - loss: 0.4576 - accuracy: 0.7993 - val_loss: 0.5090 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.4564 - accuracy: 0.8129 - val_loss: 0.5089 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.4554 - accuracy: 0.8163 - val_loss: 0.5102 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.4576 - accuracy: 0.8027 - val_loss: 0.5039 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.4514 - accuracy: 0.8095 - val_loss: 0.5100 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4503 - accuracy: 0.8095 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 136us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3980 - accuracy: 0.4218 - val_loss: 1.1381 - val_accuracy: 0.5769\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 249us/step - loss: 1.1537 - accuracy: 0.5340 - val_loss: 1.0337 - val_accuracy: 0.6538\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 217us/step - loss: 1.0355 - accuracy: 0.5986 - val_loss: 0.9545 - val_accuracy: 0.6923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.9543 - accuracy: 0.6497 - val_loss: 0.8891 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 272us/step - loss: 0.8804 - accuracy: 0.6769 - val_loss: 0.8160 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 207us/step - loss: 0.8245 - accuracy: 0.6973 - val_loss: 0.7730 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.7784 - accuracy: 0.7245 - val_loss: 0.7308 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.7418 - accuracy: 0.7279 - val_loss: 0.7004 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.7128 - accuracy: 0.7313 - val_loss: 0.6689 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.6875 - accuracy: 0.7347 - val_loss: 0.6578 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6691 - accuracy: 0.7313 - val_loss: 0.6310 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.6528 - accuracy: 0.7381 - val_loss: 0.6281 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.6375 - accuracy: 0.7415 - val_loss: 0.6034 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.6258 - accuracy: 0.7347 - val_loss: 0.5996 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6126 - accuracy: 0.7449 - val_loss: 0.5898 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6033 - accuracy: 0.7415 - val_loss: 0.5848 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5943 - accuracy: 0.7483 - val_loss: 0.5691 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5910 - accuracy: 0.7381 - val_loss: 0.5623 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5810 - accuracy: 0.7483 - val_loss: 0.5757 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.5716 - accuracy: 0.7483 - val_loss: 0.5540 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5672 - accuracy: 0.7449 - val_loss: 0.5464 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5600 - accuracy: 0.7483 - val_loss: 0.5462 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.5556 - accuracy: 0.7551 - val_loss: 0.5526 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.5513 - accuracy: 0.7551 - val_loss: 0.5442 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.5464 - accuracy: 0.7517 - val_loss: 0.5461 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 771us/step - loss: 0.5431 - accuracy: 0.7653 - val_loss: 0.5285 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.5389 - accuracy: 0.7551 - val_loss: 0.5270 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5339 - accuracy: 0.7619 - val_loss: 0.5326 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5328 - accuracy: 0.7585 - val_loss: 0.5224 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5279 - accuracy: 0.7687 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5247 - accuracy: 0.7653 - val_loss: 0.5210 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 751us/step - loss: 0.5248 - accuracy: 0.7687 - val_loss: 0.5185 - val_accuracy: 0.8654\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 657us/step - loss: 0.5182 - accuracy: 0.7721 - val_loss: 0.5273 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5150 - accuracy: 0.7585 - val_loss: 0.5212 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 830us/step - loss: 0.5165 - accuracy: 0.7687 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.5119 - accuracy: 0.7721 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.5070 - accuracy: 0.7789 - val_loss: 0.5118 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5048 - accuracy: 0.7687 - val_loss: 0.5140 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.5033 - accuracy: 0.7789 - val_loss: 0.5086 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5018 - accuracy: 0.7789 - val_loss: 0.5147 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.4998 - accuracy: 0.7789 - val_loss: 0.5144 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 0.4978 - accuracy: 0.7755 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4950 - accuracy: 0.7755 - val_loss: 0.5117 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4926 - accuracy: 0.7789 - val_loss: 0.5105 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.4910 - accuracy: 0.7789 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4912 - accuracy: 0.7823 - val_loss: 0.5130 - val_accuracy: 0.8654\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4922 - accuracy: 0.7891 - val_loss: 0.5082 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.4869 - accuracy: 0.7755 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.4852 - accuracy: 0.7823 - val_loss: 0.4954 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 765us/step - loss: 0.4838 - accuracy: 0.7789 - val_loss: 0.5036 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 846us/step - loss: 0.4810 - accuracy: 0.7755 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.4784 - accuracy: 0.7857 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 713us/step - loss: 0.4783 - accuracy: 0.7823 - val_loss: 0.4958 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 659us/step - loss: 0.4800 - accuracy: 0.7857 - val_loss: 0.4997 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 820us/step - loss: 0.4766 - accuracy: 0.7891 - val_loss: 0.4961 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 749us/step - loss: 0.4741 - accuracy: 0.7857 - val_loss: 0.4963 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.4734 - accuracy: 0.7823 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 907us/step - loss: 0.4726 - accuracy: 0.7891 - val_loss: 0.4955 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 695us/step - loss: 0.4710 - accuracy: 0.7891 - val_loss: 0.4961 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 110us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.5315 - accuracy: 0.2347 - val_loss: 1.3437 - val_accuracy: 0.2500\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 604us/step - loss: 1.2391 - accuracy: 0.4592 - val_loss: 1.1816 - val_accuracy: 0.5385\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 774us/step - loss: 1.0891 - accuracy: 0.6224 - val_loss: 1.0428 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 741us/step - loss: 0.9757 - accuracy: 0.6905 - val_loss: 0.9505 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 914us/step - loss: 0.8873 - accuracy: 0.7211 - val_loss: 0.8608 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 748us/step - loss: 0.8206 - accuracy: 0.7415 - val_loss: 0.8017 - val_accuracy: 0.8077\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 880us/step - loss: 0.7713 - accuracy: 0.7517 - val_loss: 0.7553 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 730us/step - loss: 0.7295 - accuracy: 0.7585 - val_loss: 0.7138 - val_accuracy: 0.8077\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.6992 - accuracy: 0.7517 - val_loss: 0.6835 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 646us/step - loss: 0.6747 - accuracy: 0.7517 - val_loss: 0.6614 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.6541 - accuracy: 0.7619 - val_loss: 0.6513 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 739us/step - loss: 0.6413 - accuracy: 0.7483 - val_loss: 0.6324 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.6245 - accuracy: 0.7483 - val_loss: 0.6144 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.6135 - accuracy: 0.7449 - val_loss: 0.6061 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6029 - accuracy: 0.7585 - val_loss: 0.5957 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 647us/step - loss: 0.5946 - accuracy: 0.7653 - val_loss: 0.5771 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5852 - accuracy: 0.7619 - val_loss: 0.5770 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.5777 - accuracy: 0.7619 - val_loss: 0.5765 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 853us/step - loss: 0.5724 - accuracy: 0.7449 - val_loss: 0.5679 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7619 - val_loss: 0.5582 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 939us/step - loss: 0.5611 - accuracy: 0.7585 - val_loss: 0.5515 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 864us/step - loss: 0.5582 - accuracy: 0.7619 - val_loss: 0.5649 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 882us/step - loss: 0.5538 - accuracy: 0.7585 - val_loss: 0.5407 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7687 - val_loss: 0.5361 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 761us/step - loss: 0.5494 - accuracy: 0.7585 - val_loss: 0.5405 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 878us/step - loss: 0.5434 - accuracy: 0.7619 - val_loss: 0.5419 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 844us/step - loss: 0.5383 - accuracy: 0.7721 - val_loss: 0.5277 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 833us/step - loss: 0.5362 - accuracy: 0.7755 - val_loss: 0.5319 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 751us/step - loss: 0.5315 - accuracy: 0.7653 - val_loss: 0.5358 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7721 - val_loss: 0.5166 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 977us/step - loss: 0.5266 - accuracy: 0.7687 - val_loss: 0.5213 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 945us/step - loss: 0.5260 - accuracy: 0.7721 - val_loss: 0.5247 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.5220 - accuracy: 0.7687 - val_loss: 0.5240 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.5218 - accuracy: 0.7619 - val_loss: 0.5196 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.5169 - accuracy: 0.7721 - val_loss: 0.5217 - val_accuracy: 0.7885\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5135 - accuracy: 0.7721 - val_loss: 0.5163 - val_accuracy: 0.7885\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 0.5130 - accuracy: 0.7789 - val_loss: 0.5131 - val_accuracy: 0.7885\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.5128 - accuracy: 0.7755 - val_loss: 0.5057 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 633us/step - loss: 0.5106 - accuracy: 0.7755 - val_loss: 0.5090 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5078 - accuracy: 0.7857 - val_loss: 0.5013 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5057 - accuracy: 0.7721 - val_loss: 0.5103 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5046 - accuracy: 0.7721 - val_loss: 0.5162 - val_accuracy: 0.7885\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.5027 - accuracy: 0.7687 - val_loss: 0.5064 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.5009 - accuracy: 0.7789 - val_loss: 0.5035 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 869us/step - loss: 0.5004 - accuracy: 0.7789 - val_loss: 0.5079 - val_accuracy: 0.8077\n",
      "Epoch 46/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7789 - val_loss: 0.5023 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7959 - val_loss: 0.4947 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 648us/step - loss: 0.4958 - accuracy: 0.7925 - val_loss: 0.5001 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 883us/step - loss: 0.4937 - accuracy: 0.7755 - val_loss: 0.5063 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 808us/step - loss: 0.4917 - accuracy: 0.7755 - val_loss: 0.5121 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 833us/step - loss: 0.4924 - accuracy: 0.7925 - val_loss: 0.4958 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 833us/step - loss: 0.4896 - accuracy: 0.7891 - val_loss: 0.5030 - val_accuracy: 0.8077\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 786us/step - loss: 0.4882 - accuracy: 0.7721 - val_loss: 0.5038 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 872us/step - loss: 0.4869 - accuracy: 0.7721 - val_loss: 0.5010 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 610us/step - loss: 0.4848 - accuracy: 0.7891 - val_loss: 0.4988 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 987us/step - loss: 0.4848 - accuracy: 0.7959 - val_loss: 0.4984 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7891 - val_loss: 0.4929 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 925us/step - loss: 0.4824 - accuracy: 0.7891 - val_loss: 0.4961 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 688us/step - loss: 0.4783 - accuracy: 0.7891 - val_loss: 0.5089 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 926us/step - loss: 0.4777 - accuracy: 0.7823 - val_loss: 0.4913 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7823 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 765us/step - loss: 0.4766 - accuracy: 0.7857 - val_loss: 0.4969 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 920us/step - loss: 0.4766 - accuracy: 0.7925 - val_loss: 0.4973 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 839us/step - loss: 0.4723 - accuracy: 0.7857 - val_loss: 0.4883 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 899us/step - loss: 0.4724 - accuracy: 0.8027 - val_loss: 0.4879 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7891 - val_loss: 0.4907 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 815us/step - loss: 0.4686 - accuracy: 0.7959 - val_loss: 0.4864 - val_accuracy: 0.8269\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 857us/step - loss: 0.4713 - accuracy: 0.7823 - val_loss: 0.4934 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.4668 - accuracy: 0.7959 - val_loss: 0.4806 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.4679 - accuracy: 0.7925 - val_loss: 0.4890 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.4634 - accuracy: 0.7959 - val_loss: 0.4794 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4647 - accuracy: 0.7925 - val_loss: 0.4949 - val_accuracy: 0.8269\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 726us/step - loss: 0.4618 - accuracy: 0.7925 - val_loss: 0.4810 - val_accuracy: 0.8269\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 633us/step - loss: 0.4607 - accuracy: 0.7925 - val_loss: 0.4901 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4578 - accuracy: 0.7993 - val_loss: 0.4786 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4616 - accuracy: 0.7959 - val_loss: 0.4849 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4585 - accuracy: 0.8027 - val_loss: 0.4786 - val_accuracy: 0.8269\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 625us/step - loss: 0.4555 - accuracy: 0.7925 - val_loss: 0.4807 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 642us/step - loss: 0.4549 - accuracy: 0.7891 - val_loss: 0.4788 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 673us/step - loss: 0.4542 - accuracy: 0.8027 - val_loss: 0.4841 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4532 - accuracy: 0.7959 - val_loss: 0.4775 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 0.4536 - accuracy: 0.7891 - val_loss: 0.4754 - val_accuracy: 0.8269\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4488 - accuracy: 0.7993 - val_loss: 0.4974 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 594us/step - loss: 0.4482 - accuracy: 0.8027 - val_loss: 0.4816 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 818us/step - loss: 0.4504 - accuracy: 0.8027 - val_loss: 0.4673 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 477us/step - loss: 0.4533 - accuracy: 0.7993 - val_loss: 0.4801 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 0.4464 - accuracy: 0.8027 - val_loss: 0.4778 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.4434 - accuracy: 0.8061 - val_loss: 0.4675 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.4435 - accuracy: 0.8129 - val_loss: 0.4837 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 674us/step - loss: 0.4428 - accuracy: 0.8027 - val_loss: 0.4786 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.4389 - accuracy: 0.8027 - val_loss: 0.4696 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.4414 - accuracy: 0.8129 - val_loss: 0.4692 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4379 - accuracy: 0.8061 - val_loss: 0.4761 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4353 - accuracy: 0.8095 - val_loss: 0.4717 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.4359 - accuracy: 0.8095 - val_loss: 0.4746 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 142us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.5367 - accuracy: 0.4796 - val_loss: 1.4363 - val_accuracy: 0.4231\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 1.2074 - accuracy: 0.4864 - val_loss: 1.1435 - val_accuracy: 0.4808\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 1.0422 - accuracy: 0.6054 - val_loss: 1.0051 - val_accuracy: 0.6538\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.9344 - accuracy: 0.6939 - val_loss: 0.9017 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.8509 - accuracy: 0.7381 - val_loss: 0.8190 - val_accuracy: 0.8077\n",
      "Epoch 6/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 482us/step - loss: 0.7820 - accuracy: 0.7279 - val_loss: 0.7658 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.7298 - accuracy: 0.7449 - val_loss: 0.7267 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.6928 - accuracy: 0.7687 - val_loss: 0.6885 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 605us/step - loss: 0.6647 - accuracy: 0.7585 - val_loss: 0.6666 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.6459 - accuracy: 0.7619 - val_loss: 0.6460 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6303 - accuracy: 0.7721 - val_loss: 0.6373 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6178 - accuracy: 0.7687 - val_loss: 0.6129 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.6030 - accuracy: 0.7789 - val_loss: 0.6072 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5924 - accuracy: 0.7585 - val_loss: 0.6004 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.5833 - accuracy: 0.7755 - val_loss: 0.5870 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 620us/step - loss: 0.5757 - accuracy: 0.7721 - val_loss: 0.5778 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 779us/step - loss: 0.5671 - accuracy: 0.7755 - val_loss: 0.5779 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.5636 - accuracy: 0.7755 - val_loss: 0.5716 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.5564 - accuracy: 0.7789 - val_loss: 0.5592 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5516 - accuracy: 0.7789 - val_loss: 0.5639 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5487 - accuracy: 0.7653 - val_loss: 0.5613 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5432 - accuracy: 0.7755 - val_loss: 0.5579 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.5375 - accuracy: 0.7823 - val_loss: 0.5520 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.5340 - accuracy: 0.7823 - val_loss: 0.5460 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5300 - accuracy: 0.7755 - val_loss: 0.5517 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 880us/step - loss: 0.5276 - accuracy: 0.7789 - val_loss: 0.5547 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 792us/step - loss: 0.5287 - accuracy: 0.7653 - val_loss: 0.5384 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5239 - accuracy: 0.7823 - val_loss: 0.5569 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 600us/step - loss: 0.5198 - accuracy: 0.7721 - val_loss: 0.5340 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5160 - accuracy: 0.7687 - val_loss: 0.5487 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.5148 - accuracy: 0.7755 - val_loss: 0.5376 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.5135 - accuracy: 0.7687 - val_loss: 0.5405 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5088 - accuracy: 0.7857 - val_loss: 0.5452 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5073 - accuracy: 0.7857 - val_loss: 0.5322 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5048 - accuracy: 0.7755 - val_loss: 0.5352 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5013 - accuracy: 0.7891 - val_loss: 0.5325 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.5005 - accuracy: 0.7823 - val_loss: 0.5310 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 511us/step - loss: 0.4997 - accuracy: 0.7959 - val_loss: 0.5393 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4970 - accuracy: 0.7755 - val_loss: 0.5375 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4948 - accuracy: 0.7857 - val_loss: 0.5382 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4931 - accuracy: 0.7925 - val_loss: 0.5258 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 734us/step - loss: 0.4930 - accuracy: 0.7789 - val_loss: 0.5292 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.4892 - accuracy: 0.7959 - val_loss: 0.5314 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.4881 - accuracy: 0.7891 - val_loss: 0.5260 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.4873 - accuracy: 0.8027 - val_loss: 0.5351 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4855 - accuracy: 0.7891 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.4830 - accuracy: 0.7993 - val_loss: 0.5291 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.4813 - accuracy: 0.7925 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4822 - accuracy: 0.8027 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4816 - accuracy: 0.7891 - val_loss: 0.5213 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 605us/step - loss: 0.4811 - accuracy: 0.7925 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4791 - accuracy: 0.7959 - val_loss: 0.5297 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.4774 - accuracy: 0.7993 - val_loss: 0.5177 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 706us/step - loss: 0.4776 - accuracy: 0.7993 - val_loss: 0.5248 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.4770 - accuracy: 0.7959 - val_loss: 0.5315 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4697 - accuracy: 0.8095 - val_loss: 0.5091 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4707 - accuracy: 0.8027 - val_loss: 0.5264 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.4684 - accuracy: 0.8095 - val_loss: 0.5176 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4698 - accuracy: 0.8129 - val_loss: 0.5183 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.4673 - accuracy: 0.8095 - val_loss: 0.5141 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.4629 - accuracy: 0.8061 - val_loss: 0.5271 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 552us/step - loss: 0.4637 - accuracy: 0.8095 - val_loss: 0.5133 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 0.4625 - accuracy: 0.8129 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4612 - accuracy: 0.8129 - val_loss: 0.5200 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4597 - accuracy: 0.8129 - val_loss: 0.5318 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.4605 - accuracy: 0.8129 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 108us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4576 - accuracy: 0.2823 - val_loss: 1.3038 - val_accuracy: 0.4423\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 360us/step - loss: 1.2637 - accuracy: 0.4898 - val_loss: 1.1699 - val_accuracy: 0.5962\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 1.1267 - accuracy: 0.5714 - val_loss: 1.0595 - val_accuracy: 0.6346\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 1.0140 - accuracy: 0.6429 - val_loss: 0.9500 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.9196 - accuracy: 0.7075 - val_loss: 0.8728 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.8441 - accuracy: 0.7211 - val_loss: 0.7989 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.7867 - accuracy: 0.7347 - val_loss: 0.7509 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.7425 - accuracy: 0.7347 - val_loss: 0.7061 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.7061 - accuracy: 0.7415 - val_loss: 0.6807 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.6808 - accuracy: 0.7381 - val_loss: 0.6542 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.6602 - accuracy: 0.7279 - val_loss: 0.6400 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.6411 - accuracy: 0.7381 - val_loss: 0.6295 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.6296 - accuracy: 0.7381 - val_loss: 0.6178 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.6161 - accuracy: 0.7483 - val_loss: 0.6014 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.6085 - accuracy: 0.7449 - val_loss: 0.5949 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 620us/step - loss: 0.5970 - accuracy: 0.7347 - val_loss: 0.5934 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5893 - accuracy: 0.7449 - val_loss: 0.5842 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.5834 - accuracy: 0.7483 - val_loss: 0.5703 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.5757 - accuracy: 0.7347 - val_loss: 0.5681 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5686 - accuracy: 0.7619 - val_loss: 0.5646 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5682 - accuracy: 0.7585 - val_loss: 0.5697 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5565 - accuracy: 0.7517 - val_loss: 0.5549 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 507us/step - loss: 0.5562 - accuracy: 0.7619 - val_loss: 0.5505 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 676us/step - loss: 0.5500 - accuracy: 0.7483 - val_loss: 0.5571 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5460 - accuracy: 0.7483 - val_loss: 0.5551 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.5444 - accuracy: 0.7483 - val_loss: 0.5489 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5406 - accuracy: 0.7517 - val_loss: 0.5550 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5390 - accuracy: 0.7585 - val_loss: 0.5286 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5389 - accuracy: 0.7585 - val_loss: 0.5392 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.5294 - accuracy: 0.7551 - val_loss: 0.5314 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.5310 - accuracy: 0.7585 - val_loss: 0.5269 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5226 - accuracy: 0.7551 - val_loss: 0.5416 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.5257 - accuracy: 0.7721 - val_loss: 0.5355 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5276 - accuracy: 0.7551 - val_loss: 0.5245 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.5149 - accuracy: 0.7619 - val_loss: 0.5269 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.5125 - accuracy: 0.7619 - val_loss: 0.5240 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 902us/step - loss: 0.5098 - accuracy: 0.7687 - val_loss: 0.5147 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 242us/step - loss: 0.5088 - accuracy: 0.7585 - val_loss: 0.5215 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.5059 - accuracy: 0.7687 - val_loss: 0.5150 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5046 - accuracy: 0.7687 - val_loss: 0.5195 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5053 - accuracy: 0.7551 - val_loss: 0.5025 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5024 - accuracy: 0.7721 - val_loss: 0.5139 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4986 - accuracy: 0.7755 - val_loss: 0.5084 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.4974 - accuracy: 0.7619 - val_loss: 0.5066 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4992 - accuracy: 0.7721 - val_loss: 0.5167 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 340us/step - loss: 0.4932 - accuracy: 0.7551 - val_loss: 0.5039 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4918 - accuracy: 0.7823 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.4902 - accuracy: 0.7789 - val_loss: 0.5157 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.4878 - accuracy: 0.7721 - val_loss: 0.5029 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.4854 - accuracy: 0.7857 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 440us/step - loss: 0.4851 - accuracy: 0.7857 - val_loss: 0.4948 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4829 - accuracy: 0.7721 - val_loss: 0.5005 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4817 - accuracy: 0.7959 - val_loss: 0.5010 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.4845 - accuracy: 0.7891 - val_loss: 0.5015 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4791 - accuracy: 0.7823 - val_loss: 0.5082 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4753 - accuracy: 0.7653 - val_loss: 0.4957 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4771 - accuracy: 0.7823 - val_loss: 0.5010 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.4752 - accuracy: 0.7959 - val_loss: 0.5021 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4713 - accuracy: 0.7857 - val_loss: 0.4932 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.4739 - accuracy: 0.7891 - val_loss: 0.5086 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4699 - accuracy: 0.8027 - val_loss: 0.4858 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.4661 - accuracy: 0.7857 - val_loss: 0.5031 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.4653 - accuracy: 0.7993 - val_loss: 0.4960 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4655 - accuracy: 0.7993 - val_loss: 0.4879 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4622 - accuracy: 0.7891 - val_loss: 0.4893 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.4625 - accuracy: 0.7959 - val_loss: 0.4993 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4607 - accuracy: 0.7891 - val_loss: 0.4854 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4591 - accuracy: 0.7857 - val_loss: 0.4881 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.4596 - accuracy: 0.7993 - val_loss: 0.4906 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4554 - accuracy: 0.8061 - val_loss: 0.4846 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.4559 - accuracy: 0.7959 - val_loss: 0.4837 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.4532 - accuracy: 0.7993 - val_loss: 0.4924 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4523 - accuracy: 0.7993 - val_loss: 0.4865 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4516 - accuracy: 0.7993 - val_loss: 0.4770 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.4517 - accuracy: 0.7993 - val_loss: 0.4862 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.4504 - accuracy: 0.7959 - val_loss: 0.4767 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.4466 - accuracy: 0.8027 - val_loss: 0.4862 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4510 - accuracy: 0.7993 - val_loss: 0.4885 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4494 - accuracy: 0.8027 - val_loss: 0.4832 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4439 - accuracy: 0.8027 - val_loss: 0.4828 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4425 - accuracy: 0.8061 - val_loss: 0.4823 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.4420 - accuracy: 0.7993 - val_loss: 0.4785 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.4393 - accuracy: 0.8129 - val_loss: 0.4852 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.4404 - accuracy: 0.8129 - val_loss: 0.4865 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.4392 - accuracy: 0.8095 - val_loss: 0.4810 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4366 - accuracy: 0.7993 - val_loss: 0.4837 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 100us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3419 - accuracy: 0.2891 - val_loss: 1.2023 - val_accuracy: 0.4423\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 1.1639 - accuracy: 0.5748 - val_loss: 1.0755 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 640us/step - loss: 1.0454 - accuracy: 0.6735 - val_loss: 0.9654 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.9442 - accuracy: 0.7041 - val_loss: 0.8705 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 219us/step - loss: 0.8657 - accuracy: 0.7177 - val_loss: 0.7961 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.8071 - accuracy: 0.7245 - val_loss: 0.7478 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 604us/step - loss: 0.7580 - accuracy: 0.7347 - val_loss: 0.6983 - val_accuracy: 0.8269\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.7236 - accuracy: 0.7415 - val_loss: 0.6669 - val_accuracy: 0.8269\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.6970 - accuracy: 0.7517 - val_loss: 0.6429 - val_accuracy: 0.8269\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.6726 - accuracy: 0.7551 - val_loss: 0.6283 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6549 - accuracy: 0.7551 - val_loss: 0.6131 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6416 - accuracy: 0.7517 - val_loss: 0.6131 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.6307 - accuracy: 0.7449 - val_loss: 0.5989 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.6184 - accuracy: 0.7483 - val_loss: 0.5793 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6079 - accuracy: 0.7619 - val_loss: 0.5723 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.5972 - accuracy: 0.7415 - val_loss: 0.5749 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 574us/step - loss: 0.5942 - accuracy: 0.7517 - val_loss: 0.5644 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.5854 - accuracy: 0.7585 - val_loss: 0.5537 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.5780 - accuracy: 0.7517 - val_loss: 0.5501 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 296us/step - loss: 0.5738 - accuracy: 0.7551 - val_loss: 0.5471 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.5684 - accuracy: 0.7619 - val_loss: 0.5554 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5683 - accuracy: 0.7551 - val_loss: 0.5400 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5583 - accuracy: 0.7619 - val_loss: 0.5419 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5523 - accuracy: 0.7585 - val_loss: 0.5423 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.5482 - accuracy: 0.7517 - val_loss: 0.5398 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.5442 - accuracy: 0.7687 - val_loss: 0.5413 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5412 - accuracy: 0.7619 - val_loss: 0.5419 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5354 - accuracy: 0.7755 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5344 - accuracy: 0.7755 - val_loss: 0.5409 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 250us/step - loss: 0.5311 - accuracy: 0.7789 - val_loss: 0.5318 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.5307 - accuracy: 0.7755 - val_loss: 0.5262 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5271 - accuracy: 0.7619 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5261 - accuracy: 0.7755 - val_loss: 0.5185 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5210 - accuracy: 0.7789 - val_loss: 0.5390 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.5141 - accuracy: 0.7789 - val_loss: 0.5186 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.5171 - accuracy: 0.7823 - val_loss: 0.5251 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5123 - accuracy: 0.7823 - val_loss: 0.5296 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5091 - accuracy: 0.7721 - val_loss: 0.5164 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.5071 - accuracy: 0.7959 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5075 - accuracy: 0.7789 - val_loss: 0.5212 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5037 - accuracy: 0.7857 - val_loss: 0.5247 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 395us/step - loss: 0.5039 - accuracy: 0.7959 - val_loss: 0.5154 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.4981 - accuracy: 0.7959 - val_loss: 0.5187 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4981 - accuracy: 0.7925 - val_loss: 0.5285 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.4957 - accuracy: 0.7823 - val_loss: 0.5269 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4971 - accuracy: 0.7993 - val_loss: 0.5187 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4948 - accuracy: 0.7857 - val_loss: 0.5235 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4911 - accuracy: 0.7993 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4888 - accuracy: 0.7959 - val_loss: 0.5237 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 599us/step - loss: 0.4877 - accuracy: 0.7959 - val_loss: 0.5214 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.4855 - accuracy: 0.7925 - val_loss: 0.5148 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.4864 - accuracy: 0.7925 - val_loss: 0.5244 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 637us/step - loss: 0.4815 - accuracy: 0.7925 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.4824 - accuracy: 0.7959 - val_loss: 0.5189 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.4819 - accuracy: 0.7857 - val_loss: 0.5161 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.4774 - accuracy: 0.7891 - val_loss: 0.5031 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 228us/step - loss: 0.4753 - accuracy: 0.8027 - val_loss: 0.5183 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4723 - accuracy: 0.8061 - val_loss: 0.5040 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.4756 - accuracy: 0.7993 - val_loss: 0.5143 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.4719 - accuracy: 0.8061 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 670us/step - loss: 0.4699 - accuracy: 0.7993 - val_loss: 0.5069 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.4674 - accuracy: 0.8027 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4668 - accuracy: 0.8095 - val_loss: 0.5064 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 220us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.2666 - accuracy: 0.4592 - val_loss: 1.1651 - val_accuracy: 0.5192\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 1.0894 - accuracy: 0.5748 - val_loss: 1.0314 - val_accuracy: 0.6154\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.9653 - accuracy: 0.6837 - val_loss: 0.9393 - val_accuracy: 0.6731\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 520us/step - loss: 0.8710 - accuracy: 0.7279 - val_loss: 0.8452 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.8021 - accuracy: 0.7245 - val_loss: 0.7818 - val_accuracy: 0.7308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.7502 - accuracy: 0.7347 - val_loss: 0.7479 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 651us/step - loss: 0.7093 - accuracy: 0.7415 - val_loss: 0.6995 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.6825 - accuracy: 0.7279 - val_loss: 0.6910 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.6560 - accuracy: 0.7517 - val_loss: 0.6517 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.6358 - accuracy: 0.7415 - val_loss: 0.6374 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.6225 - accuracy: 0.7517 - val_loss: 0.6238 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 310us/step - loss: 0.6145 - accuracy: 0.7483 - val_loss: 0.6091 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5977 - accuracy: 0.7585 - val_loss: 0.6052 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.5886 - accuracy: 0.7619 - val_loss: 0.6048 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 481us/step - loss: 0.5794 - accuracy: 0.7619 - val_loss: 0.5833 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.5733 - accuracy: 0.7585 - val_loss: 0.5861 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5645 - accuracy: 0.7721 - val_loss: 0.5746 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.5589 - accuracy: 0.7585 - val_loss: 0.5763 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5527 - accuracy: 0.7721 - val_loss: 0.5684 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5481 - accuracy: 0.7551 - val_loss: 0.5682 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5461 - accuracy: 0.7517 - val_loss: 0.5609 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5412 - accuracy: 0.7653 - val_loss: 0.5708 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5356 - accuracy: 0.7619 - val_loss: 0.5488 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.5310 - accuracy: 0.7653 - val_loss: 0.5547 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5294 - accuracy: 0.7653 - val_loss: 0.5635 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.5238 - accuracy: 0.7619 - val_loss: 0.5469 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 552us/step - loss: 0.5259 - accuracy: 0.7721 - val_loss: 0.5445 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5170 - accuracy: 0.7653 - val_loss: 0.5450 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.5157 - accuracy: 0.7721 - val_loss: 0.5444 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 671us/step - loss: 0.5137 - accuracy: 0.7585 - val_loss: 0.5414 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5100 - accuracy: 0.7857 - val_loss: 0.5456 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.5110 - accuracy: 0.7653 - val_loss: 0.5328 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.5031 - accuracy: 0.7755 - val_loss: 0.5361 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 918us/step - loss: 0.5037 - accuracy: 0.7823 - val_loss: 0.5312 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.4984 - accuracy: 0.7721 - val_loss: 0.5298 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 631us/step - loss: 0.4966 - accuracy: 0.7823 - val_loss: 0.5381 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7721 - val_loss: 0.5330 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 703us/step - loss: 0.4923 - accuracy: 0.7857 - val_loss: 0.5268 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.4903 - accuracy: 0.7959 - val_loss: 0.5153 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.4873 - accuracy: 0.7823 - val_loss: 0.5291 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4876 - accuracy: 0.7721 - val_loss: 0.5209 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.4885 - accuracy: 0.7721 - val_loss: 0.5135 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.4840 - accuracy: 0.7755 - val_loss: 0.5277 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.4831 - accuracy: 0.8061 - val_loss: 0.5105 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.4818 - accuracy: 0.7857 - val_loss: 0.5050 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.4782 - accuracy: 0.7993 - val_loss: 0.5302 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4767 - accuracy: 0.7721 - val_loss: 0.5206 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.4742 - accuracy: 0.7891 - val_loss: 0.5176 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4749 - accuracy: 0.8129 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.4704 - accuracy: 0.7993 - val_loss: 0.5044 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4724 - accuracy: 0.7925 - val_loss: 0.5113 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.4683 - accuracy: 0.8027 - val_loss: 0.5098 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4661 - accuracy: 0.7925 - val_loss: 0.5133 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 232us/step - loss: 0.4659 - accuracy: 0.7789 - val_loss: 0.5088 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.4637 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.4630 - accuracy: 0.7993 - val_loss: 0.5080 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4606 - accuracy: 0.7925 - val_loss: 0.5006 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 469us/step - loss: 0.4595 - accuracy: 0.8061 - val_loss: 0.5071 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4587 - accuracy: 0.7993 - val_loss: 0.5001 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4572 - accuracy: 0.8163 - val_loss: 0.5053 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4549 - accuracy: 0.8163 - val_loss: 0.5007 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.4595 - accuracy: 0.8027 - val_loss: 0.5007 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.4571 - accuracy: 0.8061 - val_loss: 0.5056 - val_accuracy: 0.8269\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.4562 - accuracy: 0.8027 - val_loss: 0.4987 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 805us/step - loss: 0.4519 - accuracy: 0.8061 - val_loss: 0.5106 - val_accuracy: 0.8269\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.4477 - accuracy: 0.8197 - val_loss: 0.4933 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.4481 - accuracy: 0.8095 - val_loss: 0.4905 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 459us/step - loss: 0.4467 - accuracy: 0.8163 - val_loss: 0.4949 - val_accuracy: 0.8269\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4480 - accuracy: 0.8129 - val_loss: 0.5028 - val_accuracy: 0.8269\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4431 - accuracy: 0.8129 - val_loss: 0.4882 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4458 - accuracy: 0.8265 - val_loss: 0.4998 - val_accuracy: 0.8269\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.4416 - accuracy: 0.8231 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.4407 - accuracy: 0.8163 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.4400 - accuracy: 0.8163 - val_loss: 0.4842 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4411 - accuracy: 0.8299 - val_loss: 0.5054 - val_accuracy: 0.8077\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.4379 - accuracy: 0.8265 - val_loss: 0.4834 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4357 - accuracy: 0.8265 - val_loss: 0.4945 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4353 - accuracy: 0.8129 - val_loss: 0.4968 - val_accuracy: 0.8269\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.4317 - accuracy: 0.8299 - val_loss: 0.4869 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4323 - accuracy: 0.8333 - val_loss: 0.4852 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4313 - accuracy: 0.8231 - val_loss: 0.4946 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4350 - accuracy: 0.8095 - val_loss: 0.4876 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.4295 - accuracy: 0.8231 - val_loss: 0.4927 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4264 - accuracy: 0.8265 - val_loss: 0.4834 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4268 - accuracy: 0.8299 - val_loss: 0.4741 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.4265 - accuracy: 0.8333 - val_loss: 0.4878 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4281 - accuracy: 0.8231 - val_loss: 0.4912 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.4233 - accuracy: 0.8299 - val_loss: 0.4825 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.4254 - accuracy: 0.8333 - val_loss: 0.4982 - val_accuracy: 0.8077\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4241 - accuracy: 0.8333 - val_loss: 0.4869 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4202 - accuracy: 0.8401 - val_loss: 0.4878 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.4180 - accuracy: 0.8333 - val_loss: 0.4819 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 318us/step - loss: 0.4188 - accuracy: 0.8401 - val_loss: 0.4870 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4183 - accuracy: 0.8367 - val_loss: 0.4816 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4172 - accuracy: 0.8299 - val_loss: 0.4924 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 140us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.2925 - val_loss: 1.3393 - val_accuracy: 0.4038\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 1.2426 - accuracy: 0.4932 - val_loss: 1.1723 - val_accuracy: 0.6923\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 789us/step - loss: 1.1096 - accuracy: 0.5748 - val_loss: 1.0485 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.9987 - accuracy: 0.6633 - val_loss: 0.9413 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 818us/step - loss: 0.9145 - accuracy: 0.6973 - val_loss: 0.8603 - val_accuracy: 0.8077\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.8477 - accuracy: 0.7075 - val_loss: 0.7917 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.7957 - accuracy: 0.7211 - val_loss: 0.7520 - val_accuracy: 0.8462\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 0.7537 - accuracy: 0.7415 - val_loss: 0.7128 - val_accuracy: 0.8462\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.7219 - accuracy: 0.7517 - val_loss: 0.6819 - val_accuracy: 0.8462\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.6958 - accuracy: 0.7313 - val_loss: 0.6539 - val_accuracy: 0.8462\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.6726 - accuracy: 0.7245 - val_loss: 0.6328 - val_accuracy: 0.8462\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.6520 - accuracy: 0.7483 - val_loss: 0.6218 - val_accuracy: 0.8462\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.6398 - accuracy: 0.7381 - val_loss: 0.6078 - val_accuracy: 0.8462\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6258 - accuracy: 0.7551 - val_loss: 0.6069 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.6159 - accuracy: 0.7517 - val_loss: 0.5865 - val_accuracy: 0.8462\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.6022 - accuracy: 0.7585 - val_loss: 0.5896 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.5973 - accuracy: 0.7517 - val_loss: 0.5714 - val_accuracy: 0.8462\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.75 - 0s 436us/step - loss: 0.5883 - accuracy: 0.7551 - val_loss: 0.5773 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5807 - accuracy: 0.7449 - val_loss: 0.5777 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.5727 - accuracy: 0.7619 - val_loss: 0.5663 - val_accuracy: 0.8462\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5724 - accuracy: 0.7653 - val_loss: 0.5685 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.5630 - accuracy: 0.7619 - val_loss: 0.5783 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.5568 - accuracy: 0.7619 - val_loss: 0.5642 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5524 - accuracy: 0.7619 - val_loss: 0.5556 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 683us/step - loss: 0.5480 - accuracy: 0.7687 - val_loss: 0.5559 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.5429 - accuracy: 0.7687 - val_loss: 0.5668 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5390 - accuracy: 0.7687 - val_loss: 0.5535 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 470us/step - loss: 0.5383 - accuracy: 0.7551 - val_loss: 0.5574 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.5324 - accuracy: 0.7721 - val_loss: 0.5503 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.5300 - accuracy: 0.7687 - val_loss: 0.5456 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 997us/step - loss: 0.5285 - accuracy: 0.7721 - val_loss: 0.5583 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 989us/step - loss: 0.5250 - accuracy: 0.7687 - val_loss: 0.5412 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 689us/step - loss: 0.5234 - accuracy: 0.7721 - val_loss: 0.5388 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 588us/step - loss: 0.5172 - accuracy: 0.7857 - val_loss: 0.5446 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 656us/step - loss: 0.5159 - accuracy: 0.7789 - val_loss: 0.5413 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 892us/step - loss: 0.5166 - accuracy: 0.7823 - val_loss: 0.5299 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 829us/step - loss: 0.5107 - accuracy: 0.7823 - val_loss: 0.5437 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5101 - accuracy: 0.7789 - val_loss: 0.5375 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 631us/step - loss: 0.5078 - accuracy: 0.7891 - val_loss: 0.5361 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.5031 - accuracy: 0.7789 - val_loss: 0.5389 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 597us/step - loss: 0.5074 - accuracy: 0.7687 - val_loss: 0.5376 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 868us/step - loss: 0.5097 - accuracy: 0.7755 - val_loss: 0.5311 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 624us/step - loss: 0.4991 - accuracy: 0.7925 - val_loss: 0.5291 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.4982 - accuracy: 0.7823 - val_loss: 0.5267 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 642us/step - loss: 0.4954 - accuracy: 0.8027 - val_loss: 0.5309 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 576us/step - loss: 0.4941 - accuracy: 0.7823 - val_loss: 0.5254 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4935 - accuracy: 0.7789 - val_loss: 0.5388 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 372us/step - loss: 0.4908 - accuracy: 0.7857 - val_loss: 0.5201 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 723us/step - loss: 0.4883 - accuracy: 0.7857 - val_loss: 0.5216 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.4856 - accuracy: 0.7925 - val_loss: 0.5338 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4836 - accuracy: 0.7891 - val_loss: 0.5168 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4831 - accuracy: 0.8061 - val_loss: 0.5256 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.4856 - accuracy: 0.7925 - val_loss: 0.5158 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.4801 - accuracy: 0.8061 - val_loss: 0.5171 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4787 - accuracy: 0.8027 - val_loss: 0.5187 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.4785 - accuracy: 0.8027 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4776 - accuracy: 0.7959 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.4758 - accuracy: 0.8027 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.4717 - accuracy: 0.8095 - val_loss: 0.5166 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4716 - accuracy: 0.8061 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.4710 - accuracy: 0.7993 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.4682 - accuracy: 0.7959 - val_loss: 0.5197 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.4682 - accuracy: 0.8061 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.4668 - accuracy: 0.8027 - val_loss: 0.5157 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 482us/step - loss: 0.4646 - accuracy: 0.8061 - val_loss: 0.5117 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.4646 - accuracy: 0.8095 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.4638 - accuracy: 0.8129 - val_loss: 0.5045 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 615us/step - loss: 0.4616 - accuracy: 0.8095 - val_loss: 0.5198 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.4628 - accuracy: 0.8061 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4588 - accuracy: 0.7993 - val_loss: 0.5017 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4586 - accuracy: 0.8027 - val_loss: 0.5184 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.4584 - accuracy: 0.8061 - val_loss: 0.5097 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 480us/step - loss: 0.4567 - accuracy: 0.8163 - val_loss: 0.5032 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4529 - accuracy: 0.8129 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.4543 - accuracy: 0.8095 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4536 - accuracy: 0.8129 - val_loss: 0.5102 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4501 - accuracy: 0.8163 - val_loss: 0.4995 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.4494 - accuracy: 0.8163 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.4507 - accuracy: 0.8095 - val_loss: 0.5128 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 0.4485 - accuracy: 0.8197 - val_loss: 0.5073 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4483 - accuracy: 0.7993 - val_loss: 0.4966 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.4446 - accuracy: 0.8197 - val_loss: 0.4919 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4447 - accuracy: 0.8231 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 322us/step - loss: 0.4451 - accuracy: 0.8061 - val_loss: 0.5109 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4441 - accuracy: 0.8129 - val_loss: 0.4977 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4423 - accuracy: 0.8061 - val_loss: 0.5063 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 586us/step - loss: 0.4396 - accuracy: 0.8095 - val_loss: 0.5122 - val_accuracy: 0.8077\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.4401 - accuracy: 0.8333 - val_loss: 0.5107 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4362 - accuracy: 0.8231 - val_loss: 0.4977 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 425us/step - loss: 0.4389 - accuracy: 0.8163 - val_loss: 0.5001 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.4374 - accuracy: 0.8027 - val_loss: 0.5012 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.4351 - accuracy: 0.8197 - val_loss: 0.5018 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 253us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4522 - accuracy: 0.3469 - val_loss: 1.3665 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 1.2221 - accuracy: 0.4966 - val_loss: 1.1862 - val_accuracy: 0.5192\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 1.0864 - accuracy: 0.5952 - val_loss: 1.0595 - val_accuracy: 0.5962\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.9802 - accuracy: 0.6395 - val_loss: 0.9478 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.8966 - accuracy: 0.6633 - val_loss: 0.8682 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.8290 - accuracy: 0.7177 - val_loss: 0.7977 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.7816 - accuracy: 0.7381 - val_loss: 0.7479 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.7398 - accuracy: 0.7347 - val_loss: 0.7124 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.7049 - accuracy: 0.7483 - val_loss: 0.6903 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.6779 - accuracy: 0.7585 - val_loss: 0.6606 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.6590 - accuracy: 0.7619 - val_loss: 0.6448 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.6398 - accuracy: 0.7551 - val_loss: 0.6266 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.6227 - accuracy: 0.7551 - val_loss: 0.5987 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.6089 - accuracy: 0.7585 - val_loss: 0.5956 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.6029 - accuracy: 0.7687 - val_loss: 0.5932 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5901 - accuracy: 0.7619 - val_loss: 0.5722 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.5815 - accuracy: 0.7721 - val_loss: 0.5756 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 595us/step - loss: 0.5731 - accuracy: 0.7619 - val_loss: 0.5633 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 800us/step - loss: 0.5660 - accuracy: 0.7619 - val_loss: 0.5667 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5596 - accuracy: 0.7619 - val_loss: 0.5472 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 664us/step - loss: 0.5559 - accuracy: 0.7687 - val_loss: 0.5573 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 570us/step - loss: 0.5503 - accuracy: 0.7755 - val_loss: 0.5453 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 538us/step - loss: 0.5439 - accuracy: 0.7789 - val_loss: 0.5358 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5400 - accuracy: 0.7755 - val_loss: 0.5397 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.5357 - accuracy: 0.7653 - val_loss: 0.5496 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 440us/step - loss: 0.5325 - accuracy: 0.7721 - val_loss: 0.5349 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5285 - accuracy: 0.7721 - val_loss: 0.5297 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 666us/step - loss: 0.5245 - accuracy: 0.7755 - val_loss: 0.5307 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5207 - accuracy: 0.7755 - val_loss: 0.5376 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5178 - accuracy: 0.7755 - val_loss: 0.5278 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5164 - accuracy: 0.7755 - val_loss: 0.5304 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 689us/step - loss: 0.5163 - accuracy: 0.7823 - val_loss: 0.5261 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 0.5096 - accuracy: 0.7823 - val_loss: 0.5256 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 571us/step - loss: 0.5103 - accuracy: 0.7857 - val_loss: 0.5285 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.5049 - accuracy: 0.7891 - val_loss: 0.5278 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 682us/step - loss: 0.5030 - accuracy: 0.7891 - val_loss: 0.5208 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5005 - accuracy: 0.7959 - val_loss: 0.5259 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 624us/step - loss: 0.5002 - accuracy: 0.7721 - val_loss: 0.5139 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 743us/step - loss: 0.4960 - accuracy: 0.7857 - val_loss: 0.5242 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 875us/step - loss: 0.4935 - accuracy: 0.7959 - val_loss: 0.5114 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 827us/step - loss: 0.4945 - accuracy: 0.7857 - val_loss: 0.5164 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.4945 - accuracy: 0.7789 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 0.4884 - accuracy: 0.8027 - val_loss: 0.5056 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4898 - accuracy: 0.7925 - val_loss: 0.5131 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4833 - accuracy: 0.7925 - val_loss: 0.4975 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 243us/step - loss: 0.4847 - accuracy: 0.7993 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 515us/step - loss: 0.4812 - accuracy: 0.8027 - val_loss: 0.5225 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4788 - accuracy: 0.8061 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.4753 - accuracy: 0.8027 - val_loss: 0.5080 - val_accuracy: 0.8269\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4750 - accuracy: 0.8027 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.4719 - accuracy: 0.8095 - val_loss: 0.5199 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.4717 - accuracy: 0.8061 - val_loss: 0.5134 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.4687 - accuracy: 0.8061 - val_loss: 0.5053 - val_accuracy: 0.8269\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4668 - accuracy: 0.8197 - val_loss: 0.5038 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.4699 - accuracy: 0.8129 - val_loss: 0.4982 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 90us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4665 - accuracy: 0.2993 - val_loss: 1.2052 - val_accuracy: 0.4615\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 1.1893 - accuracy: 0.5204 - val_loss: 1.0567 - val_accuracy: 0.6538\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 1.0627 - accuracy: 0.6088 - val_loss: 0.9489 - val_accuracy: 0.6923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.9509 - accuracy: 0.7041 - val_loss: 0.8544 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.8724 - accuracy: 0.7279 - val_loss: 0.7840 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.8099 - accuracy: 0.7347 - val_loss: 0.7372 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.7624 - accuracy: 0.7551 - val_loss: 0.6956 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.7266 - accuracy: 0.7517 - val_loss: 0.6722 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.6985 - accuracy: 0.7551 - val_loss: 0.6470 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.6739 - accuracy: 0.7551 - val_loss: 0.6267 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.6572 - accuracy: 0.7619 - val_loss: 0.6245 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.6407 - accuracy: 0.7551 - val_loss: 0.5947 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.6287 - accuracy: 0.7585 - val_loss: 0.5939 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.6145 - accuracy: 0.7687 - val_loss: 0.5801 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 247us/step - loss: 0.6066 - accuracy: 0.7653 - val_loss: 0.5811 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 251us/step - loss: 0.5975 - accuracy: 0.7619 - val_loss: 0.5592 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5900 - accuracy: 0.7449 - val_loss: 0.5657 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5819 - accuracy: 0.7653 - val_loss: 0.5515 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.5755 - accuracy: 0.7619 - val_loss: 0.5533 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5718 - accuracy: 0.7551 - val_loss: 0.5499 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5647 - accuracy: 0.7551 - val_loss: 0.5483 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5576 - accuracy: 0.7687 - val_loss: 0.5396 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.5555 - accuracy: 0.7517 - val_loss: 0.5400 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5510 - accuracy: 0.7551 - val_loss: 0.5469 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5458 - accuracy: 0.7585 - val_loss: 0.5261 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.5460 - accuracy: 0.7653 - val_loss: 0.5238 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5393 - accuracy: 0.7585 - val_loss: 0.5392 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5365 - accuracy: 0.7585 - val_loss: 0.5275 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5309 - accuracy: 0.7619 - val_loss: 0.5170 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5330 - accuracy: 0.7653 - val_loss: 0.5332 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.5249 - accuracy: 0.7585 - val_loss: 0.5154 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 187us/step - loss: 0.5286 - accuracy: 0.7653 - val_loss: 0.5286 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5217 - accuracy: 0.7823 - val_loss: 0.5102 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.5182 - accuracy: 0.7687 - val_loss: 0.5196 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.5144 - accuracy: 0.7619 - val_loss: 0.5168 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.5159 - accuracy: 0.7687 - val_loss: 0.5216 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.5125 - accuracy: 0.7585 - val_loss: 0.5192 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.5115 - accuracy: 0.7653 - val_loss: 0.5183 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5065 - accuracy: 0.7721 - val_loss: 0.5148 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 611us/step - loss: 0.5055 - accuracy: 0.7721 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.4996 - accuracy: 0.7857 - val_loss: 0.5174 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.5027 - accuracy: 0.7653 - val_loss: 0.5054 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.4976 - accuracy: 0.7823 - val_loss: 0.5099 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.4983 - accuracy: 0.7755 - val_loss: 0.5156 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 427us/step - loss: 0.4924 - accuracy: 0.7721 - val_loss: 0.5052 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4911 - accuracy: 0.7925 - val_loss: 0.5074 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 509us/step - loss: 0.4936 - accuracy: 0.7755 - val_loss: 0.5055 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.4906 - accuracy: 0.7925 - val_loss: 0.5041 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.4878 - accuracy: 0.7925 - val_loss: 0.5033 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 451us/step - loss: 0.4835 - accuracy: 0.7891 - val_loss: 0.5108 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4872 - accuracy: 0.7925 - val_loss: 0.5140 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4825 - accuracy: 0.7959 - val_loss: 0.4959 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4826 - accuracy: 0.8061 - val_loss: 0.4975 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.4792 - accuracy: 0.7857 - val_loss: 0.5101 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 626us/step - loss: 0.4787 - accuracy: 0.7959 - val_loss: 0.4993 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.4755 - accuracy: 0.7993 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4760 - accuracy: 0.7993 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.4713 - accuracy: 0.8061 - val_loss: 0.5113 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.4704 - accuracy: 0.7891 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.4733 - accuracy: 0.7959 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.4654 - accuracy: 0.7993 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4659 - accuracy: 0.8197 - val_loss: 0.4978 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 332us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3477 - accuracy: 0.3776 - val_loss: 1.1212 - val_accuracy: 0.6538\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 691us/step - loss: 1.1171 - accuracy: 0.6259 - val_loss: 0.9980 - val_accuracy: 0.7308\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.9996 - accuracy: 0.7211 - val_loss: 0.8956 - val_accuracy: 0.8077\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.9150 - accuracy: 0.7211 - val_loss: 0.8225 - val_accuracy: 0.8269\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.8460 - accuracy: 0.7483 - val_loss: 0.7736 - val_accuracy: 0.8462\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.7928 - accuracy: 0.7551 - val_loss: 0.7243 - val_accuracy: 0.8462\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.7541 - accuracy: 0.7449 - val_loss: 0.6905 - val_accuracy: 0.8269\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.7198 - accuracy: 0.7449 - val_loss: 0.6715 - val_accuracy: 0.8269\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.6895 - accuracy: 0.7653 - val_loss: 0.6411 - val_accuracy: 0.8462\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.6698 - accuracy: 0.7551 - val_loss: 0.6335 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 545us/step - loss: 0.6526 - accuracy: 0.7551 - val_loss: 0.6132 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.6356 - accuracy: 0.7653 - val_loss: 0.6006 - val_accuracy: 0.8269\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6224 - accuracy: 0.7619 - val_loss: 0.5975 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 468us/step - loss: 0.6110 - accuracy: 0.7653 - val_loss: 0.5866 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6044 - accuracy: 0.7619 - val_loss: 0.5943 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5913 - accuracy: 0.7653 - val_loss: 0.5746 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.5877 - accuracy: 0.7619 - val_loss: 0.5722 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 567us/step - loss: 0.5804 - accuracy: 0.7619 - val_loss: 0.5697 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 527us/step - loss: 0.5759 - accuracy: 0.7619 - val_loss: 0.5545 - val_accuracy: 0.8462\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 0.5661 - accuracy: 0.7619 - val_loss: 0.5655 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.5599 - accuracy: 0.7687 - val_loss: 0.5634 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5565 - accuracy: 0.7449 - val_loss: 0.5583 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5499 - accuracy: 0.7517 - val_loss: 0.5498 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.5468 - accuracy: 0.7619 - val_loss: 0.5546 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 499us/step - loss: 0.5423 - accuracy: 0.7687 - val_loss: 0.5496 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 619us/step - loss: 0.5373 - accuracy: 0.7687 - val_loss: 0.5577 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.5358 - accuracy: 0.7653 - val_loss: 0.5474 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5307 - accuracy: 0.7653 - val_loss: 0.5428 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5302 - accuracy: 0.7585 - val_loss: 0.5416 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 801us/step - loss: 0.5221 - accuracy: 0.7721 - val_loss: 0.5405 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.5203 - accuracy: 0.7755 - val_loss: 0.5434 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 728us/step - loss: 0.5186 - accuracy: 0.7653 - val_loss: 0.5292 - val_accuracy: 0.8462\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 497us/step - loss: 0.5142 - accuracy: 0.7755 - val_loss: 0.5314 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 650us/step - loss: 0.5117 - accuracy: 0.7755 - val_loss: 0.5371 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 605us/step - loss: 0.5070 - accuracy: 0.7891 - val_loss: 0.5274 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.5113 - accuracy: 0.7653 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 773us/step - loss: 0.5046 - accuracy: 0.7891 - val_loss: 0.5282 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 437us/step - loss: 0.5014 - accuracy: 0.7823 - val_loss: 0.5365 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 724us/step - loss: 0.4985 - accuracy: 0.7789 - val_loss: 0.5326 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 609us/step - loss: 0.4970 - accuracy: 0.7959 - val_loss: 0.5286 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4932 - accuracy: 0.7959 - val_loss: 0.5388 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 704us/step - loss: 0.4968 - accuracy: 0.7823 - val_loss: 0.5324 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.4913 - accuracy: 0.7891 - val_loss: 0.5247 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4898 - accuracy: 0.7891 - val_loss: 0.5196 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 747us/step - loss: 0.4893 - accuracy: 0.7789 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 904us/step - loss: 0.4835 - accuracy: 0.7891 - val_loss: 0.5201 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 335us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4426 - accuracy: 0.3095 - val_loss: 1.3261 - val_accuracy: 0.3846\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 1.1885 - accuracy: 0.5204 - val_loss: 1.1625 - val_accuracy: 0.5385\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 646us/step - loss: 1.0388 - accuracy: 0.6259 - val_loss: 1.0284 - val_accuracy: 0.5769\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.9265 - accuracy: 0.6599 - val_loss: 0.9070 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.8409 - accuracy: 0.7075 - val_loss: 0.8252 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 798us/step - loss: 0.7796 - accuracy: 0.7211 - val_loss: 0.7631 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.7277 - accuracy: 0.7381 - val_loss: 0.7214 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 755us/step - loss: 0.6963 - accuracy: 0.7415 - val_loss: 0.6844 - val_accuracy: 0.8077\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 698us/step - loss: 0.6655 - accuracy: 0.7449 - val_loss: 0.6544 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 723us/step - loss: 0.6467 - accuracy: 0.7381 - val_loss: 0.6291 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 691us/step - loss: 0.6276 - accuracy: 0.7415 - val_loss: 0.6140 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.6147 - accuracy: 0.7653 - val_loss: 0.5939 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.6046 - accuracy: 0.7517 - val_loss: 0.5880 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.5941 - accuracy: 0.7585 - val_loss: 0.5768 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.5826 - accuracy: 0.7585 - val_loss: 0.5718 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5756 - accuracy: 0.7551 - val_loss: 0.5630 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5682 - accuracy: 0.7619 - val_loss: 0.5571 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.5627 - accuracy: 0.7653 - val_loss: 0.5513 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 753us/step - loss: 0.5561 - accuracy: 0.7653 - val_loss: 0.5514 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 746us/step - loss: 0.5531 - accuracy: 0.7619 - val_loss: 0.5392 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5485 - accuracy: 0.7551 - val_loss: 0.5396 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.5423 - accuracy: 0.7585 - val_loss: 0.5317 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.5383 - accuracy: 0.7653 - val_loss: 0.5353 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5352 - accuracy: 0.7653 - val_loss: 0.5330 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 550us/step - loss: 0.5351 - accuracy: 0.7619 - val_loss: 0.5283 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.5298 - accuracy: 0.7585 - val_loss: 0.5167 - val_accuracy: 0.8462\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.5300 - accuracy: 0.7687 - val_loss: 0.5316 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.5246 - accuracy: 0.7653 - val_loss: 0.5172 - val_accuracy: 0.8654\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.5184 - accuracy: 0.7619 - val_loss: 0.5204 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.5154 - accuracy: 0.7687 - val_loss: 0.5165 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5132 - accuracy: 0.7687 - val_loss: 0.5169 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5094 - accuracy: 0.7755 - val_loss: 0.5185 - val_accuracy: 0.8654\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.5071 - accuracy: 0.7721 - val_loss: 0.5150 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 736us/step - loss: 0.5074 - accuracy: 0.7857 - val_loss: 0.5129 - val_accuracy: 0.8654\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 531us/step - loss: 0.5029 - accuracy: 0.7721 - val_loss: 0.5217 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.5051 - accuracy: 0.7789 - val_loss: 0.5098 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7857 - val_loss: 0.5022 - val_accuracy: 0.8654\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 727us/step - loss: 0.4964 - accuracy: 0.7789 - val_loss: 0.5077 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7823 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.4913 - accuracy: 0.7891 - val_loss: 0.5117 - val_accuracy: 0.8654\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 743us/step - loss: 0.4914 - accuracy: 0.7857 - val_loss: 0.5109 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4896 - accuracy: 0.7755 - val_loss: 0.5009 - val_accuracy: 0.8654\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 605us/step - loss: 0.4860 - accuracy: 0.7823 - val_loss: 0.5102 - val_accuracy: 0.8654\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.4840 - accuracy: 0.7789 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.4828 - accuracy: 0.7959 - val_loss: 0.5033 - val_accuracy: 0.8654\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4799 - accuracy: 0.8027 - val_loss: 0.4991 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 0.4774 - accuracy: 0.7959 - val_loss: 0.5082 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4772 - accuracy: 0.7891 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 338us/step - loss: 0.4760 - accuracy: 0.7959 - val_loss: 0.5015 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 336us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4367 - accuracy: 0.2823 - val_loss: 1.2823 - val_accuracy: 0.4423\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 1.1392 - accuracy: 0.5272 - val_loss: 1.1035 - val_accuracy: 0.5577\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 1.0056 - accuracy: 0.6429 - val_loss: 0.9762 - val_accuracy: 0.6154\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.9030 - accuracy: 0.6871 - val_loss: 0.8830 - val_accuracy: 0.6923\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.8298 - accuracy: 0.7075 - val_loss: 0.8138 - val_accuracy: 0.7115\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.7743 - accuracy: 0.7245 - val_loss: 0.7678 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.7323 - accuracy: 0.7245 - val_loss: 0.7137 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.7028 - accuracy: 0.7381 - val_loss: 0.6865 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.6769 - accuracy: 0.7381 - val_loss: 0.6649 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 398us/step - loss: 0.6577 - accuracy: 0.7415 - val_loss: 0.6470 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.6397 - accuracy: 0.7347 - val_loss: 0.6177 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.6246 - accuracy: 0.7449 - val_loss: 0.6119 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 201us/step - loss: 0.6130 - accuracy: 0.7619 - val_loss: 0.6010 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 207us/step - loss: 0.6026 - accuracy: 0.7483 - val_loss: 0.5891 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 250us/step - loss: 0.5969 - accuracy: 0.7449 - val_loss: 0.5833 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 0.5880 - accuracy: 0.7517 - val_loss: 0.5799 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5802 - accuracy: 0.7585 - val_loss: 0.5630 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5725 - accuracy: 0.7517 - val_loss: 0.5588 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5649 - accuracy: 0.7483 - val_loss: 0.5564 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.5640 - accuracy: 0.7517 - val_loss: 0.5525 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5580 - accuracy: 0.7687 - val_loss: 0.5359 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 416us/step - loss: 0.5503 - accuracy: 0.7687 - val_loss: 0.5510 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.5480 - accuracy: 0.7653 - val_loss: 0.5493 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 619us/step - loss: 0.5450 - accuracy: 0.7653 - val_loss: 0.5298 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.5529 - accuracy: 0.7619 - val_loss: 0.5455 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5344 - accuracy: 0.7653 - val_loss: 0.5278 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.5328 - accuracy: 0.7585 - val_loss: 0.5255 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.5276 - accuracy: 0.7755 - val_loss: 0.5233 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5263 - accuracy: 0.7687 - val_loss: 0.5231 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5222 - accuracy: 0.7687 - val_loss: 0.5196 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.5228 - accuracy: 0.7721 - val_loss: 0.5274 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5163 - accuracy: 0.7721 - val_loss: 0.5246 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5145 - accuracy: 0.7789 - val_loss: 0.5160 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5110 - accuracy: 0.7789 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5095 - accuracy: 0.7823 - val_loss: 0.5187 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5071 - accuracy: 0.7823 - val_loss: 0.5153 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5065 - accuracy: 0.7823 - val_loss: 0.5097 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5017 - accuracy: 0.7755 - val_loss: 0.5010 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.5035 - accuracy: 0.7789 - val_loss: 0.5060 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 725us/step - loss: 0.4979 - accuracy: 0.7789 - val_loss: 0.5149 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.4979 - accuracy: 0.7823 - val_loss: 0.5097 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 553us/step - loss: 0.4963 - accuracy: 0.7789 - val_loss: 0.5058 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 0.4910 - accuracy: 0.7823 - val_loss: 0.4996 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 455us/step - loss: 0.4911 - accuracy: 0.7721 - val_loss: 0.5037 - val_accuracy: 0.8077\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.4880 - accuracy: 0.7993 - val_loss: 0.4893 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.4867 - accuracy: 0.7891 - val_loss: 0.5023 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.4834 - accuracy: 0.7993 - val_loss: 0.4949 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4828 - accuracy: 0.8027 - val_loss: 0.4945 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.4822 - accuracy: 0.7857 - val_loss: 0.5052 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.4816 - accuracy: 0.7925 - val_loss: 0.4899 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4788 - accuracy: 0.7959 - val_loss: 0.4979 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.4761 - accuracy: 0.8027 - val_loss: 0.4873 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 741us/step - loss: 0.4725 - accuracy: 0.7959 - val_loss: 0.4955 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 485us/step - loss: 0.4717 - accuracy: 0.8027 - val_loss: 0.5048 - val_accuracy: 0.8077\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 405us/step - loss: 0.4694 - accuracy: 0.7993 - val_loss: 0.4881 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.4767 - accuracy: 0.7857 - val_loss: 0.4805 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.4693 - accuracy: 0.8061 - val_loss: 0.4935 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4651 - accuracy: 0.8095 - val_loss: 0.4845 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4650 - accuracy: 0.8061 - val_loss: 0.4998 - val_accuracy: 0.8077\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 820us/step - loss: 0.4616 - accuracy: 0.8095 - val_loss: 0.4846 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.4617 - accuracy: 0.8197 - val_loss: 0.4828 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.4583 - accuracy: 0.8163 - val_loss: 0.4773 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 250us/step - loss: 0.4565 - accuracy: 0.8163 - val_loss: 0.4708 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 256us/step - loss: 0.4579 - accuracy: 0.8061 - val_loss: 0.4879 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4583 - accuracy: 0.8129 - val_loss: 0.4760 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 199us/step - loss: 0.4553 - accuracy: 0.8061 - val_loss: 0.4778 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 245us/step - loss: 0.4528 - accuracy: 0.8095 - val_loss: 0.4697 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4503 - accuracy: 0.8231 - val_loss: 0.4856 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4483 - accuracy: 0.8231 - val_loss: 0.4703 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4510 - accuracy: 0.8129 - val_loss: 0.4796 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 317us/step - loss: 0.4486 - accuracy: 0.8163 - val_loss: 0.4689 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4462 - accuracy: 0.8265 - val_loss: 0.4748 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4471 - accuracy: 0.8265 - val_loss: 0.4607 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 0.4438 - accuracy: 0.8061 - val_loss: 0.4869 - val_accuracy: 0.8269\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 702us/step - loss: 0.4374 - accuracy: 0.8265 - val_loss: 0.4630 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.4406 - accuracy: 0.8333 - val_loss: 0.4725 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 506us/step - loss: 0.4387 - accuracy: 0.8129 - val_loss: 0.4682 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4364 - accuracy: 0.8265 - val_loss: 0.4755 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.4355 - accuracy: 0.8299 - val_loss: 0.4758 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.4343 - accuracy: 0.8231 - val_loss: 0.4690 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4314 - accuracy: 0.8197 - val_loss: 0.4658 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.4313 - accuracy: 0.8197 - val_loss: 0.4623 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.4319 - accuracy: 0.8265 - val_loss: 0.4656 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 107us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.6405 - accuracy: 0.2279 - val_loss: 1.4049 - val_accuracy: 0.2500\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 1.3000 - accuracy: 0.3537 - val_loss: 1.2223 - val_accuracy: 0.4423\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 1.1253 - accuracy: 0.5816 - val_loss: 1.0730 - val_accuracy: 0.5769\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 640us/step - loss: 1.0092 - accuracy: 0.6633 - val_loss: 0.9615 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 740us/step - loss: 0.9165 - accuracy: 0.7109 - val_loss: 0.8783 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 613us/step - loss: 0.8464 - accuracy: 0.7041 - val_loss: 0.8066 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 630us/step - loss: 0.7928 - accuracy: 0.7279 - val_loss: 0.7649 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.7510 - accuracy: 0.7245 - val_loss: 0.7220 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 522us/step - loss: 0.7200 - accuracy: 0.7381 - val_loss: 0.6920 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.6925 - accuracy: 0.7381 - val_loss: 0.6656 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.6746 - accuracy: 0.7551 - val_loss: 0.6482 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.6560 - accuracy: 0.7449 - val_loss: 0.6327 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.6393 - accuracy: 0.7551 - val_loss: 0.6155 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.6300 - accuracy: 0.7381 - val_loss: 0.6107 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.6124 - accuracy: 0.7585 - val_loss: 0.6036 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.6048 - accuracy: 0.7585 - val_loss: 0.5893 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5963 - accuracy: 0.7653 - val_loss: 0.5840 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5899 - accuracy: 0.7585 - val_loss: 0.5835 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 286us/step - loss: 0.5783 - accuracy: 0.7551 - val_loss: 0.5683 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5762 - accuracy: 0.7517 - val_loss: 0.5688 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5686 - accuracy: 0.7721 - val_loss: 0.5647 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 555us/step - loss: 0.5625 - accuracy: 0.7585 - val_loss: 0.5655 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5583 - accuracy: 0.7517 - val_loss: 0.5594 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 200us/step - loss: 0.5564 - accuracy: 0.7585 - val_loss: 0.5615 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 253us/step - loss: 0.5508 - accuracy: 0.7721 - val_loss: 0.5598 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 199us/step - loss: 0.5443 - accuracy: 0.7517 - val_loss: 0.5478 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 332us/step - loss: 0.5463 - accuracy: 0.7483 - val_loss: 0.5474 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 530us/step - loss: 0.5380 - accuracy: 0.7687 - val_loss: 0.5447 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.5335 - accuracy: 0.7551 - val_loss: 0.5600 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.5323 - accuracy: 0.7619 - val_loss: 0.5435 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5291 - accuracy: 0.7687 - val_loss: 0.5468 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.5232 - accuracy: 0.7619 - val_loss: 0.5448 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5201 - accuracy: 0.7585 - val_loss: 0.5477 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5170 - accuracy: 0.7619 - val_loss: 0.5433 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.5156 - accuracy: 0.7585 - val_loss: 0.5438 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.5143 - accuracy: 0.7653 - val_loss: 0.5291 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.5102 - accuracy: 0.7789 - val_loss: 0.5337 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5074 - accuracy: 0.7619 - val_loss: 0.5388 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.5058 - accuracy: 0.7789 - val_loss: 0.5211 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5018 - accuracy: 0.7687 - val_loss: 0.5258 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 460us/step - loss: 0.4986 - accuracy: 0.7619 - val_loss: 0.5299 - val_accuracy: 0.8077\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.4997 - accuracy: 0.7653 - val_loss: 0.5310 - val_accuracy: 0.8077\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4973 - accuracy: 0.7789 - val_loss: 0.5290 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.4929 - accuracy: 0.7721 - val_loss: 0.5140 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.4938 - accuracy: 0.7857 - val_loss: 0.5276 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4894 - accuracy: 0.7721 - val_loss: 0.5312 - val_accuracy: 0.8077\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.4890 - accuracy: 0.7755 - val_loss: 0.5273 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4882 - accuracy: 0.7755 - val_loss: 0.5356 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4829 - accuracy: 0.7857 - val_loss: 0.5202 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.4848 - accuracy: 0.7891 - val_loss: 0.5249 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4800 - accuracy: 0.7857 - val_loss: 0.5258 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4766 - accuracy: 0.7857 - val_loss: 0.5215 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.4775 - accuracy: 0.7789 - val_loss: 0.5197 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.4746 - accuracy: 0.7857 - val_loss: 0.5203 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 108us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4124 - accuracy: 0.3367 - val_loss: 1.2516 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 1.1328 - accuracy: 0.5238 - val_loss: 1.1150 - val_accuracy: 0.6346\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.9969 - accuracy: 0.6463 - val_loss: 0.9773 - val_accuracy: 0.6346\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.9049 - accuracy: 0.6871 - val_loss: 0.8800 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.8344 - accuracy: 0.7007 - val_loss: 0.8187 - val_accuracy: 0.7308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 254us/step - loss: 0.7781 - accuracy: 0.7143 - val_loss: 0.7662 - val_accuracy: 0.7308\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.7403 - accuracy: 0.7313 - val_loss: 0.7282 - val_accuracy: 0.7500\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.7048 - accuracy: 0.7347 - val_loss: 0.6967 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.6828 - accuracy: 0.7415 - val_loss: 0.6728 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.6615 - accuracy: 0.7347 - val_loss: 0.6529 - val_accuracy: 0.7692\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.6413 - accuracy: 0.7551 - val_loss: 0.6369 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.6312 - accuracy: 0.7449 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.6131 - accuracy: 0.7449 - val_loss: 0.6122 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 431us/step - loss: 0.6014 - accuracy: 0.7517 - val_loss: 0.5904 - val_accuracy: 0.7692\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5974 - accuracy: 0.7483 - val_loss: 0.5857 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.5873 - accuracy: 0.7517 - val_loss: 0.5931 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.5783 - accuracy: 0.7619 - val_loss: 0.5705 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.5722 - accuracy: 0.7619 - val_loss: 0.5625 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5667 - accuracy: 0.7551 - val_loss: 0.5585 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.5662 - accuracy: 0.7619 - val_loss: 0.5646 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.5617 - accuracy: 0.7789 - val_loss: 0.5512 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5539 - accuracy: 0.7585 - val_loss: 0.5451 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5485 - accuracy: 0.7551 - val_loss: 0.5485 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 262us/step - loss: 0.5457 - accuracy: 0.7585 - val_loss: 0.5516 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.5415 - accuracy: 0.7585 - val_loss: 0.5451 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5389 - accuracy: 0.7551 - val_loss: 0.5432 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.5343 - accuracy: 0.7517 - val_loss: 0.5394 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 358us/step - loss: 0.5325 - accuracy: 0.7653 - val_loss: 0.5330 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.5321 - accuracy: 0.7517 - val_loss: 0.5265 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 260us/step - loss: 0.5336 - accuracy: 0.7619 - val_loss: 0.5424 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5247 - accuracy: 0.7789 - val_loss: 0.5245 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5275 - accuracy: 0.7585 - val_loss: 0.5329 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5223 - accuracy: 0.7755 - val_loss: 0.5303 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.5186 - accuracy: 0.7585 - val_loss: 0.5248 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5151 - accuracy: 0.7823 - val_loss: 0.5273 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5125 - accuracy: 0.7687 - val_loss: 0.5154 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.5110 - accuracy: 0.7857 - val_loss: 0.5214 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5077 - accuracy: 0.7789 - val_loss: 0.5237 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.5066 - accuracy: 0.7755 - val_loss: 0.5293 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5078 - accuracy: 0.7891 - val_loss: 0.5037 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.5089 - accuracy: 0.7653 - val_loss: 0.5156 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.5036 - accuracy: 0.7823 - val_loss: 0.5292 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 279us/step - loss: 0.5074 - accuracy: 0.7823 - val_loss: 0.5226 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.5013 - accuracy: 0.7755 - val_loss: 0.5244 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.4966 - accuracy: 0.7857 - val_loss: 0.5158 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.4971 - accuracy: 0.7721 - val_loss: 0.5192 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4974 - accuracy: 0.7857 - val_loss: 0.5218 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 266us/step - loss: 0.4946 - accuracy: 0.7789 - val_loss: 0.5193 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.4932 - accuracy: 0.7925 - val_loss: 0.5160 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.4901 - accuracy: 0.7857 - val_loss: 0.5203 - val_accuracy: 0.8269\n",
      "116/116 [==============================] - 0s 100us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4136 - accuracy: 0.2653 - val_loss: 1.2911 - val_accuracy: 0.4615\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 1.2056 - accuracy: 0.5272 - val_loss: 1.0972 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 1.0578 - accuracy: 0.6735 - val_loss: 0.9808 - val_accuracy: 0.7308\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.9514 - accuracy: 0.7109 - val_loss: 0.8697 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.8583 - accuracy: 0.7449 - val_loss: 0.7935 - val_accuracy: 0.7500\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 292us/step - loss: 0.7917 - accuracy: 0.7585 - val_loss: 0.7295 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.7422 - accuracy: 0.7619 - val_loss: 0.6921 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.6998 - accuracy: 0.7551 - val_loss: 0.6530 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6737 - accuracy: 0.7551 - val_loss: 0.6293 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.6503 - accuracy: 0.7551 - val_loss: 0.6058 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 275us/step - loss: 0.6319 - accuracy: 0.7619 - val_loss: 0.5891 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 271us/step - loss: 0.6244 - accuracy: 0.7585 - val_loss: 0.6063 - val_accuracy: 0.7885\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.6001 - accuracy: 0.7721 - val_loss: 0.5651 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 270us/step - loss: 0.5925 - accuracy: 0.7755 - val_loss: 0.5611 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.5849 - accuracy: 0.7653 - val_loss: 0.5808 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.5753 - accuracy: 0.7687 - val_loss: 0.5568 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 269us/step - loss: 0.5671 - accuracy: 0.7585 - val_loss: 0.5577 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.5613 - accuracy: 0.7687 - val_loss: 0.5490 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5537 - accuracy: 0.7687 - val_loss: 0.5501 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5506 - accuracy: 0.7653 - val_loss: 0.5502 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 267us/step - loss: 0.5492 - accuracy: 0.7653 - val_loss: 0.5463 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5434 - accuracy: 0.7755 - val_loss: 0.5440 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.5395 - accuracy: 0.7619 - val_loss: 0.5445 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 0.5338 - accuracy: 0.7551 - val_loss: 0.5236 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.5278 - accuracy: 0.7721 - val_loss: 0.5313 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.5275 - accuracy: 0.7653 - val_loss: 0.5257 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.5220 - accuracy: 0.7755 - val_loss: 0.5356 - val_accuracy: 0.8077\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5197 - accuracy: 0.7653 - val_loss: 0.5230 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 0.5188 - accuracy: 0.7721 - val_loss: 0.5145 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5150 - accuracy: 0.7619 - val_loss: 0.5211 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.5128 - accuracy: 0.7755 - val_loss: 0.5144 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5106 - accuracy: 0.7721 - val_loss: 0.5183 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 262us/step - loss: 0.5066 - accuracy: 0.7551 - val_loss: 0.5178 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5054 - accuracy: 0.7687 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.5064 - accuracy: 0.7823 - val_loss: 0.5141 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 276us/step - loss: 0.4977 - accuracy: 0.7653 - val_loss: 0.5019 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.4962 - accuracy: 0.7687 - val_loss: 0.5069 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4916 - accuracy: 0.7755 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 256us/step - loss: 0.4912 - accuracy: 0.7653 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 257us/step - loss: 0.4883 - accuracy: 0.7755 - val_loss: 0.5147 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 265us/step - loss: 0.4863 - accuracy: 0.7687 - val_loss: 0.5152 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 264us/step - loss: 0.4866 - accuracy: 0.7653 - val_loss: 0.5040 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 261us/step - loss: 0.4810 - accuracy: 0.7823 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 263us/step - loss: 0.4810 - accuracy: 0.7823 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.4791 - accuracy: 0.7687 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.4761 - accuracy: 0.7857 - val_loss: 0.5030 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4753 - accuracy: 0.7891 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.4731 - accuracy: 0.7823 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 304us/step - loss: 0.4717 - accuracy: 0.7857 - val_loss: 0.5101 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4701 - accuracy: 0.7755 - val_loss: 0.5016 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 268us/step - loss: 0.4669 - accuracy: 0.7993 - val_loss: 0.4902 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.4657 - accuracy: 0.7959 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4692 - accuracy: 0.7925 - val_loss: 0.5031 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.4636 - accuracy: 0.8027 - val_loss: 0.4935 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4610 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.4583 - accuracy: 0.7993 - val_loss: 0.4899 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 328us/step - loss: 0.4595 - accuracy: 0.8027 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.4597 - accuracy: 0.7925 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.4548 - accuracy: 0.8061 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.4528 - accuracy: 0.8231 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 255us/step - loss: 0.4535 - accuracy: 0.8061 - val_loss: 0.4850 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.4524 - accuracy: 0.8027 - val_loss: 0.4935 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4475 - accuracy: 0.7993 - val_loss: 0.5014 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4566 - accuracy: 0.8163 - val_loss: 0.4824 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4533 - accuracy: 0.7959 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.4443 - accuracy: 0.8333 - val_loss: 0.4868 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4440 - accuracy: 0.8299 - val_loss: 0.5038 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.4460 - accuracy: 0.8231 - val_loss: 0.5016 - val_accuracy: 0.8077\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.4420 - accuracy: 0.8197 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.4396 - accuracy: 0.8197 - val_loss: 0.5098 - val_accuracy: 0.8269\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.4402 - accuracy: 0.8163 - val_loss: 0.5005 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4389 - accuracy: 0.8129 - val_loss: 0.4969 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.4339 - accuracy: 0.8367 - val_loss: 0.5039 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 273us/step - loss: 0.4357 - accuracy: 0.8061 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 110us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3033 - accuracy: 0.3946 - val_loss: 1.1187 - val_accuracy: 0.6346\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 1.0946 - accuracy: 0.6088 - val_loss: 0.9745 - val_accuracy: 0.6731\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.9726 - accuracy: 0.6599 - val_loss: 0.8664 - val_accuracy: 0.7692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.8808 - accuracy: 0.7279 - val_loss: 0.8066 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.8145 - accuracy: 0.7211 - val_loss: 0.7439 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 287us/step - loss: 0.7675 - accuracy: 0.7551 - val_loss: 0.7004 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.7261 - accuracy: 0.7449 - val_loss: 0.6739 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.6937 - accuracy: 0.7517 - val_loss: 0.6526 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.6716 - accuracy: 0.7449 - val_loss: 0.6254 - val_accuracy: 0.8269\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.6492 - accuracy: 0.7585 - val_loss: 0.6226 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 282us/step - loss: 0.6336 - accuracy: 0.7551 - val_loss: 0.6006 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.6207 - accuracy: 0.7653 - val_loss: 0.5942 - val_accuracy: 0.8269\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.6149 - accuracy: 0.7585 - val_loss: 0.5748 - val_accuracy: 0.8269\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 283us/step - loss: 0.6026 - accuracy: 0.7551 - val_loss: 0.5786 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.5933 - accuracy: 0.7449 - val_loss: 0.5724 - val_accuracy: 0.8269\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5843 - accuracy: 0.7483 - val_loss: 0.5743 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 526us/step - loss: 0.5771 - accuracy: 0.7551 - val_loss: 0.5577 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5694 - accuracy: 0.7585 - val_loss: 0.5497 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5663 - accuracy: 0.7585 - val_loss: 0.5535 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.5616 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 687us/step - loss: 0.5552 - accuracy: 0.7517 - val_loss: 0.5496 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 540us/step - loss: 0.5600 - accuracy: 0.7551 - val_loss: 0.5492 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.5472 - accuracy: 0.7517 - val_loss: 0.5642 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.5379 - accuracy: 0.7551 - val_loss: 0.5370 - val_accuracy: 0.8462\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5375 - accuracy: 0.7619 - val_loss: 0.5347 - val_accuracy: 0.8462\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 474us/step - loss: 0.5339 - accuracy: 0.7653 - val_loss: 0.5434 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.5320 - accuracy: 0.7619 - val_loss: 0.5365 - val_accuracy: 0.8462\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.5287 - accuracy: 0.7653 - val_loss: 0.5379 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.5245 - accuracy: 0.7619 - val_loss: 0.5401 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.5226 - accuracy: 0.7653 - val_loss: 0.5301 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.5231 - accuracy: 0.7823 - val_loss: 0.5230 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.5176 - accuracy: 0.7585 - val_loss: 0.5327 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5145 - accuracy: 0.7687 - val_loss: 0.5350 - val_accuracy: 0.8269\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5118 - accuracy: 0.7653 - val_loss: 0.5263 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5134 - accuracy: 0.7755 - val_loss: 0.5254 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5099 - accuracy: 0.7789 - val_loss: 0.5203 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.5041 - accuracy: 0.7619 - val_loss: 0.5379 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.5019 - accuracy: 0.7653 - val_loss: 0.5222 - val_accuracy: 0.8269\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5000 - accuracy: 0.7789 - val_loss: 0.5225 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.4999 - accuracy: 0.7721 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.4990 - accuracy: 0.7823 - val_loss: 0.5175 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.4939 - accuracy: 0.7755 - val_loss: 0.5216 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4924 - accuracy: 0.7755 - val_loss: 0.5264 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.4906 - accuracy: 0.7823 - val_loss: 0.5258 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.78 - 0s 344us/step - loss: 0.4898 - accuracy: 0.7857 - val_loss: 0.5138 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.4873 - accuracy: 0.7823 - val_loss: 0.5132 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4857 - accuracy: 0.7789 - val_loss: 0.5205 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.4861 - accuracy: 0.7789 - val_loss: 0.5219 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.4828 - accuracy: 0.7823 - val_loss: 0.5148 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 486us/step - loss: 0.4808 - accuracy: 0.7891 - val_loss: 0.5046 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4791 - accuracy: 0.7857 - val_loss: 0.5160 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.4767 - accuracy: 0.7993 - val_loss: 0.5175 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 343us/step - loss: 0.4750 - accuracy: 0.7823 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.4746 - accuracy: 0.7857 - val_loss: 0.5087 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.4714 - accuracy: 0.8027 - val_loss: 0.5151 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 466us/step - loss: 0.4707 - accuracy: 0.7925 - val_loss: 0.5106 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 794us/step - loss: 0.4694 - accuracy: 0.8027 - val_loss: 0.5094 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.4686 - accuracy: 0.7959 - val_loss: 0.5109 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.4699 - accuracy: 0.7925 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.4699 - accuracy: 0.7993 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 140us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.3095 - accuracy: 0.3367 - val_loss: 1.1361 - val_accuracy: 0.5192\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 1.1046 - accuracy: 0.6054 - val_loss: 1.0000 - val_accuracy: 0.6346\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.9717 - accuracy: 0.6667 - val_loss: 0.8782 - val_accuracy: 0.7692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 695us/step - loss: 0.8677 - accuracy: 0.7143 - val_loss: 0.7950 - val_accuracy: 0.7692\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.7942 - accuracy: 0.7075 - val_loss: 0.7331 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.7362 - accuracy: 0.7517 - val_loss: 0.6913 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 665us/step - loss: 0.6970 - accuracy: 0.7551 - val_loss: 0.6520 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 777us/step - loss: 0.6681 - accuracy: 0.7585 - val_loss: 0.6264 - val_accuracy: 0.8077\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 725us/step - loss: 0.6481 - accuracy: 0.7585 - val_loss: 0.6101 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 518us/step - loss: 0.6249 - accuracy: 0.7483 - val_loss: 0.6029 - val_accuracy: 0.8269\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.6118 - accuracy: 0.7585 - val_loss: 0.5833 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.6018 - accuracy: 0.7449 - val_loss: 0.5834 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.5910 - accuracy: 0.7585 - val_loss: 0.5732 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.5812 - accuracy: 0.7687 - val_loss: 0.5566 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5732 - accuracy: 0.7721 - val_loss: 0.5628 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 741us/step - loss: 0.5658 - accuracy: 0.7551 - val_loss: 0.5565 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 612us/step - loss: 0.5602 - accuracy: 0.7789 - val_loss: 0.5469 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.5523 - accuracy: 0.7789 - val_loss: 0.5428 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.5519 - accuracy: 0.7721 - val_loss: 0.5370 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 666us/step - loss: 0.5489 - accuracy: 0.7755 - val_loss: 0.5419 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 584us/step - loss: 0.5420 - accuracy: 0.7551 - val_loss: 0.5361 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.5369 - accuracy: 0.7687 - val_loss: 0.5326 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.5316 - accuracy: 0.7687 - val_loss: 0.5355 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.5306 - accuracy: 0.7653 - val_loss: 0.5319 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 428us/step - loss: 0.5276 - accuracy: 0.7687 - val_loss: 0.5131 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 345us/step - loss: 0.5287 - accuracy: 0.7687 - val_loss: 0.5284 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5222 - accuracy: 0.7755 - val_loss: 0.5209 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.5197 - accuracy: 0.7619 - val_loss: 0.5236 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.5155 - accuracy: 0.7721 - val_loss: 0.5231 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 752us/step - loss: 0.5153 - accuracy: 0.7585 - val_loss: 0.5259 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 757us/step - loss: 0.5124 - accuracy: 0.7721 - val_loss: 0.5268 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5098 - accuracy: 0.7755 - val_loss: 0.5161 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.5086 - accuracy: 0.7789 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.5050 - accuracy: 0.7721 - val_loss: 0.5261 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 419us/step - loss: 0.5037 - accuracy: 0.7755 - val_loss: 0.5177 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5001 - accuracy: 0.7755 - val_loss: 0.5231 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.4968 - accuracy: 0.7789 - val_loss: 0.5086 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.5006 - accuracy: 0.7823 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4922 - accuracy: 0.7857 - val_loss: 0.5103 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 417us/step - loss: 0.4928 - accuracy: 0.7789 - val_loss: 0.5127 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4895 - accuracy: 0.7857 - val_loss: 0.4987 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 547us/step - loss: 0.4885 - accuracy: 0.7891 - val_loss: 0.5107 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4874 - accuracy: 0.7925 - val_loss: 0.5013 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.4842 - accuracy: 0.7891 - val_loss: 0.5097 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4830 - accuracy: 0.7789 - val_loss: 0.4922 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 533us/step - loss: 0.4803 - accuracy: 0.7857 - val_loss: 0.4910 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 654us/step - loss: 0.4819 - accuracy: 0.7823 - val_loss: 0.4989 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.4767 - accuracy: 0.7823 - val_loss: 0.4839 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 797us/step - loss: 0.4777 - accuracy: 0.7823 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4759 - accuracy: 0.7891 - val_loss: 0.5085 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.4759 - accuracy: 0.7925 - val_loss: 0.4825 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 604us/step - loss: 0.4759 - accuracy: 0.7823 - val_loss: 0.4956 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 509us/step - loss: 0.4717 - accuracy: 0.7857 - val_loss: 0.5000 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.4672 - accuracy: 0.7857 - val_loss: 0.4846 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.4686 - accuracy: 0.7857 - val_loss: 0.4887 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 625us/step - loss: 0.4683 - accuracy: 0.7993 - val_loss: 0.4847 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 411us/step - loss: 0.4669 - accuracy: 0.7857 - val_loss: 0.4970 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.4620 - accuracy: 0.7925 - val_loss: 0.4828 - val_accuracy: 0.8462\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4651 - accuracy: 0.7755 - val_loss: 0.4899 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.4606 - accuracy: 0.8095 - val_loss: 0.4848 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.4608 - accuracy: 0.7925 - val_loss: 0.4825 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 639us/step - loss: 0.4573 - accuracy: 0.8027 - val_loss: 0.4965 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.4559 - accuracy: 0.7891 - val_loss: 0.4828 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.4574 - accuracy: 0.7993 - val_loss: 0.4811 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 494us/step - loss: 0.4547 - accuracy: 0.8061 - val_loss: 0.4812 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 647us/step - loss: 0.4507 - accuracy: 0.8061 - val_loss: 0.4894 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.4553 - accuracy: 0.8027 - val_loss: 0.4782 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 729us/step - loss: 0.4510 - accuracy: 0.8095 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.4476 - accuracy: 0.8095 - val_loss: 0.4751 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 285us/step - loss: 0.4454 - accuracy: 0.8095 - val_loss: 0.4807 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.4467 - accuracy: 0.8061 - val_loss: 0.4753 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 470us/step - loss: 0.4472 - accuracy: 0.8163 - val_loss: 0.4786 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.4515 - accuracy: 0.8129 - val_loss: 0.4733 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.4482 - accuracy: 0.8095 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.4427 - accuracy: 0.8163 - val_loss: 0.4768 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 0.4396 - accuracy: 0.8095 - val_loss: 0.4840 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.4418 - accuracy: 0.8061 - val_loss: 0.4930 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.4378 - accuracy: 0.8061 - val_loss: 0.4825 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4372 - accuracy: 0.8163 - val_loss: 0.4789 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4378 - accuracy: 0.8129 - val_loss: 0.4818 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.4350 - accuracy: 0.8095 - val_loss: 0.4695 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 680us/step - loss: 0.4355 - accuracy: 0.8095 - val_loss: 0.4829 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 645us/step - loss: 0.4314 - accuracy: 0.8231 - val_loss: 0.4692 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.4337 - accuracy: 0.8299 - val_loss: 0.4796 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 701us/step - loss: 0.4291 - accuracy: 0.8265 - val_loss: 0.4771 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.4302 - accuracy: 0.8299 - val_loss: 0.4817 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 872us/step - loss: 0.4345 - accuracy: 0.8163 - val_loss: 0.4735 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.4279 - accuracy: 0.8265 - val_loss: 0.4707 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.4239 - accuracy: 0.8367 - val_loss: 0.4731 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.4252 - accuracy: 0.8163 - val_loss: 0.4752 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.4241 - accuracy: 0.8231 - val_loss: 0.4640 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 483us/step - loss: 0.4224 - accuracy: 0.8333 - val_loss: 0.4769 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 392us/step - loss: 0.4225 - accuracy: 0.8197 - val_loss: 0.4834 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 390us/step - loss: 0.4210 - accuracy: 0.8333 - val_loss: 0.4744 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 578us/step - loss: 0.4241 - accuracy: 0.8265 - val_loss: 0.4710 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.4226 - accuracy: 0.8129 - val_loss: 0.4724 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 496us/step - loss: 0.4161 - accuracy: 0.8231 - val_loss: 0.4666 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 575us/step - loss: 0.4161 - accuracy: 0.8231 - val_loss: 0.4813 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 465us/step - loss: 0.4139 - accuracy: 0.8299 - val_loss: 0.4700 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.4136 - accuracy: 0.8333 - val_loss: 0.4713 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.4140 - accuracy: 0.8401 - val_loss: 0.4689 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 193us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.2810 - accuracy: 0.4082 - val_loss: 1.1569 - val_accuracy: 0.5192\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 1.0807 - accuracy: 0.5748 - val_loss: 0.9969 - val_accuracy: 0.5962\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 581us/step - loss: 0.9495 - accuracy: 0.6463 - val_loss: 0.8851 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.8548 - accuracy: 0.7041 - val_loss: 0.8040 - val_accuracy: 0.7308\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.7868 - accuracy: 0.7177 - val_loss: 0.7386 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.7382 - accuracy: 0.7381 - val_loss: 0.7099 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 387us/step - loss: 0.6989 - accuracy: 0.7347 - val_loss: 0.6661 - val_accuracy: 0.7885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 543us/step - loss: 0.6726 - accuracy: 0.7347 - val_loss: 0.6328 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 435us/step - loss: 0.6520 - accuracy: 0.7381 - val_loss: 0.6199 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.6385 - accuracy: 0.7279 - val_loss: 0.6002 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 626us/step - loss: 0.6224 - accuracy: 0.7381 - val_loss: 0.5918 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 634us/step - loss: 0.6102 - accuracy: 0.7415 - val_loss: 0.5761 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 749us/step - loss: 0.5980 - accuracy: 0.7347 - val_loss: 0.5661 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 746us/step - loss: 0.5902 - accuracy: 0.7415 - val_loss: 0.5714 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 665us/step - loss: 0.5823 - accuracy: 0.7483 - val_loss: 0.5572 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.5749 - accuracy: 0.7551 - val_loss: 0.5517 - val_accuracy: 0.8269\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5690 - accuracy: 0.7517 - val_loss: 0.5459 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.5635 - accuracy: 0.7517 - val_loss: 0.5470 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 374us/step - loss: 0.5590 - accuracy: 0.7619 - val_loss: 0.5269 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.5528 - accuracy: 0.7449 - val_loss: 0.5408 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 334us/step - loss: 0.5489 - accuracy: 0.7551 - val_loss: 0.5360 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 369us/step - loss: 0.5435 - accuracy: 0.7517 - val_loss: 0.5239 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.5394 - accuracy: 0.7653 - val_loss: 0.5251 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 501us/step - loss: 0.5365 - accuracy: 0.7551 - val_loss: 0.5294 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 407us/step - loss: 0.5344 - accuracy: 0.7517 - val_loss: 0.5320 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 0.5305 - accuracy: 0.7585 - val_loss: 0.5226 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5263 - accuracy: 0.7585 - val_loss: 0.5191 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 393us/step - loss: 0.5234 - accuracy: 0.7619 - val_loss: 0.5156 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5292 - accuracy: 0.7653 - val_loss: 0.5055 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5188 - accuracy: 0.7585 - val_loss: 0.5185 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5160 - accuracy: 0.7619 - val_loss: 0.5020 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.5177 - accuracy: 0.7653 - val_loss: 0.5086 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5149 - accuracy: 0.7585 - val_loss: 0.5105 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5087 - accuracy: 0.7891 - val_loss: 0.4928 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.5079 - accuracy: 0.7619 - val_loss: 0.5157 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5059 - accuracy: 0.7789 - val_loss: 0.4990 - val_accuracy: 0.8269\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5018 - accuracy: 0.7755 - val_loss: 0.5075 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 624us/step - loss: 0.5055 - accuracy: 0.7619 - val_loss: 0.4878 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4957 - accuracy: 0.7891 - val_loss: 0.5000 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4943 - accuracy: 0.7789 - val_loss: 0.4999 - val_accuracy: 0.8269\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.4922 - accuracy: 0.7789 - val_loss: 0.5014 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4904 - accuracy: 0.7891 - val_loss: 0.4969 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.4901 - accuracy: 0.7891 - val_loss: 0.4981 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.4867 - accuracy: 0.7857 - val_loss: 0.4884 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 0.4850 - accuracy: 0.7823 - val_loss: 0.4890 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.4824 - accuracy: 0.7823 - val_loss: 0.5006 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4838 - accuracy: 0.7755 - val_loss: 0.4985 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 699us/step - loss: 0.4831 - accuracy: 0.7925 - val_loss: 0.4921 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 408us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3741 - accuracy: 0.3605 - val_loss: 1.1823 - val_accuracy: 0.4808\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 1.1584 - accuracy: 0.5646 - val_loss: 1.0392 - val_accuracy: 0.5962\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 1.0372 - accuracy: 0.6259 - val_loss: 0.9610 - val_accuracy: 0.6154\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.9423 - accuracy: 0.6395 - val_loss: 0.8685 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 418us/step - loss: 0.8593 - accuracy: 0.6667 - val_loss: 0.8036 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.7987 - accuracy: 0.6871 - val_loss: 0.7518 - val_accuracy: 0.7500\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.7519 - accuracy: 0.6973 - val_loss: 0.7084 - val_accuracy: 0.7692\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 557us/step - loss: 0.7147 - accuracy: 0.7211 - val_loss: 0.6738 - val_accuracy: 0.7692\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.6846 - accuracy: 0.7279 - val_loss: 0.6525 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.6604 - accuracy: 0.7483 - val_loss: 0.6175 - val_accuracy: 0.8077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.6418 - accuracy: 0.7517 - val_loss: 0.6232 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 277us/step - loss: 0.6266 - accuracy: 0.7347 - val_loss: 0.5929 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.6145 - accuracy: 0.7585 - val_loss: 0.5880 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.6021 - accuracy: 0.7551 - val_loss: 0.5742 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.5911 - accuracy: 0.7551 - val_loss: 0.5537 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5856 - accuracy: 0.7585 - val_loss: 0.5553 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5778 - accuracy: 0.7517 - val_loss: 0.5505 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 312us/step - loss: 0.5712 - accuracy: 0.7517 - val_loss: 0.5355 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5652 - accuracy: 0.7551 - val_loss: 0.5362 - val_accuracy: 0.7885\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.5593 - accuracy: 0.7653 - val_loss: 0.5421 - val_accuracy: 0.8077\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.5605 - accuracy: 0.7619 - val_loss: 0.5361 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.5485 - accuracy: 0.7585 - val_loss: 0.5306 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5460 - accuracy: 0.7619 - val_loss: 0.5405 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.5457 - accuracy: 0.7823 - val_loss: 0.5168 - val_accuracy: 0.8462\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5364 - accuracy: 0.7721 - val_loss: 0.5282 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 282us/step - loss: 0.5341 - accuracy: 0.7653 - val_loss: 0.5172 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5315 - accuracy: 0.7653 - val_loss: 0.5246 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 259us/step - loss: 0.5288 - accuracy: 0.7483 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5241 - accuracy: 0.7653 - val_loss: 0.5147 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5212 - accuracy: 0.7721 - val_loss: 0.5015 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.5182 - accuracy: 0.7755 - val_loss: 0.5140 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 670us/step - loss: 0.5190 - accuracy: 0.7687 - val_loss: 0.5215 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 379us/step - loss: 0.5176 - accuracy: 0.7653 - val_loss: 0.5145 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 558us/step - loss: 0.5106 - accuracy: 0.7857 - val_loss: 0.5022 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 667us/step - loss: 0.5090 - accuracy: 0.7789 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.5061 - accuracy: 0.7721 - val_loss: 0.5001 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 725us/step - loss: 0.5034 - accuracy: 0.7755 - val_loss: 0.5029 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 877us/step - loss: 0.5018 - accuracy: 0.7789 - val_loss: 0.4981 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7823 - val_loss: 0.5025 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.5003 - accuracy: 0.7789 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 994us/step - loss: 0.4982 - accuracy: 0.7755 - val_loss: 0.4915 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.4970 - accuracy: 0.7789 - val_loss: 0.4878 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.4971 - accuracy: 0.7823 - val_loss: 0.5112 - val_accuracy: 0.8269\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 632us/step - loss: 0.4969 - accuracy: 0.7619 - val_loss: 0.4980 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 521us/step - loss: 0.4871 - accuracy: 0.7925 - val_loss: 0.4862 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 528us/step - loss: 0.4870 - accuracy: 0.7857 - val_loss: 0.4754 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 423us/step - loss: 0.4857 - accuracy: 0.7891 - val_loss: 0.4840 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4884 - accuracy: 0.7721 - val_loss: 0.4994 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 564us/step - loss: 0.4827 - accuracy: 0.7857 - val_loss: 0.4819 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.4792 - accuracy: 0.7959 - val_loss: 0.4877 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4787 - accuracy: 0.7993 - val_loss: 0.4845 - val_accuracy: 0.8462\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.4766 - accuracy: 0.7925 - val_loss: 0.4849 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 694us/step - loss: 0.4785 - accuracy: 0.7925 - val_loss: 0.4783 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.4761 - accuracy: 0.7925 - val_loss: 0.4867 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.4714 - accuracy: 0.7959 - val_loss: 0.4826 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.4756 - accuracy: 0.7993 - val_loss: 0.4776 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 122us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.3653 - accuracy: 0.3401 - val_loss: 1.2312 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 404us/step - loss: 1.1490 - accuracy: 0.5646 - val_loss: 1.0662 - val_accuracy: 0.6923\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 1.0153 - accuracy: 0.6565 - val_loss: 0.9310 - val_accuracy: 0.7115\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 673us/step - loss: 0.9007 - accuracy: 0.7143 - val_loss: 0.8608 - val_accuracy: 0.7500\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 508us/step - loss: 0.8206 - accuracy: 0.7347 - val_loss: 0.7719 - val_accuracy: 0.7885\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 534us/step - loss: 0.7652 - accuracy: 0.7347 - val_loss: 0.7219 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 587us/step - loss: 0.7198 - accuracy: 0.7313 - val_loss: 0.6892 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 0.6896 - accuracy: 0.7449 - val_loss: 0.6521 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.6661 - accuracy: 0.7449 - val_loss: 0.6262 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 517us/step - loss: 0.6446 - accuracy: 0.7313 - val_loss: 0.6182 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.6258 - accuracy: 0.7721 - val_loss: 0.6017 - val_accuracy: 0.7885\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 463us/step - loss: 0.6145 - accuracy: 0.7517 - val_loss: 0.5933 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.6010 - accuracy: 0.7687 - val_loss: 0.5740 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 537us/step - loss: 0.5912 - accuracy: 0.7619 - val_loss: 0.5844 - val_accuracy: 0.8077\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 458us/step - loss: 0.5833 - accuracy: 0.7585 - val_loss: 0.5691 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.5758 - accuracy: 0.7449 - val_loss: 0.5571 - val_accuracy: 0.7885\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5677 - accuracy: 0.7551 - val_loss: 0.5641 - val_accuracy: 0.7885\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.5620 - accuracy: 0.7619 - val_loss: 0.5615 - val_accuracy: 0.7885\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 347us/step - loss: 0.5622 - accuracy: 0.7551 - val_loss: 0.5617 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 426us/step - loss: 0.5560 - accuracy: 0.7551 - val_loss: 0.5490 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5489 - accuracy: 0.7721 - val_loss: 0.5537 - val_accuracy: 0.7885\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5485 - accuracy: 0.7619 - val_loss: 0.5485 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.5376 - accuracy: 0.7551 - val_loss: 0.5430 - val_accuracy: 0.7885\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 394us/step - loss: 0.5376 - accuracy: 0.7585 - val_loss: 0.5413 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 414us/step - loss: 0.5321 - accuracy: 0.7585 - val_loss: 0.5404 - val_accuracy: 0.7885\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.5315 - accuracy: 0.7653 - val_loss: 0.5318 - val_accuracy: 0.7885\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 446us/step - loss: 0.5291 - accuracy: 0.7619 - val_loss: 0.5428 - val_accuracy: 0.7885\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.5238 - accuracy: 0.7619 - val_loss: 0.5327 - val_accuracy: 0.8077\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 487us/step - loss: 0.5220 - accuracy: 0.7619 - val_loss: 0.5384 - val_accuracy: 0.8077\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5268 - accuracy: 0.7687 - val_loss: 0.5414 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 493us/step - loss: 0.5214 - accuracy: 0.7619 - val_loss: 0.5472 - val_accuracy: 0.8077\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.5126 - accuracy: 0.7619 - val_loss: 0.5298 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.5096 - accuracy: 0.7653 - val_loss: 0.5293 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 489us/step - loss: 0.5103 - accuracy: 0.7925 - val_loss: 0.5334 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.5108 - accuracy: 0.7687 - val_loss: 0.5485 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 0.5070 - accuracy: 0.7755 - val_loss: 0.5162 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.5029 - accuracy: 0.7721 - val_loss: 0.5177 - val_accuracy: 0.8269\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.5059 - accuracy: 0.7585 - val_loss: 0.5220 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 523us/step - loss: 0.4978 - accuracy: 0.7721 - val_loss: 0.5146 - val_accuracy: 0.8269\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 972us/step - loss: 0.4943 - accuracy: 0.7789 - val_loss: 0.5105 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 408us/step - loss: 0.4952 - accuracy: 0.7687 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.4926 - accuracy: 0.7857 - val_loss: 0.5103 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.4882 - accuracy: 0.7721 - val_loss: 0.5297 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 459us/step - loss: 0.4884 - accuracy: 0.7721 - val_loss: 0.5088 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 410us/step - loss: 0.4876 - accuracy: 0.7891 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.4862 - accuracy: 0.7891 - val_loss: 0.5200 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.4844 - accuracy: 0.7891 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 0.4839 - accuracy: 0.7857 - val_loss: 0.5173 - val_accuracy: 0.8077\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 337us/step - loss: 0.4783 - accuracy: 0.7721 - val_loss: 0.5011 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 0.4819 - accuracy: 0.7925 - val_loss: 0.5057 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4781 - accuracy: 0.7857 - val_loss: 0.5165 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 321us/step - loss: 0.4756 - accuracy: 0.7823 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 399us/step - loss: 0.4730 - accuracy: 0.7925 - val_loss: 0.4940 - val_accuracy: 0.8462\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 315us/step - loss: 0.4719 - accuracy: 0.7823 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4723 - accuracy: 0.7721 - val_loss: 0.5075 - val_accuracy: 0.8462\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 298us/step - loss: 0.4695 - accuracy: 0.7891 - val_loss: 0.5035 - val_accuracy: 0.8462\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4664 - accuracy: 0.7891 - val_loss: 0.4898 - val_accuracy: 0.8462\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 356us/step - loss: 0.4675 - accuracy: 0.7823 - val_loss: 0.5110 - val_accuracy: 0.8269\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4662 - accuracy: 0.7993 - val_loss: 0.4938 - val_accuracy: 0.8462\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 385us/step - loss: 0.4627 - accuracy: 0.7959 - val_loss: 0.4989 - val_accuracy: 0.8462\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.4620 - accuracy: 0.8129 - val_loss: 0.5074 - val_accuracy: 0.8462\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 498us/step - loss: 0.4606 - accuracy: 0.7959 - val_loss: 0.5035 - val_accuracy: 0.8462\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.4600 - accuracy: 0.8095 - val_loss: 0.4937 - val_accuracy: 0.8462\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.4602 - accuracy: 0.8027 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.4567 - accuracy: 0.7959 - val_loss: 0.4941 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 781us/step - loss: 0.4541 - accuracy: 0.7959 - val_loss: 0.4964 - val_accuracy: 0.8462\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 629us/step - loss: 0.4532 - accuracy: 0.8027 - val_loss: 0.4767 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 658us/step - loss: 0.4510 - accuracy: 0.7993 - val_loss: 0.5021 - val_accuracy: 0.8462\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.4519 - accuracy: 0.7959 - val_loss: 0.4986 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 453us/step - loss: 0.4531 - accuracy: 0.8129 - val_loss: 0.4888 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 490us/step - loss: 0.4500 - accuracy: 0.7959 - val_loss: 0.4900 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.4507 - accuracy: 0.7891 - val_loss: 0.4967 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 354us/step - loss: 0.4468 - accuracy: 0.8197 - val_loss: 0.4913 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4446 - accuracy: 0.8129 - val_loss: 0.4839 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 380us/step - loss: 0.4449 - accuracy: 0.8129 - val_loss: 0.5077 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.4441 - accuracy: 0.8027 - val_loss: 0.4909 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 542us/step - loss: 0.4412 - accuracy: 0.8095 - val_loss: 0.4914 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 45us/step\n"
     ]
    }
   ],
   "source": [
    "for n in range(k_opt_1-3, 64):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_dim = 11, activation = 'sigmoid'))\n",
    "    model.add(Dense(4, activation ='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "    history = model.fit(X_train, Y_train, batch_size = 10, epochs = 150, validation_split= 0.15, verbose = 1, \n",
    "         callbacks = [callback_early_stopping])\n",
    "    y_test,accuracy = model.evaluate(X_test, Y_test)\n",
    "    history_all.append(history)\n",
    "    accuracy_all.append(accuracy)\n",
    "    n_value.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f715d1afb50>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(n_value,accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for different number of neurons in two hidden layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "numbers.append(4);\n",
    "for x in range(4):\n",
    "    numbers.append(numbers[x]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 16, 32, 64]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 10\n",
    "callback_early_stopping =EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "\n",
    "history_all = []\n",
    "accuracy_all = []\n",
    "n_value = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 2ms/step - loss: 1.4221 - accuracy: 0.2551 - val_loss: 1.4361 - val_accuracy: 0.1923\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 585us/step - loss: 1.3979 - accuracy: 0.2551 - val_loss: 1.4123 - val_accuracy: 0.1923\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 544us/step - loss: 1.3808 - accuracy: 0.2551 - val_loss: 1.3933 - val_accuracy: 0.1923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 429us/step - loss: 1.3658 - accuracy: 0.2619 - val_loss: 1.3751 - val_accuracy: 0.2115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 554us/step - loss: 1.3537 - accuracy: 0.2925 - val_loss: 1.3621 - val_accuracy: 0.2308\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 732us/step - loss: 1.3423 - accuracy: 0.3129 - val_loss: 1.3479 - val_accuracy: 0.2885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 654us/step - loss: 1.3322 - accuracy: 0.3265 - val_loss: 1.3336 - val_accuracy: 0.2885\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 688us/step - loss: 1.3221 - accuracy: 0.3367 - val_loss: 1.3243 - val_accuracy: 0.2885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 571us/step - loss: 1.3115 - accuracy: 0.3401 - val_loss: 1.3111 - val_accuracy: 0.2500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 744us/step - loss: 1.3008 - accuracy: 0.3639 - val_loss: 1.2999 - val_accuracy: 0.3077\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 1.2911 - accuracy: 0.3810 - val_loss: 1.2888 - val_accuracy: 0.3269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 1.2790 - accuracy: 0.4082 - val_loss: 1.2744 - val_accuracy: 0.4423\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 773us/step - loss: 1.2670 - accuracy: 0.4048 - val_loss: 1.2630 - val_accuracy: 0.4038\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 672us/step - loss: 1.2544 - accuracy: 0.4456 - val_loss: 1.2496 - val_accuracy: 0.5577\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 1.2428 - accuracy: 0.5068 - val_loss: 1.2378 - val_accuracy: 0.6154\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 701us/step - loss: 1.2301 - accuracy: 0.5374 - val_loss: 1.2256 - val_accuracy: 0.6538\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 567us/step - loss: 1.2180 - accuracy: 0.5714 - val_loss: 1.2141 - val_accuracy: 0.6346\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 680us/step - loss: 1.2054 - accuracy: 0.5680 - val_loss: 1.2016 - val_accuracy: 0.6346\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 1.1929 - accuracy: 0.6054 - val_loss: 1.1898 - val_accuracy: 0.6154\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 753us/step - loss: 1.1810 - accuracy: 0.6293 - val_loss: 1.1769 - val_accuracy: 0.6154\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 841us/step - loss: 1.1688 - accuracy: 0.6327 - val_loss: 1.1643 - val_accuracy: 0.6154\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 1.1567 - accuracy: 0.6565 - val_loss: 1.1528 - val_accuracy: 0.6154\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 776us/step - loss: 1.1447 - accuracy: 0.6531 - val_loss: 1.1416 - val_accuracy: 0.6154\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 732us/step - loss: 1.1330 - accuracy: 0.6565 - val_loss: 1.1286 - val_accuracy: 0.6154\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 665us/step - loss: 1.1217 - accuracy: 0.6565 - val_loss: 1.1174 - val_accuracy: 0.6154\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 696us/step - loss: 1.1102 - accuracy: 0.6565 - val_loss: 1.1045 - val_accuracy: 0.6346\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 731us/step - loss: 1.0990 - accuracy: 0.6667 - val_loss: 1.0959 - val_accuracy: 0.5962\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 906us/step - loss: 1.0877 - accuracy: 0.6667 - val_loss: 1.0865 - val_accuracy: 0.6154\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 794us/step - loss: 1.0775 - accuracy: 0.6667 - val_loss: 1.0753 - val_accuracy: 0.6154\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 808us/step - loss: 1.0668 - accuracy: 0.6735 - val_loss: 1.0630 - val_accuracy: 0.6154\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 1.0563 - accuracy: 0.6667 - val_loss: 1.0535 - val_accuracy: 0.5962\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 738us/step - loss: 1.0461 - accuracy: 0.6701 - val_loss: 1.0451 - val_accuracy: 0.6154\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 661us/step - loss: 1.0358 - accuracy: 0.6701 - val_loss: 1.0350 - val_accuracy: 0.6154\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 893us/step - loss: 1.0263 - accuracy: 0.6633 - val_loss: 1.0272 - val_accuracy: 0.6346\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 998us/step - loss: 1.0164 - accuracy: 0.6667 - val_loss: 1.0191 - val_accuracy: 0.6346\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 989us/step - loss: 1.0070 - accuracy: 0.6735 - val_loss: 1.0103 - val_accuracy: 0.6154\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 811us/step - loss: 0.9977 - accuracy: 0.6667 - val_loss: 1.0006 - val_accuracy: 0.6538\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 692us/step - loss: 0.9887 - accuracy: 0.6701 - val_loss: 0.9925 - val_accuracy: 0.6154\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 603us/step - loss: 0.9798 - accuracy: 0.6701 - val_loss: 0.9858 - val_accuracy: 0.6346\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 745us/step - loss: 0.9713 - accuracy: 0.6701 - val_loss: 0.9786 - val_accuracy: 0.6538\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 775us/step - loss: 0.9632 - accuracy: 0.6701 - val_loss: 0.9708 - val_accuracy: 0.6154\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 971us/step - loss: 0.9550 - accuracy: 0.6735 - val_loss: 0.9634 - val_accuracy: 0.6538\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 842us/step - loss: 0.9475 - accuracy: 0.6701 - val_loss: 0.9535 - val_accuracy: 0.6346\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 737us/step - loss: 0.9390 - accuracy: 0.6803 - val_loss: 0.9500 - val_accuracy: 0.6538\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 676us/step - loss: 0.9313 - accuracy: 0.6769 - val_loss: 0.9434 - val_accuracy: 0.6346\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.9237 - accuracy: 0.6769 - val_loss: 0.9395 - val_accuracy: 0.6154\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 561us/step - loss: 0.9162 - accuracy: 0.6735 - val_loss: 0.9278 - val_accuracy: 0.6346\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 863us/step - loss: 0.9089 - accuracy: 0.6769 - val_loss: 0.9237 - val_accuracy: 0.6346\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 753us/step - loss: 0.9019 - accuracy: 0.6837 - val_loss: 0.9160 - val_accuracy: 0.6538\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 655us/step - loss: 0.8953 - accuracy: 0.6837 - val_loss: 0.9135 - val_accuracy: 0.6538\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 886us/step - loss: 0.8880 - accuracy: 0.6905 - val_loss: 0.9061 - val_accuracy: 0.6154\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.8813 - accuracy: 0.6905 - val_loss: 0.8997 - val_accuracy: 0.6538\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 881us/step - loss: 0.8749 - accuracy: 0.6905 - val_loss: 0.8924 - val_accuracy: 0.6538\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 626us/step - loss: 0.8685 - accuracy: 0.6973 - val_loss: 0.8883 - val_accuracy: 0.6538\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.8617 - accuracy: 0.6905 - val_loss: 0.8798 - val_accuracy: 0.6731\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.8561 - accuracy: 0.6973 - val_loss: 0.8742 - val_accuracy: 0.6538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.8496 - accuracy: 0.6973 - val_loss: 0.8663 - val_accuracy: 0.6731\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.8432 - accuracy: 0.6905 - val_loss: 0.8592 - val_accuracy: 0.6731\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.8371 - accuracy: 0.6973 - val_loss: 0.8537 - val_accuracy: 0.6731\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.8314 - accuracy: 0.7007 - val_loss: 0.8483 - val_accuracy: 0.6923\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.8256 - accuracy: 0.7007 - val_loss: 0.8425 - val_accuracy: 0.6923\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 525us/step - loss: 0.8193 - accuracy: 0.7075 - val_loss: 0.8398 - val_accuracy: 0.6923\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 582us/step - loss: 0.8141 - accuracy: 0.7075 - val_loss: 0.8345 - val_accuracy: 0.7115\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.8083 - accuracy: 0.7109 - val_loss: 0.8304 - val_accuracy: 0.7115\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.8026 - accuracy: 0.7109 - val_loss: 0.8280 - val_accuracy: 0.7115\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.7975 - accuracy: 0.7109 - val_loss: 0.8199 - val_accuracy: 0.7115\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 492us/step - loss: 0.7922 - accuracy: 0.7143 - val_loss: 0.8167 - val_accuracy: 0.7115\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 405us/step - loss: 0.7866 - accuracy: 0.7109 - val_loss: 0.8115 - val_accuracy: 0.7115\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.7820 - accuracy: 0.7075 - val_loss: 0.8061 - val_accuracy: 0.7115\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 294us/step - loss: 0.7769 - accuracy: 0.7143 - val_loss: 0.8023 - val_accuracy: 0.7115\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 281us/step - loss: 0.7725 - accuracy: 0.7109 - val_loss: 0.7970 - val_accuracy: 0.7115\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.7676 - accuracy: 0.7109 - val_loss: 0.7890 - val_accuracy: 0.7308\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 0.7623 - accuracy: 0.7245 - val_loss: 0.7893 - val_accuracy: 0.7500\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 608us/step - loss: 0.7570 - accuracy: 0.7415 - val_loss: 0.7828 - val_accuracy: 0.7500\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 478us/step - loss: 0.7532 - accuracy: 0.7313 - val_loss: 0.7800 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.7478 - accuracy: 0.7483 - val_loss: 0.7780 - val_accuracy: 0.7500\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 449us/step - loss: 0.7431 - accuracy: 0.7483 - val_loss: 0.7725 - val_accuracy: 0.7885\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.7390 - accuracy: 0.7415 - val_loss: 0.7672 - val_accuracy: 0.7692\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 283us/step - loss: 0.7347 - accuracy: 0.7483 - val_loss: 0.7654 - val_accuracy: 0.7885\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.7305 - accuracy: 0.7551 - val_loss: 0.7572 - val_accuracy: 0.8269\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.7252 - accuracy: 0.7517 - val_loss: 0.7588 - val_accuracy: 0.8269\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.7207 - accuracy: 0.7585 - val_loss: 0.7525 - val_accuracy: 0.8077\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 397us/step - loss: 0.7169 - accuracy: 0.7585 - val_loss: 0.7468 - val_accuracy: 0.8269\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 389us/step - loss: 0.7128 - accuracy: 0.7687 - val_loss: 0.7434 - val_accuracy: 0.8269\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 472us/step - loss: 0.7089 - accuracy: 0.7687 - val_loss: 0.7392 - val_accuracy: 0.8269\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.7044 - accuracy: 0.7721 - val_loss: 0.7356 - val_accuracy: 0.8269\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 568us/step - loss: 0.7008 - accuracy: 0.7653 - val_loss: 0.7308 - val_accuracy: 0.8269\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 679us/step - loss: 0.6970 - accuracy: 0.7551 - val_loss: 0.7274 - val_accuracy: 0.8269\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 324us/step - loss: 0.6936 - accuracy: 0.7721 - val_loss: 0.7236 - val_accuracy: 0.8269\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6888 - accuracy: 0.7789 - val_loss: 0.7220 - val_accuracy: 0.8269\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.6855 - accuracy: 0.7687 - val_loss: 0.7170 - val_accuracy: 0.8269\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6817 - accuracy: 0.7789 - val_loss: 0.7135 - val_accuracy: 0.8269\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.6775 - accuracy: 0.7789 - val_loss: 0.7092 - val_accuracy: 0.8269\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 284us/step - loss: 0.6743 - accuracy: 0.7823 - val_loss: 0.7075 - val_accuracy: 0.8269\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.6701 - accuracy: 0.7823 - val_loss: 0.7026 - val_accuracy: 0.8269\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 358us/step - loss: 0.6663 - accuracy: 0.7789 - val_loss: 0.6991 - val_accuracy: 0.8269\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.6635 - accuracy: 0.7721 - val_loss: 0.6941 - val_accuracy: 0.8269\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.6603 - accuracy: 0.7789 - val_loss: 0.6919 - val_accuracy: 0.8269\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.6576 - accuracy: 0.7823 - val_loss: 0.6867 - val_accuracy: 0.8269\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 442us/step - loss: 0.6535 - accuracy: 0.7789 - val_loss: 0.6828 - val_accuracy: 0.8269\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 386us/step - loss: 0.6496 - accuracy: 0.7789 - val_loss: 0.6820 - val_accuracy: 0.8269\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.6467 - accuracy: 0.7823 - val_loss: 0.6804 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 323us/step - loss: 0.6437 - accuracy: 0.7789 - val_loss: 0.6763 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 589us/step - loss: 0.6409 - accuracy: 0.7823 - val_loss: 0.6692 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.6384 - accuracy: 0.7789 - val_loss: 0.6666 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 524us/step - loss: 0.6337 - accuracy: 0.7789 - val_loss: 0.6634 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.6308 - accuracy: 0.7823 - val_loss: 0.6618 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.6279 - accuracy: 0.7823 - val_loss: 0.6573 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.6247 - accuracy: 0.7857 - val_loss: 0.6537 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.6221 - accuracy: 0.7857 - val_loss: 0.6546 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 388us/step - loss: 0.6190 - accuracy: 0.7789 - val_loss: 0.6477 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.6161 - accuracy: 0.7789 - val_loss: 0.6455 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 356us/step - loss: 0.6140 - accuracy: 0.7891 - val_loss: 0.6424 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.6112 - accuracy: 0.7891 - val_loss: 0.6420 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 319us/step - loss: 0.6081 - accuracy: 0.7891 - val_loss: 0.6397 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 351us/step - loss: 0.6055 - accuracy: 0.7959 - val_loss: 0.6371 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 274us/step - loss: 0.6037 - accuracy: 0.7857 - val_loss: 0.6322 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 288us/step - loss: 0.6008 - accuracy: 0.7789 - val_loss: 0.6304 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 368us/step - loss: 0.5980 - accuracy: 0.7925 - val_loss: 0.6277 - val_accuracy: 0.8462\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 293us/step - loss: 0.5953 - accuracy: 0.7891 - val_loss: 0.6257 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5925 - accuracy: 0.7925 - val_loss: 0.6233 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5910 - accuracy: 0.7993 - val_loss: 0.6185 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 310us/step - loss: 0.5888 - accuracy: 0.7993 - val_loss: 0.6195 - val_accuracy: 0.8462\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 291us/step - loss: 0.5859 - accuracy: 0.7959 - val_loss: 0.6147 - val_accuracy: 0.8462\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5837 - accuracy: 0.7959 - val_loss: 0.6116 - val_accuracy: 0.8462\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5815 - accuracy: 0.8027 - val_loss: 0.6096 - val_accuracy: 0.8462\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5791 - accuracy: 0.7993 - val_loss: 0.6062 - val_accuracy: 0.8462\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5770 - accuracy: 0.7959 - val_loss: 0.6056 - val_accuracy: 0.8462\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 330us/step - loss: 0.5750 - accuracy: 0.8027 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
      "Epoch 130/150\n",
      "294/294 [==============================] - 0s 370us/step - loss: 0.5732 - accuracy: 0.7925 - val_loss: 0.6022 - val_accuracy: 0.8462\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.5708 - accuracy: 0.8027 - val_loss: 0.6003 - val_accuracy: 0.8462\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 422us/step - loss: 0.5694 - accuracy: 0.8095 - val_loss: 0.5966 - val_accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 444us/step - loss: 0.5670 - accuracy: 0.8061 - val_loss: 0.5923 - val_accuracy: 0.8462\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.5647 - accuracy: 0.8061 - val_loss: 0.5924 - val_accuracy: 0.8462\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 296us/step - loss: 0.5628 - accuracy: 0.8027 - val_loss: 0.5910 - val_accuracy: 0.8462\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.5617 - accuracy: 0.7993 - val_loss: 0.5923 - val_accuracy: 0.8462\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 357us/step - loss: 0.5596 - accuracy: 0.7959 - val_loss: 0.5874 - val_accuracy: 0.8462\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.5577 - accuracy: 0.8027 - val_loss: 0.5865 - val_accuracy: 0.8462\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 436us/step - loss: 0.5562 - accuracy: 0.8095 - val_loss: 0.5807 - val_accuracy: 0.8462\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 541us/step - loss: 0.5543 - accuracy: 0.8095 - val_loss: 0.5823 - val_accuracy: 0.8462\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 565us/step - loss: 0.5522 - accuracy: 0.7993 - val_loss: 0.5775 - val_accuracy: 0.8462\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.5509 - accuracy: 0.8061 - val_loss: 0.5799 - val_accuracy: 0.8462\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 0.5497 - accuracy: 0.8061 - val_loss: 0.5745 - val_accuracy: 0.8462\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5470 - accuracy: 0.8061 - val_loss: 0.5742 - val_accuracy: 0.8462\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 349us/step - loss: 0.5454 - accuracy: 0.8095 - val_loss: 0.5747 - val_accuracy: 0.8462\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 562us/step - loss: 0.5442 - accuracy: 0.8061 - val_loss: 0.5736 - val_accuracy: 0.8462\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 377us/step - loss: 0.5420 - accuracy: 0.8095 - val_loss: 0.5700 - val_accuracy: 0.8462\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5419 - accuracy: 0.8095 - val_loss: 0.5667 - val_accuracy: 0.8462\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 615us/step - loss: 0.5400 - accuracy: 0.8095 - val_loss: 0.5723 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 720us/step - loss: 0.5384 - accuracy: 0.8095 - val_loss: 0.5667 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 180us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 4ms/step - loss: 1.3992 - accuracy: 0.3129 - val_loss: 1.3632 - val_accuracy: 0.3077\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 514us/step - loss: 1.3679 - accuracy: 0.3027 - val_loss: 1.3496 - val_accuracy: 0.3269\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 662us/step - loss: 1.3399 - accuracy: 0.3265 - val_loss: 1.3289 - val_accuracy: 0.3269\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 1.3163 - accuracy: 0.4014 - val_loss: 1.3080 - val_accuracy: 0.4615\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 619us/step - loss: 1.2915 - accuracy: 0.5000 - val_loss: 1.2824 - val_accuracy: 0.5962\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 1.2621 - accuracy: 0.6224 - val_loss: 1.2504 - val_accuracy: 0.6538\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 452us/step - loss: 1.2304 - accuracy: 0.7143 - val_loss: 1.2161 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 1.1946 - accuracy: 0.6973 - val_loss: 1.1766 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 297us/step - loss: 1.1587 - accuracy: 0.7007 - val_loss: 1.1373 - val_accuracy: 0.7692\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 301us/step - loss: 1.1239 - accuracy: 0.6973 - val_loss: 1.0974 - val_accuracy: 0.7308\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 278us/step - loss: 1.0895 - accuracy: 0.7109 - val_loss: 1.0635 - val_accuracy: 0.8269\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 461us/step - loss: 1.0562 - accuracy: 0.7109 - val_loss: 1.0258 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 1.0258 - accuracy: 0.7143 - val_loss: 0.9955 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.9972 - accuracy: 0.7109 - val_loss: 0.9697 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 300us/step - loss: 0.9710 - accuracy: 0.7143 - val_loss: 0.9457 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 327us/step - loss: 0.9462 - accuracy: 0.7245 - val_loss: 0.9217 - val_accuracy: 0.7692\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 456us/step - loss: 0.9249 - accuracy: 0.7177 - val_loss: 0.8985 - val_accuracy: 0.7692\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 470us/step - loss: 0.9016 - accuracy: 0.7381 - val_loss: 0.8789 - val_accuracy: 0.7692\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.8818 - accuracy: 0.7211 - val_loss: 0.8596 - val_accuracy: 0.7692\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.8624 - accuracy: 0.7279 - val_loss: 0.8399 - val_accuracy: 0.7692\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 768us/step - loss: 0.8435 - accuracy: 0.7551 - val_loss: 0.8248 - val_accuracy: 0.7692\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 973us/step - loss: 0.8259 - accuracy: 0.7517 - val_loss: 0.8075 - val_accuracy: 0.7885\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.8104 - accuracy: 0.7483 - val_loss: 0.7917 - val_accuracy: 0.7692\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.7933 - accuracy: 0.7551 - val_loss: 0.7752 - val_accuracy: 0.7885\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 924us/step - loss: 0.7791 - accuracy: 0.7517 - val_loss: 0.7595 - val_accuracy: 0.7692\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 579us/step - loss: 0.7639 - accuracy: 0.7585 - val_loss: 0.7496 - val_accuracy: 0.7692\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 454us/step - loss: 0.7521 - accuracy: 0.7619 - val_loss: 0.7359 - val_accuracy: 0.7692\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 693us/step - loss: 0.7395 - accuracy: 0.7585 - val_loss: 0.7224 - val_accuracy: 0.7885\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 793us/step - loss: 0.7294 - accuracy: 0.7721 - val_loss: 0.7102 - val_accuracy: 0.7885\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.7164 - accuracy: 0.7653 - val_loss: 0.7006 - val_accuracy: 0.7885\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.7049 - accuracy: 0.7755 - val_loss: 0.6879 - val_accuracy: 0.7885\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 814us/step - loss: 0.6953 - accuracy: 0.7721 - val_loss: 0.6818 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 602us/step - loss: 0.6863 - accuracy: 0.7789 - val_loss: 0.6726 - val_accuracy: 0.8077\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 617us/step - loss: 0.6774 - accuracy: 0.7789 - val_loss: 0.6644 - val_accuracy: 0.8077\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 512us/step - loss: 0.6686 - accuracy: 0.7789 - val_loss: 0.6547 - val_accuracy: 0.8077\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 787us/step - loss: 0.6614 - accuracy: 0.7789 - val_loss: 0.6460 - val_accuracy: 0.8077\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.7755 - val_loss: 0.6453 - val_accuracy: 0.8077\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 926us/step - loss: 0.6464 - accuracy: 0.7823 - val_loss: 0.6326 - val_accuracy: 0.8077\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.7789 - val_loss: 0.6277 - val_accuracy: 0.8077\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 580us/step - loss: 0.6333 - accuracy: 0.7823 - val_loss: 0.6225 - val_accuracy: 0.8077\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 649us/step - loss: 0.6282 - accuracy: 0.7823 - val_loss: 0.6195 - val_accuracy: 0.8269\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 645us/step - loss: 0.6231 - accuracy: 0.7823 - val_loss: 0.6123 - val_accuracy: 0.8269\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 607us/step - loss: 0.6176 - accuracy: 0.7823 - val_loss: 0.6060 - val_accuracy: 0.8077\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 804us/step - loss: 0.6117 - accuracy: 0.7823 - val_loss: 0.6055 - val_accuracy: 0.8269\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.6066 - accuracy: 0.7823 - val_loss: 0.5990 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 563us/step - loss: 0.6016 - accuracy: 0.7823 - val_loss: 0.5938 - val_accuracy: 0.8269\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 673us/step - loss: 0.5980 - accuracy: 0.7823 - val_loss: 0.5881 - val_accuracy: 0.8269\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 802us/step - loss: 0.5929 - accuracy: 0.7789 - val_loss: 0.5835 - val_accuracy: 0.8269\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 714us/step - loss: 0.5900 - accuracy: 0.7823 - val_loss: 0.5798 - val_accuracy: 0.8077\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 950us/step - loss: 0.5853 - accuracy: 0.7857 - val_loss: 0.5778 - val_accuracy: 0.8269\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 847us/step - loss: 0.5819 - accuracy: 0.7857 - val_loss: 0.5779 - val_accuracy: 0.8269\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 892us/step - loss: 0.5787 - accuracy: 0.7857 - val_loss: 0.5708 - val_accuracy: 0.8269\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.7857 - val_loss: 0.5662 - val_accuracy: 0.8077\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 685us/step - loss: 0.5706 - accuracy: 0.7823 - val_loss: 0.5631 - val_accuracy: 0.8269\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 969us/step - loss: 0.5678 - accuracy: 0.7857 - val_loss: 0.5605 - val_accuracy: 0.8269\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 846us/step - loss: 0.5645 - accuracy: 0.7823 - val_loss: 0.5595 - val_accuracy: 0.8269\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 609us/step - loss: 0.5618 - accuracy: 0.7823 - val_loss: 0.5590 - val_accuracy: 0.8269\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.5596 - accuracy: 0.7823 - val_loss: 0.5555 - val_accuracy: 0.8077\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 621us/step - loss: 0.5566 - accuracy: 0.7857 - val_loss: 0.5491 - val_accuracy: 0.8269\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 755us/step - loss: 0.5530 - accuracy: 0.7857 - val_loss: 0.5500 - val_accuracy: 0.8269\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 803us/step - loss: 0.5507 - accuracy: 0.7857 - val_loss: 0.5493 - val_accuracy: 0.8269\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7823 - val_loss: 0.5442 - val_accuracy: 0.8269\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 500us/step - loss: 0.5460 - accuracy: 0.7823 - val_loss: 0.5440 - val_accuracy: 0.8077\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 694us/step - loss: 0.5436 - accuracy: 0.7891 - val_loss: 0.5475 - val_accuracy: 0.8269\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 0.5425 - accuracy: 0.7857 - val_loss: 0.5391 - val_accuracy: 0.8077\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.5382 - accuracy: 0.7857 - val_loss: 0.5432 - val_accuracy: 0.8269\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 583us/step - loss: 0.5359 - accuracy: 0.7857 - val_loss: 0.5418 - val_accuracy: 0.8077\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 677us/step - loss: 0.5337 - accuracy: 0.7857 - val_loss: 0.5387 - val_accuracy: 0.8077\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 681us/step - loss: 0.5322 - accuracy: 0.7823 - val_loss: 0.5373 - val_accuracy: 0.8077\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 705us/step - loss: 0.5291 - accuracy: 0.7857 - val_loss: 0.5383 - val_accuracy: 0.8077\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 636us/step - loss: 0.5276 - accuracy: 0.7891 - val_loss: 0.5390 - val_accuracy: 0.8077\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.5255 - accuracy: 0.7823 - val_loss: 0.5325 - val_accuracy: 0.8462\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.5240 - accuracy: 0.7891 - val_loss: 0.5334 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 475us/step - loss: 0.5210 - accuracy: 0.7823 - val_loss: 0.5317 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 471us/step - loss: 0.5195 - accuracy: 0.7857 - val_loss: 0.5329 - val_accuracy: 0.8462\n",
      "Epoch 76/150\n",
      "294/294 [==============================] - 0s 913us/step - loss: 0.5173 - accuracy: 0.7891 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
      "Epoch 77/150\n",
      "294/294 [==============================] - 0s 670us/step - loss: 0.5158 - accuracy: 0.7891 - val_loss: 0.5282 - val_accuracy: 0.8462\n",
      "Epoch 78/150\n",
      "294/294 [==============================] - 0s 846us/step - loss: 0.5137 - accuracy: 0.7857 - val_loss: 0.5276 - val_accuracy: 0.8462\n",
      "Epoch 79/150\n",
      "294/294 [==============================] - 0s 751us/step - loss: 0.5113 - accuracy: 0.7925 - val_loss: 0.5256 - val_accuracy: 0.8462\n",
      "Epoch 80/150\n",
      "294/294 [==============================] - 0s 910us/step - loss: 0.5107 - accuracy: 0.7857 - val_loss: 0.5273 - val_accuracy: 0.8462\n",
      "Epoch 81/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7891 - val_loss: 0.5222 - val_accuracy: 0.8462\n",
      "Epoch 82/150\n",
      "294/294 [==============================] - 0s 827us/step - loss: 0.5067 - accuracy: 0.7891 - val_loss: 0.5268 - val_accuracy: 0.8462\n",
      "Epoch 83/150\n",
      "294/294 [==============================] - 0s 535us/step - loss: 0.5058 - accuracy: 0.7925 - val_loss: 0.5149 - val_accuracy: 0.8462\n",
      "Epoch 84/150\n",
      "294/294 [==============================] - 0s 467us/step - loss: 0.5034 - accuracy: 0.7959 - val_loss: 0.5185 - val_accuracy: 0.8462\n",
      "Epoch 85/150\n",
      "294/294 [==============================] - 0s 674us/step - loss: 0.5019 - accuracy: 0.7925 - val_loss: 0.5180 - val_accuracy: 0.8462\n",
      "Epoch 86/150\n",
      "294/294 [==============================] - 0s 738us/step - loss: 0.5001 - accuracy: 0.7891 - val_loss: 0.5202 - val_accuracy: 0.8462\n",
      "Epoch 87/150\n",
      "294/294 [==============================] - 0s 586us/step - loss: 0.4979 - accuracy: 0.7857 - val_loss: 0.5143 - val_accuracy: 0.8462\n",
      "Epoch 88/150\n",
      "294/294 [==============================] - 0s 627us/step - loss: 0.4980 - accuracy: 0.7891 - val_loss: 0.5135 - val_accuracy: 0.8462\n",
      "Epoch 89/150\n",
      "294/294 [==============================] - 0s 842us/step - loss: 0.4955 - accuracy: 0.7891 - val_loss: 0.5173 - val_accuracy: 0.8462\n",
      "Epoch 90/150\n",
      "294/294 [==============================] - 0s 664us/step - loss: 0.4938 - accuracy: 0.7993 - val_loss: 0.5154 - val_accuracy: 0.8462\n",
      "Epoch 91/150\n",
      "294/294 [==============================] - 0s 513us/step - loss: 0.4930 - accuracy: 0.7993 - val_loss: 0.5156 - val_accuracy: 0.8462\n",
      "Epoch 92/150\n",
      "294/294 [==============================] - 0s 597us/step - loss: 0.4916 - accuracy: 0.7993 - val_loss: 0.5097 - val_accuracy: 0.8462\n",
      "Epoch 93/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.4902 - accuracy: 0.7959 - val_loss: 0.5095 - val_accuracy: 0.8462\n",
      "Epoch 94/150\n",
      "294/294 [==============================] - 0s 602us/step - loss: 0.4887 - accuracy: 0.8061 - val_loss: 0.5120 - val_accuracy: 0.8462\n",
      "Epoch 95/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 0.4875 - accuracy: 0.8027 - val_loss: 0.5135 - val_accuracy: 0.8462\n",
      "Epoch 96/150\n",
      "294/294 [==============================] - 0s 515us/step - loss: 0.4877 - accuracy: 0.7959 - val_loss: 0.5107 - val_accuracy: 0.8462\n",
      "Epoch 97/150\n",
      "294/294 [==============================] - 0s 853us/step - loss: 0.4850 - accuracy: 0.8061 - val_loss: 0.5189 - val_accuracy: 0.8462\n",
      "Epoch 98/150\n",
      "294/294 [==============================] - 0s 409us/step - loss: 0.4853 - accuracy: 0.7993 - val_loss: 0.5134 - val_accuracy: 0.8462\n",
      "Epoch 99/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.4835 - accuracy: 0.8027 - val_loss: 0.5130 - val_accuracy: 0.8462\n",
      "Epoch 100/150\n",
      "294/294 [==============================] - 0s 353us/step - loss: 0.4828 - accuracy: 0.8095 - val_loss: 0.5155 - val_accuracy: 0.8462\n",
      "Epoch 101/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4806 - accuracy: 0.8027 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 102/150\n",
      "294/294 [==============================] - 0s 365us/step - loss: 0.4790 - accuracy: 0.7993 - val_loss: 0.5062 - val_accuracy: 0.8462\n",
      "Epoch 103/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4785 - accuracy: 0.8061 - val_loss: 0.5102 - val_accuracy: 0.8462\n",
      "Epoch 104/150\n",
      "294/294 [==============================] - 0s 887us/step - loss: 0.4780 - accuracy: 0.7993 - val_loss: 0.5063 - val_accuracy: 0.8462\n",
      "Epoch 105/150\n",
      "294/294 [==============================] - 0s 983us/step - loss: 0.4765 - accuracy: 0.8095 - val_loss: 0.5065 - val_accuracy: 0.8462\n",
      "Epoch 106/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8061 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 107/150\n",
      "294/294 [==============================] - 0s 760us/step - loss: 0.4738 - accuracy: 0.8027 - val_loss: 0.5059 - val_accuracy: 0.8462\n",
      "Epoch 108/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.8095 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 109/150\n",
      "294/294 [==============================] - 0s 639us/step - loss: 0.4714 - accuracy: 0.8061 - val_loss: 0.5060 - val_accuracy: 0.8462\n",
      "Epoch 110/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4699 - accuracy: 0.8129 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 111/150\n",
      "294/294 [==============================] - 0s 636us/step - loss: 0.4692 - accuracy: 0.7993 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 112/150\n",
      "294/294 [==============================] - 0s 744us/step - loss: 0.4680 - accuracy: 0.8129 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 113/150\n",
      "294/294 [==============================] - 0s 549us/step - loss: 0.4676 - accuracy: 0.8061 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 114/150\n",
      "294/294 [==============================] - 0s 605us/step - loss: 0.4669 - accuracy: 0.8129 - val_loss: 0.5028 - val_accuracy: 0.8462\n",
      "Epoch 115/150\n",
      "294/294 [==============================] - 0s 858us/step - loss: 0.4642 - accuracy: 0.8095 - val_loss: 0.5048 - val_accuracy: 0.8462\n",
      "Epoch 116/150\n",
      "294/294 [==============================] - 0s 638us/step - loss: 0.4634 - accuracy: 0.8061 - val_loss: 0.5091 - val_accuracy: 0.8462\n",
      "Epoch 117/150\n",
      "294/294 [==============================] - 0s 532us/step - loss: 0.4646 - accuracy: 0.8027 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 118/150\n",
      "294/294 [==============================] - 0s 830us/step - loss: 0.4616 - accuracy: 0.8095 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 119/150\n",
      "294/294 [==============================] - 0s 678us/step - loss: 0.4630 - accuracy: 0.8061 - val_loss: 0.5071 - val_accuracy: 0.8462\n",
      "Epoch 120/150\n",
      "294/294 [==============================] - 0s 620us/step - loss: 0.4597 - accuracy: 0.8027 - val_loss: 0.5054 - val_accuracy: 0.8462\n",
      "Epoch 121/150\n",
      "294/294 [==============================] - 0s 853us/step - loss: 0.4596 - accuracy: 0.8129 - val_loss: 0.5080 - val_accuracy: 0.8462\n",
      "Epoch 122/150\n",
      "294/294 [==============================] - 0s 596us/step - loss: 0.4573 - accuracy: 0.8027 - val_loss: 0.5071 - val_accuracy: 0.8462\n",
      "Epoch 123/150\n",
      "294/294 [==============================] - 0s 703us/step - loss: 0.4564 - accuracy: 0.8027 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 124/150\n",
      "294/294 [==============================] - 0s 502us/step - loss: 0.4556 - accuracy: 0.8095 - val_loss: 0.5038 - val_accuracy: 0.8462\n",
      "Epoch 125/150\n",
      "294/294 [==============================] - 0s 342us/step - loss: 0.4548 - accuracy: 0.8163 - val_loss: 0.5050 - val_accuracy: 0.8462\n",
      "Epoch 126/150\n",
      "294/294 [==============================] - 0s 644us/step - loss: 0.4538 - accuracy: 0.8129 - val_loss: 0.5013 - val_accuracy: 0.8462\n",
      "Epoch 127/150\n",
      "294/294 [==============================] - 0s 529us/step - loss: 0.4525 - accuracy: 0.8129 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 128/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.4512 - accuracy: 0.8163 - val_loss: 0.5039 - val_accuracy: 0.8462\n",
      "Epoch 129/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4519 - accuracy: 0.8061 - val_loss: 0.5020 - val_accuracy: 0.8462\n",
      "Epoch 130/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 489us/step - loss: 0.4516 - accuracy: 0.8027 - val_loss: 0.5017 - val_accuracy: 0.8462\n",
      "Epoch 131/150\n",
      "294/294 [==============================] - 0s 721us/step - loss: 0.4483 - accuracy: 0.8129 - val_loss: 0.5049 - val_accuracy: 0.8462\n",
      "Epoch 132/150\n",
      "294/294 [==============================] - 0s 559us/step - loss: 0.4489 - accuracy: 0.8095 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.4477 - accuracy: 0.8129 - val_loss: 0.5108 - val_accuracy: 0.8462\n",
      "Epoch 134/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.4477 - accuracy: 0.8095 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 135/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4445 - accuracy: 0.8129 - val_loss: 0.5008 - val_accuracy: 0.8462\n",
      "Epoch 136/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.4448 - accuracy: 0.8163 - val_loss: 0.5041 - val_accuracy: 0.8462\n",
      "Epoch 137/150\n",
      "294/294 [==============================] - 0s 309us/step - loss: 0.4437 - accuracy: 0.8095 - val_loss: 0.5030 - val_accuracy: 0.8462\n",
      "Epoch 138/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.4439 - accuracy: 0.8129 - val_loss: 0.5010 - val_accuracy: 0.8462\n",
      "Epoch 139/150\n",
      "294/294 [==============================] - 0s 842us/step - loss: 0.4429 - accuracy: 0.8197 - val_loss: 0.5031 - val_accuracy: 0.8462\n",
      "Epoch 140/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4423 - accuracy: 0.8231 - val_loss: 0.4988 - val_accuracy: 0.8462\n",
      "Epoch 141/150\n",
      "294/294 [==============================] - 0s 432us/step - loss: 0.4402 - accuracy: 0.8197 - val_loss: 0.5076 - val_accuracy: 0.8269\n",
      "Epoch 142/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.4407 - accuracy: 0.8163 - val_loss: 0.5008 - val_accuracy: 0.8462\n",
      "Epoch 143/150\n",
      "294/294 [==============================] - 0s 443us/step - loss: 0.4382 - accuracy: 0.8163 - val_loss: 0.4996 - val_accuracy: 0.8462\n",
      "Epoch 144/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4364 - accuracy: 0.8197 - val_loss: 0.5028 - val_accuracy: 0.8462\n",
      "Epoch 145/150\n",
      "294/294 [==============================] - 0s 494us/step - loss: 0.4372 - accuracy: 0.8197 - val_loss: 0.4986 - val_accuracy: 0.8462\n",
      "Epoch 146/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.4355 - accuracy: 0.8231 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 147/150\n",
      "294/294 [==============================] - 0s 424us/step - loss: 0.4347 - accuracy: 0.8231 - val_loss: 0.4975 - val_accuracy: 0.8462\n",
      "Epoch 148/150\n",
      "294/294 [==============================] - 0s 401us/step - loss: 0.4334 - accuracy: 0.8231 - val_loss: 0.4986 - val_accuracy: 0.8462\n",
      "Epoch 149/150\n",
      "294/294 [==============================] - 0s 320us/step - loss: 0.4336 - accuracy: 0.8197 - val_loss: 0.4967 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.4330 - accuracy: 0.8231 - val_loss: 0.5021 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 138us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.5289 - accuracy: 0.2551 - val_loss: 1.4635 - val_accuracy: 0.1923\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 764us/step - loss: 1.4210 - accuracy: 0.2823 - val_loss: 1.3968 - val_accuracy: 0.2885\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 626us/step - loss: 1.3585 - accuracy: 0.3912 - val_loss: 1.3387 - val_accuracy: 0.4038\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 650us/step - loss: 1.3074 - accuracy: 0.4932 - val_loss: 1.2909 - val_accuracy: 0.5577\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 560us/step - loss: 1.2488 - accuracy: 0.5748 - val_loss: 1.2354 - val_accuracy: 0.6346\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 510us/step - loss: 1.1779 - accuracy: 0.6973 - val_loss: 1.1581 - val_accuracy: 0.7115\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 1.1053 - accuracy: 0.6905 - val_loss: 1.0780 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 1.0286 - accuracy: 0.7313 - val_loss: 1.0173 - val_accuracy: 0.7308\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 311us/step - loss: 0.9598 - accuracy: 0.7313 - val_loss: 0.9495 - val_accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.9032 - accuracy: 0.7347 - val_loss: 0.8938 - val_accuracy: 0.7500\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.8538 - accuracy: 0.7279 - val_loss: 0.8449 - val_accuracy: 0.7692\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.8141 - accuracy: 0.7381 - val_loss: 0.8065 - val_accuracy: 0.7692\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 766us/step - loss: 0.7818 - accuracy: 0.7449 - val_loss: 0.7767 - val_accuracy: 0.7692\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 322us/step - loss: 0.7539 - accuracy: 0.7381 - val_loss: 0.7457 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 421us/step - loss: 0.7288 - accuracy: 0.7415 - val_loss: 0.7212 - val_accuracy: 0.7692\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 591us/step - loss: 0.7097 - accuracy: 0.7449 - val_loss: 0.7077 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.6894 - accuracy: 0.7551 - val_loss: 0.6787 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.6735 - accuracy: 0.7653 - val_loss: 0.6595 - val_accuracy: 0.8269\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 289us/step - loss: 0.6616 - accuracy: 0.7449 - val_loss: 0.6469 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 307us/step - loss: 0.6511 - accuracy: 0.7653 - val_loss: 0.6367 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 290us/step - loss: 0.6354 - accuracy: 0.7653 - val_loss: 0.6248 - val_accuracy: 0.8269\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 346us/step - loss: 0.6271 - accuracy: 0.7585 - val_loss: 0.6059 - val_accuracy: 0.8269\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 332us/step - loss: 0.6169 - accuracy: 0.7687 - val_loss: 0.6073 - val_accuracy: 0.8269\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.6090 - accuracy: 0.7687 - val_loss: 0.5972 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 338us/step - loss: 0.6034 - accuracy: 0.7653 - val_loss: 0.5851 - val_accuracy: 0.8269\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5940 - accuracy: 0.7653 - val_loss: 0.5785 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.5884 - accuracy: 0.7721 - val_loss: 0.5779 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 610us/step - loss: 0.5825 - accuracy: 0.7687 - val_loss: 0.5685 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 904us/step - loss: 0.5769 - accuracy: 0.7789 - val_loss: 0.5641 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 495us/step - loss: 0.5723 - accuracy: 0.7687 - val_loss: 0.5552 - val_accuracy: 0.8462\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 590us/step - loss: 0.5688 - accuracy: 0.7687 - val_loss: 0.5610 - val_accuracy: 0.8269\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5629 - accuracy: 0.7687 - val_loss: 0.5560 - val_accuracy: 0.8269\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5633 - accuracy: 0.7789 - val_loss: 0.5387 - val_accuracy: 0.8654\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 516us/step - loss: 0.5571 - accuracy: 0.7721 - val_loss: 0.5472 - val_accuracy: 0.8269\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 567us/step - loss: 0.5522 - accuracy: 0.7789 - val_loss: 0.5460 - val_accuracy: 0.8269\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5476 - accuracy: 0.7755 - val_loss: 0.5316 - val_accuracy: 0.8654\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 475us/step - loss: 0.5438 - accuracy: 0.7823 - val_loss: 0.5320 - val_accuracy: 0.8654\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 737us/step - loss: 0.5421 - accuracy: 0.7823 - val_loss: 0.5263 - val_accuracy: 0.8654\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 441us/step - loss: 0.5358 - accuracy: 0.7789 - val_loss: 0.5276 - val_accuracy: 0.8654\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 457us/step - loss: 0.5332 - accuracy: 0.7789 - val_loss: 0.5286 - val_accuracy: 0.8654\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 433us/step - loss: 0.5330 - accuracy: 0.7755 - val_loss: 0.5233 - val_accuracy: 0.8654\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 573us/step - loss: 0.5276 - accuracy: 0.7823 - val_loss: 0.5179 - val_accuracy: 0.8654\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 381us/step - loss: 0.5255 - accuracy: 0.7891 - val_loss: 0.5156 - val_accuracy: 0.8654\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 438us/step - loss: 0.5245 - accuracy: 0.7857 - val_loss: 0.5159 - val_accuracy: 0.8654\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 378us/step - loss: 0.5232 - accuracy: 0.7857 - val_loss: 0.5197 - val_accuracy: 0.8654\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 412us/step - loss: 0.5203 - accuracy: 0.7755 - val_loss: 0.5149 - val_accuracy: 0.8654\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 339us/step - loss: 0.5147 - accuracy: 0.7925 - val_loss: 0.5112 - val_accuracy: 0.8654\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 373us/step - loss: 0.5139 - accuracy: 0.7857 - val_loss: 0.5105 - val_accuracy: 0.8654\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 383us/step - loss: 0.5122 - accuracy: 0.7925 - val_loss: 0.5133 - val_accuracy: 0.8654\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 820us/step - loss: 0.5098 - accuracy: 0.7823 - val_loss: 0.5150 - val_accuracy: 0.8654\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 539us/step - loss: 0.5068 - accuracy: 0.7925 - val_loss: 0.5043 - val_accuracy: 0.8654\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 505us/step - loss: 0.5061 - accuracy: 0.7857 - val_loss: 0.5077 - val_accuracy: 0.8654\n",
      "Epoch 53/150\n",
      "294/294 [==============================] - 0s 697us/step - loss: 0.5048 - accuracy: 0.7925 - val_loss: 0.5056 - val_accuracy: 0.8654\n",
      "Epoch 54/150\n",
      "294/294 [==============================] - 0s 406us/step - loss: 0.5025 - accuracy: 0.7925 - val_loss: 0.5048 - val_accuracy: 0.8654\n",
      "Epoch 55/150\n",
      "294/294 [==============================] - 0s 359us/step - loss: 0.4987 - accuracy: 0.7959 - val_loss: 0.5008 - val_accuracy: 0.8654\n",
      "Epoch 56/150\n",
      "294/294 [==============================] - 0s 295us/step - loss: 0.5018 - accuracy: 0.7891 - val_loss: 0.5041 - val_accuracy: 0.8654\n",
      "Epoch 57/150\n",
      "294/294 [==============================] - 0s 462us/step - loss: 0.4982 - accuracy: 0.7959 - val_loss: 0.5009 - val_accuracy: 0.8654\n",
      "Epoch 58/150\n",
      "294/294 [==============================] - 0s 566us/step - loss: 0.4935 - accuracy: 0.7959 - val_loss: 0.5021 - val_accuracy: 0.8654\n",
      "Epoch 59/150\n",
      "294/294 [==============================] - 0s 781us/step - loss: 0.4933 - accuracy: 0.7959 - val_loss: 0.4995 - val_accuracy: 0.8654\n",
      "Epoch 60/150\n",
      "294/294 [==============================] - 0s 686us/step - loss: 0.4913 - accuracy: 0.7959 - val_loss: 0.5085 - val_accuracy: 0.8654\n",
      "Epoch 61/150\n",
      "294/294 [==============================] - 0s 488us/step - loss: 0.4894 - accuracy: 0.7959 - val_loss: 0.4985 - val_accuracy: 0.8654\n",
      "Epoch 62/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.4871 - accuracy: 0.7993 - val_loss: 0.4999 - val_accuracy: 0.8654\n",
      "Epoch 63/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.4866 - accuracy: 0.7959 - val_loss: 0.5067 - val_accuracy: 0.8654\n",
      "Epoch 64/150\n",
      "294/294 [==============================] - 0s 765us/step - loss: 0.4863 - accuracy: 0.7959 - val_loss: 0.5097 - val_accuracy: 0.8654\n",
      "Epoch 65/150\n",
      "294/294 [==============================] - 0s 491us/step - loss: 0.4849 - accuracy: 0.7959 - val_loss: 0.4947 - val_accuracy: 0.8462\n",
      "Epoch 66/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7993 - val_loss: 0.5174 - val_accuracy: 0.8654\n",
      "Epoch 67/150\n",
      "294/294 [==============================] - 0s 615us/step - loss: 0.4804 - accuracy: 0.7993 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 68/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.4796 - accuracy: 0.8027 - val_loss: 0.5017 - val_accuracy: 0.8654\n",
      "Epoch 69/150\n",
      "294/294 [==============================] - 0s 464us/step - loss: 0.4808 - accuracy: 0.7993 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
      "Epoch 70/150\n",
      "294/294 [==============================] - 0s 352us/step - loss: 0.4775 - accuracy: 0.7925 - val_loss: 0.5009 - val_accuracy: 0.8462\n",
      "Epoch 71/150\n",
      "294/294 [==============================] - 0s 363us/step - loss: 0.4754 - accuracy: 0.8027 - val_loss: 0.5067 - val_accuracy: 0.8462\n",
      "Epoch 72/150\n",
      "294/294 [==============================] - 0s 305us/step - loss: 0.4750 - accuracy: 0.7993 - val_loss: 0.5076 - val_accuracy: 0.8654\n",
      "Epoch 73/150\n",
      "294/294 [==============================] - 0s 367us/step - loss: 0.4719 - accuracy: 0.7993 - val_loss: 0.5043 - val_accuracy: 0.8462\n",
      "Epoch 74/150\n",
      "294/294 [==============================] - 0s 400us/step - loss: 0.4709 - accuracy: 0.8095 - val_loss: 0.5005 - val_accuracy: 0.8462\n",
      "Epoch 75/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.4699 - accuracy: 0.8095 - val_loss: 0.5084 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 109us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.4878 - accuracy: 0.2687 - val_loss: 1.3597 - val_accuracy: 0.3269\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 476us/step - loss: 1.3033 - accuracy: 0.4524 - val_loss: 1.2370 - val_accuracy: 0.7308\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 519us/step - loss: 1.2049 - accuracy: 0.6633 - val_loss: 1.1506 - val_accuracy: 0.6923\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 613us/step - loss: 1.1082 - accuracy: 0.6837 - val_loss: 1.0462 - val_accuracy: 0.7115\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 700us/step - loss: 1.0084 - accuracy: 0.7041 - val_loss: 0.9576 - val_accuracy: 0.7692\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 366us/step - loss: 0.9186 - accuracy: 0.7313 - val_loss: 0.8650 - val_accuracy: 0.7692\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.8487 - accuracy: 0.7279 - val_loss: 0.8005 - val_accuracy: 0.7308\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 606us/step - loss: 0.7920 - accuracy: 0.7449 - val_loss: 0.7532 - val_accuracy: 0.7500\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 679us/step - loss: 0.7462 - accuracy: 0.7551 - val_loss: 0.7235 - val_accuracy: 0.8077\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 414us/step - loss: 0.7105 - accuracy: 0.7415 - val_loss: 0.6884 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 504us/step - loss: 0.6821 - accuracy: 0.7551 - val_loss: 0.6555 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 361us/step - loss: 0.6603 - accuracy: 0.7483 - val_loss: 0.6440 - val_accuracy: 0.8077\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 546us/step - loss: 0.6442 - accuracy: 0.7449 - val_loss: 0.6246 - val_accuracy: 0.8077\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 569us/step - loss: 0.6309 - accuracy: 0.7517 - val_loss: 0.6097 - val_accuracy: 0.7885\n",
      "Epoch 15/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 576us/step - loss: 0.6189 - accuracy: 0.7619 - val_loss: 0.5902 - val_accuracy: 0.8077\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 396us/step - loss: 0.6070 - accuracy: 0.7687 - val_loss: 0.5921 - val_accuracy: 0.8077\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 303us/step - loss: 0.5978 - accuracy: 0.7687 - val_loss: 0.5759 - val_accuracy: 0.8269\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 430us/step - loss: 0.5885 - accuracy: 0.7687 - val_loss: 0.5681 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 326us/step - loss: 0.5852 - accuracy: 0.7687 - val_loss: 0.5589 - val_accuracy: 0.8269\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 503us/step - loss: 0.5766 - accuracy: 0.7755 - val_loss: 0.5406 - val_accuracy: 0.8269\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 280us/step - loss: 0.5692 - accuracy: 0.7823 - val_loss: 0.5486 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5634 - accuracy: 0.7721 - val_loss: 0.5431 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.5591 - accuracy: 0.7789 - val_loss: 0.5452 - val_accuracy: 0.8077\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5588 - accuracy: 0.7789 - val_loss: 0.5250 - val_accuracy: 0.8269\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 413us/step - loss: 0.5554 - accuracy: 0.7619 - val_loss: 0.5304 - val_accuracy: 0.8077\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 299us/step - loss: 0.5506 - accuracy: 0.7721 - val_loss: 0.5234 - val_accuracy: 0.8269\n",
      "Epoch 27/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.5444 - accuracy: 0.7721 - val_loss: 0.5198 - val_accuracy: 0.8269\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 415us/step - loss: 0.5388 - accuracy: 0.7687 - val_loss: 0.5190 - val_accuracy: 0.8269\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 382us/step - loss: 0.5385 - accuracy: 0.7755 - val_loss: 0.5195 - val_accuracy: 0.8269\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 302us/step - loss: 0.5330 - accuracy: 0.7755 - val_loss: 0.5165 - val_accuracy: 0.8269\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.5296 - accuracy: 0.7823 - val_loss: 0.5052 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.5291 - accuracy: 0.7653 - val_loss: 0.5241 - val_accuracy: 0.8077\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 658us/step - loss: 0.5204 - accuracy: 0.7789 - val_loss: 0.4960 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7823 - val_loss: 0.5058 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 556us/step - loss: 0.5186 - accuracy: 0.7789 - val_loss: 0.5113 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 331us/step - loss: 0.5151 - accuracy: 0.7789 - val_loss: 0.4992 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 548us/step - loss: 0.5149 - accuracy: 0.7823 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5129 - accuracy: 0.7755 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 873us/step - loss: 0.5069 - accuracy: 0.7687 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7789 - val_loss: 0.5027 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5073 - accuracy: 0.7857 - val_loss: 0.4995 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5055 - accuracy: 0.7925 - val_loss: 0.4974 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 592us/step - loss: 0.5041 - accuracy: 0.7687 - val_loss: 0.4994 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 92us/step\n",
      "Train on 294 samples, validate on 52 samples\n",
      "Epoch 1/150\n",
      "294/294 [==============================] - 1s 3ms/step - loss: 1.3446 - accuracy: 0.4048 - val_loss: 1.1957 - val_accuracy: 0.6154\n",
      "Epoch 2/150\n",
      "294/294 [==============================] - 0s 484us/step - loss: 1.1174 - accuracy: 0.5952 - val_loss: 0.9898 - val_accuracy: 0.8269\n",
      "Epoch 3/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.9454 - accuracy: 0.7075 - val_loss: 0.8445 - val_accuracy: 0.7692\n",
      "Epoch 4/150\n",
      "294/294 [==============================] - 0s 645us/step - loss: 0.8208 - accuracy: 0.7381 - val_loss: 0.7501 - val_accuracy: 0.7692\n",
      "Epoch 5/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.7303 - accuracy: 0.7585 - val_loss: 0.6527 - val_accuracy: 0.8077\n",
      "Epoch 6/150\n",
      "294/294 [==============================] - 0s 335us/step - loss: 0.6849 - accuracy: 0.7313 - val_loss: 0.6364 - val_accuracy: 0.7885\n",
      "Epoch 7/150\n",
      "294/294 [==============================] - 0s 336us/step - loss: 0.6558 - accuracy: 0.7415 - val_loss: 0.6104 - val_accuracy: 0.8077\n",
      "Epoch 8/150\n",
      "294/294 [==============================] - 0s 420us/step - loss: 0.6215 - accuracy: 0.7347 - val_loss: 0.5687 - val_accuracy: 0.7885\n",
      "Epoch 9/150\n",
      "294/294 [==============================] - 0s 362us/step - loss: 0.6094 - accuracy: 0.7449 - val_loss: 0.5592 - val_accuracy: 0.7885\n",
      "Epoch 10/150\n",
      "294/294 [==============================] - 0s 375us/step - loss: 0.6021 - accuracy: 0.7415 - val_loss: 0.5467 - val_accuracy: 0.7885\n",
      "Epoch 11/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5942 - accuracy: 0.7551 - val_loss: 0.5443 - val_accuracy: 0.8077\n",
      "Epoch 12/150\n",
      "294/294 [==============================] - 0s 867us/step - loss: 0.5808 - accuracy: 0.7517 - val_loss: 0.5413 - val_accuracy: 0.8269\n",
      "Epoch 13/150\n",
      "294/294 [==============================] - 0s 601us/step - loss: 0.5685 - accuracy: 0.7687 - val_loss: 0.5393 - val_accuracy: 0.7885\n",
      "Epoch 14/150\n",
      "294/294 [==============================] - 0s 479us/step - loss: 0.5640 - accuracy: 0.7551 - val_loss: 0.5417 - val_accuracy: 0.8269\n",
      "Epoch 15/150\n",
      "294/294 [==============================] - 0s 473us/step - loss: 0.5537 - accuracy: 0.7517 - val_loss: 0.5239 - val_accuracy: 0.7885\n",
      "Epoch 16/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.5499 - accuracy: 0.7449 - val_loss: 0.5174 - val_accuracy: 0.8462\n",
      "Epoch 17/150\n",
      "294/294 [==============================] - 0s 384us/step - loss: 0.5436 - accuracy: 0.7721 - val_loss: 0.5132 - val_accuracy: 0.8077\n",
      "Epoch 18/150\n",
      "294/294 [==============================] - 0s 333us/step - loss: 0.5478 - accuracy: 0.7517 - val_loss: 0.5174 - val_accuracy: 0.8077\n",
      "Epoch 19/150\n",
      "294/294 [==============================] - 0s 313us/step - loss: 0.5374 - accuracy: 0.7721 - val_loss: 0.5156 - val_accuracy: 0.8077\n",
      "Epoch 20/150\n",
      "294/294 [==============================] - 0s 610us/step - loss: 0.5396 - accuracy: 0.7551 - val_loss: 0.5181 - val_accuracy: 0.7885\n",
      "Epoch 21/150\n",
      "294/294 [==============================] - 0s 434us/step - loss: 0.5351 - accuracy: 0.7755 - val_loss: 0.5157 - val_accuracy: 0.8077\n",
      "Epoch 22/150\n",
      "294/294 [==============================] - 0s 577us/step - loss: 0.5264 - accuracy: 0.7687 - val_loss: 0.5129 - val_accuracy: 0.8077\n",
      "Epoch 23/150\n",
      "294/294 [==============================] - 0s 374us/step - loss: 0.5258 - accuracy: 0.7517 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 24/150\n",
      "294/294 [==============================] - 0s 445us/step - loss: 0.5191 - accuracy: 0.7687 - val_loss: 0.5281 - val_accuracy: 0.8077\n",
      "Epoch 25/150\n",
      "294/294 [==============================] - 0s 341us/step - loss: 0.5186 - accuracy: 0.7585 - val_loss: 0.5070 - val_accuracy: 0.8462\n",
      "Epoch 26/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5188 - accuracy: 0.7789 - val_loss: 0.5159 - val_accuracy: 0.8077\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 383us/step - loss: 0.5213 - accuracy: 0.7721 - val_loss: 0.4924 - val_accuracy: 0.8462\n",
      "Epoch 28/150\n",
      "294/294 [==============================] - 0s 364us/step - loss: 0.5156 - accuracy: 0.7755 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 29/150\n",
      "294/294 [==============================] - 0s 355us/step - loss: 0.5101 - accuracy: 0.7687 - val_loss: 0.5029 - val_accuracy: 0.8462\n",
      "Epoch 30/150\n",
      "294/294 [==============================] - 0s 350us/step - loss: 0.5002 - accuracy: 0.7789 - val_loss: 0.5156 - val_accuracy: 0.8077\n",
      "Epoch 31/150\n",
      "294/294 [==============================] - 0s 306us/step - loss: 0.5096 - accuracy: 0.7483 - val_loss: 0.4932 - val_accuracy: 0.8462\n",
      "Epoch 32/150\n",
      "294/294 [==============================] - 0s 402us/step - loss: 0.5050 - accuracy: 0.7585 - val_loss: 0.4987 - val_accuracy: 0.8462\n",
      "Epoch 33/150\n",
      "294/294 [==============================] - 0s 314us/step - loss: 0.4984 - accuracy: 0.7755 - val_loss: 0.4941 - val_accuracy: 0.8462\n",
      "Epoch 34/150\n",
      "294/294 [==============================] - 0s 308us/step - loss: 0.4936 - accuracy: 0.7721 - val_loss: 0.4934 - val_accuracy: 0.8462\n",
      "Epoch 35/150\n",
      "294/294 [==============================] - 0s 316us/step - loss: 0.4921 - accuracy: 0.7891 - val_loss: 0.5002 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4842 - accuracy: 0.7959 - val_loss: 0.4823 - val_accuracy: 0.8462\n",
      "Epoch 37/150\n",
      "294/294 [==============================] - 0s 448us/step - loss: 0.4887 - accuracy: 0.7857 - val_loss: 0.5115 - val_accuracy: 0.8462\n",
      "Epoch 38/150\n",
      "294/294 [==============================] - 0s 325us/step - loss: 0.4897 - accuracy: 0.7687 - val_loss: 0.5026 - val_accuracy: 0.8462\n",
      "Epoch 39/150\n",
      "294/294 [==============================] - 0s 754us/step - loss: 0.4822 - accuracy: 0.7857 - val_loss: 0.4858 - val_accuracy: 0.8462\n",
      "Epoch 40/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7823 - val_loss: 0.5078 - val_accuracy: 0.8462\n",
      "Epoch 41/150\n",
      "294/294 [==============================] - 0s 348us/step - loss: 0.4738 - accuracy: 0.7925 - val_loss: 0.4871 - val_accuracy: 0.8462\n",
      "Epoch 42/150\n",
      "294/294 [==============================] - 0s 344us/step - loss: 0.4751 - accuracy: 0.7959 - val_loss: 0.4681 - val_accuracy: 0.8462\n",
      "Epoch 43/150\n",
      "294/294 [==============================] - 0s 447us/step - loss: 0.4732 - accuracy: 0.7857 - val_loss: 0.5032 - val_accuracy: 0.8462\n",
      "Epoch 44/150\n",
      "294/294 [==============================] - 0s 376us/step - loss: 0.4655 - accuracy: 0.7891 - val_loss: 0.4824 - val_accuracy: 0.8462\n",
      "Epoch 45/150\n",
      "294/294 [==============================] - 0s 450us/step - loss: 0.4783 - accuracy: 0.8129 - val_loss: 0.5251 - val_accuracy: 0.8269\n",
      "Epoch 46/150\n",
      "294/294 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7857 - val_loss: 0.4943 - val_accuracy: 0.8462\n",
      "Epoch 47/150\n",
      "294/294 [==============================] - 0s 759us/step - loss: 0.4658 - accuracy: 0.8027 - val_loss: 0.4728 - val_accuracy: 0.8462\n",
      "Epoch 48/150\n",
      "294/294 [==============================] - 0s 439us/step - loss: 0.4677 - accuracy: 0.7857 - val_loss: 0.4785 - val_accuracy: 0.8462\n",
      "Epoch 49/150\n",
      "294/294 [==============================] - 0s 329us/step - loss: 0.4596 - accuracy: 0.7959 - val_loss: 0.4923 - val_accuracy: 0.8462\n",
      "Epoch 50/150\n",
      "294/294 [==============================] - 0s 371us/step - loss: 0.4572 - accuracy: 0.7891 - val_loss: 0.4776 - val_accuracy: 0.8462\n",
      "Epoch 51/150\n",
      "294/294 [==============================] - 0s 391us/step - loss: 0.4556 - accuracy: 0.7925 - val_loss: 0.5029 - val_accuracy: 0.8077\n",
      "Epoch 52/150\n",
      "294/294 [==============================] - 0s 572us/step - loss: 0.4567 - accuracy: 0.7925 - val_loss: 0.4691 - val_accuracy: 0.8462\n",
      "116/116 [==============================] - 0s 117us/step\n"
     ]
    }
   ],
   "source": [
    "for n in numbers:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*n, input_dim = 11, activation = 'sigmoid'))\n",
    "    model.add(Dense(n, activation = 'sigmoid'))\n",
    "    model.add(Dense(4, activation ='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "    history = model.fit(X_train, Y_train, batch_size = 10, epochs = 150, validation_split= 0.15, verbose = 1, \n",
    "         callbacks = [callback_early_stopping])\n",
    "    y_test,accuracy = model.evaluate(X_test, Y_test)\n",
    "    history_all.append(history)\n",
    "    accuracy_all.append(accuracy)\n",
    "    n_value.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f715b008ed0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(n_value,accuracy_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
